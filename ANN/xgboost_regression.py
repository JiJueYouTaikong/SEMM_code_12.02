import random
import numpy as np
import torch
from sklearn.preprocessing import MinMaxScaler
from sklearn.multioutput import MultiOutputRegressor
from xgboost import XGBRegressor
import joblib
import os
import itertools

def init_log(is_mcm):
    os.makedirs("log", exist_ok=True)
    log_name = f"log/Xgb_{is_mcm}.log"
    return log_name

def write_log(log_file, msg):
    print(msg)
    with open(log_file, "a") as f:
        f.write(msg + "\n")

# ==== è¯„ä»·å‡½æ•°ï¼ˆåŸºæœ¬ä¿ç•™ï¼Œåªåœ¨ä½¿ç”¨æ—¶æŠŠ numpy è½¬ä¸º torchï¼‰ ====
def calculate_rmse_mae(predictions, targets):
    '''
    :param predictions: torch.Tensor [T,N,N]
    :param targets: torch.Tensor [T,N,N]
    :return: rmse, mae, mape, cpc, jsd
    '''
    T, N, _ = predictions.shape
    mse = torch.mean((predictions - targets) ** 2)
    rmse = torch.sqrt(mse)
    mae = torch.mean(torch.abs(predictions - targets))

    # è®¡ç®— MAPEï¼Œé¿å…é™¤ä»¥é›¶
    non_zero_mask = targets != 0
    if non_zero_mask.sum() > 0:
        mape = torch.mean(
            torch.abs((predictions[non_zero_mask] - targets[non_zero_mask]) / targets[non_zero_mask]))
    else:
        mape = torch.tensor(0.0)

    # Flatten
    pred_flat = predictions.reshape(predictions.shape[0], -1)
    targ_flat = targets.reshape(targets.shape[0], -1)

    # CPC
    cpc_list = []
    for t in range(pred_flat.shape[0]):
        pred_t = pred_flat[t]
        targ_t = targ_flat[t]
        numerator = 2 * torch.sum(torch.minimum(pred_t, targ_t))
        denominator = torch.sum(pred_t) + torch.sum(targ_t)
        if denominator > 0:
            cpc_list.append((numerator / denominator).item())
        else:
            cpc_list.append(1.0)
    cpc = sum(cpc_list) / len(cpc_list)

    # JSD
    jsd_list = []
    min_val = 1e-8  # å®‰å…¨è£å‰ªé˜ˆå€¼

    for t in range(pred_flat.shape[0]):
        pred_t = pred_flat[t]
        targ_t = targ_flat[t]

        # æ„é€ åˆ†å¸ƒ
        pred_dist = (pred_t + min_val) / (torch.sum(pred_t) + min_val * pred_t.numel())
        targ_dist = (targ_t + min_val) / (torch.sum(targ_t) + min_val * targ_t.numel())

        # å¼ºåˆ¶è£å‰ªï¼Œé˜²æ­¢log(0)
        pred_dist = torch.clamp(pred_dist, min=min_val)
        targ_dist = torch.clamp(targ_dist, min=min_val)
        m = 0.5 * (pred_dist + targ_dist)
        m = torch.clamp(m, min=min_val)

        kl1 = torch.sum(pred_dist * torch.log(pred_dist / m))
        kl2 = torch.sum(targ_dist * torch.log(targ_dist / m))
        jsd_t = 0.5 * (kl1 + kl2)

        if not torch.isnan(jsd_t):
            jsd_list.append(jsd_t.item())
    jsd = sum(jsd_list) / len(jsd_list) if jsd_list else 0.0

    return rmse.item(), mae.item(), mape.item(), cpc, jsd


# ==== éšæœºç§å­ ====
def set_seed(seed):
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


# ==== æ•°æ®åŠ è½½ï¼ˆè¿”å› numpy çŸ©é˜µå½¢å¼ä»¥ä¾› XGBoost ä½¿ç”¨ï¼‰ ====
def load_data(is_mcm):
    set_seed(42)

    if is_mcm:
        speed = np.load('../data/Speed_å®Œæ•´æ‰¹å¤„ç†_3.17_Final_MCM_60.npy')
        od = np.load('../data/OD_å®Œæ•´æ‰¹å¤„ç†_3.17_Final_MCM_60.npy')

        # è·å–æ•°æ®é•¿åº¦ T
        T, N = speed.shape
        # æ ¹æ®æŒ‡å®šçš„æ—¶é—´æ­¥æ•°åˆ’åˆ†
        test_size = 35
        val_size = 33
        train_size = T - test_size - val_size

    else:
        speed = np.load('../data/Speed_å®Œæ•´æ‰¹å¤„ç†_3.17_Final.npy')
        od = np.load('../data/OD_å®Œæ•´æ‰¹å¤„ç†_3.17_Final.npy')

        T, N = speed.shape
        train_size = int(T * 0.6)
        val_size = int(T * 0.2)

    # é¡ºåºåˆ’åˆ†ç´¢å¼•
    train_indices = np.arange(0, train_size)
    val_indices = np.arange(train_size, train_size + val_size)
    test_indices = np.arange(train_size + val_size, T)

    speed_train, speed_val, speed_test = speed[train_indices], speed[val_indices], speed[test_indices]
    od_train, od_val, od_test = od[train_indices], od[val_indices], od[test_indices]

    print("6:2:2é¡ºåºåˆ’åˆ†çš„è®­ç»ƒé›†Speed", speed_train.shape, "OD", od_train.shape)
    print("6:2:2é¡ºåºåˆ’åˆ†çš„éªŒè¯é›†Speed", speed_val.shape, "OD", od_val.shape)
    print("6:2:2é¡ºåºåˆ’åˆ†çš„æµ‹è¯•é›†Speed", speed_test.shape, "OD", od_test.shape)

    scaler = MinMaxScaler()
    x_train_scale = scaler.fit_transform(speed_train.reshape(-1, 1)).reshape(speed_train.shape)
    x_val_scale = scaler.transform(speed_val.reshape(-1, 1)).reshape(speed_val.shape)
    x_test_scale = scaler.transform(speed_test.reshape(-1, 1)).reshape(speed_test.shape)

    # å‡†å¤‡ X (T,N) å’Œ y (T, N*N)
    # od_train/val/test åŸå§‹æ˜¯ [T, N, N]ï¼Œéœ€è¦ flatten ä¸º [T, N*N]
    Ttr, N = x_train_scale.shape
    y_train = od_train.reshape(od_train.shape[0], -1)
    y_val = od_val.reshape(od_val.shape[0], -1)
    y_test = od_test.reshape(od_test.shape[0], -1)

    X_train = x_train_scale  # shape [Ttr, N]
    X_val = x_val_scale
    X_test = x_test_scale

    print("å½’ä¸€åŒ–å¹¶å±•å¹³åçš„å½¢çŠ¶ï¼š",
          "X_train", X_train.shape, "y_train", y_train.shape,
          "X_val", X_val.shape, "y_val", y_val.shape,
          "X_test", X_test.shape, "y_test", y_test.shape)

    return X_train, y_train, X_val, y_val, X_test, y_test, N


# ==== è®­ç»ƒ XGBoost å¤šè¾“å‡ºæ¨¡å‹ ====
def train_xgb_multioutput(X_train, y_train, X_val=None, y_val=None,
                          model_path="ckpt/xgb_multi.pkl",
                          n_estimators=200, learning_rate=0.05, max_depth=6, n_jobs=8, random_state=42):
    """
    ä½¿ç”¨ MultiOutputRegressor å°è£… XGBRegressor è®­ç»ƒå¤šè¾“å‡ºå›å½’
    æ³¨æ„ï¼šå½“è¾“å‡ºç»´éå¸¸å¤§ï¼ˆN*Nï¼‰æ—¶è®­ç»ƒè€—æ—¶/å†…å­˜ä¼šæ˜¾è‘—ä¸Šå‡ã€‚
    """
    # os.makedirs(os.path.dirname(model_path), exist_ok=True)

    xgb = XGBRegressor(objective='reg:squarederror',
                       n_estimators=n_estimators,
                       learning_rate=learning_rate,
                       max_depth=max_depth,
                       verbosity=0,
                       n_jobs=n_jobs,
                       random_state=random_state)

    mor = MultiOutputRegressor(xgb, n_jobs=1)  # å†…éƒ¨å¹¶è¡Œä¼šå ç”¨èµ„æºï¼Œn_jobs=1 ä¿å®ˆè®¾ç½®

    print("å¼€å§‹è®­ç»ƒ XGBoost å¤šè¾“å‡ºæ¨¡å‹ï¼Œè¾“å‡ºç»´åº¦:", y_train.shape[1])
    mor.fit(X_train, y_train)  # æ³¨æ„ï¼šæ²¡æœ‰ per-output early stoppingï¼ˆå¦‚éœ€å¯æ”¹ä¸ºé€åˆ—è®­ç»ƒï¼‰

    # joblib.dump(mor, model_path)
    # print("æ¨¡å‹å·²ä¿å­˜åˆ°:", model_path)
    return mor



def test_xgb_model(model, X_test, y_test, N, model_path=None,log_filename=None):
    """
    model: å¦‚æœä¸º Noneï¼Œåˆ™ä» model_path åŠ è½½
    X_test: numpy [Ttest, N]
    y_test: numpy [Ttest, N*N]
    N: åŒºåŸŸæ•°é‡
    """
    if model is None:
        assert model_path is not None, "éœ€è¦ model_path æˆ–å·²ä¼ å…¥ model"
        model = joblib.load(model_path)

    preds = model.predict(X_test)  # shape [Ttest, N*N]
    # å¦‚æœ XGBoost è¾“å‡ºæœ‰è´Ÿå€¼ï¼ˆå¯èƒ½ï¼‰ï¼Œæ ¹æ®ä¸šåŠ¡éœ€è¦è£å‰ªåˆ° 0
    preds = np.clip(preds, a_min=0.0, a_max=None)

    # reshape ä¸º [T, N, N]
    preds_3d = preds.reshape(preds.shape[0], N, N)
    real_3d = y_test.reshape(y_test.shape[0], N, N)

    # mask å¯¹è§’çº¿ä¸º 0ï¼ˆå‚ç…§ä½ åŸæœ‰å®ç°ï¼‰
    mask = np.ones_like(real_3d)
    for i in range(N):
        mask[:, i, i] = 0

    # è½¬ä¸º torch.Tensor ä»¥å¤ç”¨ calculate_rmse_mae
    preds_t = torch.tensor(preds_3d * mask, dtype=torch.float32)
    real_t = torch.tensor(real_3d, dtype=torch.float32)

    rmse, mae, mape, cpc, jsd = calculate_rmse_mae(preds_t, real_t)

    with open(log_filename, 'a') as log_file:
        log_file.write(f"XGB Test RMSE: {rmse:.6f}, MAE: {mae:.6f}, MAPE: {mape:.6f}, CPC: {cpc:.6f}, JSD: {jsd:.6f}\n")

    print(f"XGB Test RMSE: {rmse:.6f}, MAE: {mae:.6f}, MAPE: {mape:.6f}, CPC: {cpc:.6f}, JSD: {jsd:.6f}")
    return preds_3d, real_3d,rmse


def run_test_only():
    is_mcm = False  # True æˆ– Falseï¼Œæ ¹æ®è¦åŠ è½½çš„æ¨¡å‹å†³å®š
    log_file = init_log(is_mcm)

    # ==== åŠ è½½æ•°æ® ====
    X_train, y_train, X_val, y_val, X_test, y_test, N = load_data(is_mcm=is_mcm)

    # ==== æŒ‡å®šè¦åŠ è½½çš„æ¨¡å‹è·¯å¾„ ====
    model_path = f"ckpt/xgb_multi_best_{is_mcm}.pkl"
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")

    write_log(log_file, f"å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_path}")

    # ==== åŠ è½½æ¨¡å‹å¹¶æµ‹è¯• ====
    model = joblib.load(model_path)
    preds_3d, real_3d, test_rmse = test_xgb_model(
        model=model,
        X_test=X_test,
        y_test=y_test,
        N=N,
        model_path=model_path,
        log_filename=log_file
    )

    print(preds_3d.shape)

    # ==== ä¿å­˜æµ‹è¯•é›†é¢„æµ‹ç»“æœ ====
    save_path = f"pred_xgb_{is_mcm}.npy"
    np.save(save_path, preds_3d)
    write_log(log_file, f"é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {save_path}")
    print(f"é¢„æµ‹ä¿å­˜æˆåŠŸ: {save_path}")

def main():

    # ä»…æµ‹è¯•
    run_test_only()

    # ç½‘æ ¼æœç´¢ä»£ç 
    # is_mcm = False
    # log_file = init_log(is_mcm)
    #
    # X_train, y_train, X_val, y_val, X_test, y_test, N = load_data(is_mcm=is_mcm)
    #
    # # # å®šä¹‰æœç´¢èŒƒå›´
    # # n_estimators_grid = [50]
    # # learning_rate_grid = [0.01,0.001,0.05]
    # # max_depth_grid = [3, 4]
    #
    # # falseçš„æœ€ä½³å‚æ•°
    # # n_estimators_grid = [50]
    # # learning_rate_grid = [0.05]
    # # max_depth_grid = [3]
    #
    # # trueçš„æœ€ä½³å‚æ•°
    # # n_estimators_grid = [50]
    # # learning_rate_grid = [0.05]
    # # max_depth_grid = [4]
    #
    # # === æ ¹æ® is_mcm è®¾ç½®æœ€ä½³å‚æ•°ç½‘æ ¼ ===
    # if is_mcm:
    #     n_estimators_grid = [50]
    #     learning_rate_grid = [0.05]
    #     max_depth_grid = [4]  # true çš„æœ€ä½³å‚æ•°
    # else:
    #     n_estimators_grid = [50]
    #     learning_rate_grid = [0.05]
    #     max_depth_grid = [3]  # false çš„æœ€ä½³å‚æ•°
    #
    # best_score = float('inf')
    # best_params = None
    # best_model = None
    #
    # write_log(log_file, "=== å¼€å§‹ç½‘æ ¼æœç´¢ ===")
    #
    # # éå†æ‰€æœ‰è¶…å‚æ•°ç»„åˆ
    # for n_estimators, learning_rate, max_depth in itertools.product(
    #     n_estimators_grid, learning_rate_grid, max_depth_grid
    # ):
    #     params = dict(
    #         n_estimators=n_estimators,
    #         learning_rate=learning_rate,
    #         max_depth=max_depth,
    #         n_jobs=8,
    #         random_state=42
    #     )
    #     write_log(log_file, f"å°è¯•å‚æ•°ç»„åˆ: {params}")
    #
    #     model = train_xgb_multioutput(
    #         X_train, y_train, X_val, y_val,
    #         model_path=None,  # ä¸ä¿å­˜ä¸­é—´æ¨¡å‹
    #         n_estimators=params['n_estimators'],
    #         learning_rate=params['learning_rate'],
    #         max_depth=params['max_depth'],
    #         n_jobs=params['n_jobs'],
    #         random_state=params['random_state']
    #     )
    #
    #     # ç”¨éªŒè¯é›†è®¡ç®—è¯¯å·®ï¼ˆå‡è®¾ test_xgb_model è¿”å› RMSEï¼‰
    #     preds_3d, real_3d, val_rmse = test_xgb_model(
    #         model, X_val, y_val, N, model_path=None, log_filename=log_file
    #     )
    #
    #     write_log(log_file, f"éªŒè¯é›†RMSE: {val_rmse:.4f}")
    #
    #     if val_rmse < best_score:
    #         best_score = val_rmse
    #         best_params = params
    #         best_model = model
    #
    # write_log(log_file, f"\n=== æœ€ä¼˜å‚æ•° ===\n{best_params}\néªŒè¯é›†æœ€ä¼˜RMSE: {best_score:.4f}")
    #
    # # é‡æ–°åœ¨è®­ç»ƒé›†+éªŒè¯é›†ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    # model_path = f"ckpt/xgb_multi_best_{is_mcm}.pkl"
    # joblib.dump(best_model, model_path)
    # write_log(log_file, f"âœ… æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
    #
    # # æµ‹è¯•é˜¶æ®µ
    # preds_3d, real_3d,test_rmse = test_xgb_model(best_model, X_test, y_test, N, model_path=model_path, log_filename=log_file)
    #
    # # === ä¿å­˜é¢„æµ‹ç»“æœä¸º .npy ===
    # save_path = f"preds_xgb_{is_mcm}.npy"
    # np.save(save_path, preds_3d)
    # write_log(log_file, f"ğŸ“ æµ‹è¯•é›†é¢„æµ‹ç»“æœå·²ä¿å­˜ä¸º: {save_path}")
    # print(f"ä¿å­˜æˆåŠŸ: {save_path}")

if __name__ == "__main__":
    main()

