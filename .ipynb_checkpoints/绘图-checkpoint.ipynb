{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ANN",
   "id": "c99da80ec8eaafa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T06:39:47.625694Z",
     "start_time": "2025-05-05T06:39:43.604740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "# from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 数据准备\n",
    "def normalize_data(data):\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    return (data - min_val) / (max_val - min_val), min_val, max_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "# 定义新模型\n",
    "class ODModel(nn.Module):\n",
    "    def __init__(self, N, F):\n",
    "        super(ODModel, self).__init__()\n",
    "        self.N = N\n",
    "        self.F = F\n",
    "        n1 = 128\n",
    "        n2 = 64\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(N*F, n1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n1, n2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n2, N * N)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状：[batch, N, F=1]\n",
    "        batch_size, N, F = x.shape\n",
    "        x = x.view(batch_size, N * F)\n",
    "\n",
    "        # 输入到 MLP 网络中\n",
    "        od_matrix_flat = self.mlp(x)  # [batch, N * N]\n",
    "        # reshape为OD矩阵的形状\n",
    "        od_matrix = od_matrix_flat.view(batch_size, N, N)  # [batch, N, N]\n",
    "\n",
    "        return od_matrix\n",
    "\n",
    "\n",
    "# 训练过程\n",
    "def train_model(model, train_loader, val_loader, epochs=100, patience=10,learning_rate=0.001, load=0):\n",
    "\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 学习率调度器\n",
    "    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    N = 110\n",
    "\n",
    "\n",
    "    # 训练过程\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # 计算训练集的平均损失\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # 验证过程\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # 计算验证集的平均损失\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        \n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # 提前停止机制\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # 保存最佳模型\n",
    "            torch.save(model.state_dict(), \"ckpt_仿真/best_model_feature1_25.1.14数据集版本.pth\")\n",
    "            print(f\"best saved at epoch{epoch + 1},best：{best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # # 绘制训练过程中的损失曲线\n",
    "    # with open(log_filename, 'r') as log_file:\n",
    "    #     epochs_list, train_loss_list, val_loss_list = [], [], []\n",
    "    #     for line in log_file.readlines()[1:]:\n",
    "    #         epoch, train_loss, val_loss = line.strip().split(\", \")\n",
    "    #         epochs_list.append(int(epoch))\n",
    "    #         train_loss_list.append(float(train_loss))\n",
    "    #         val_loss_list.append(float(val_loss))\n",
    "    #\n",
    "    # plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
    "    # plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'train and validation loss with lr={learning_rate}')\n",
    "    # # plt.savefig(\"loss_curve.png\")\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def calculate_rmse_mae(predictions, targets):\n",
    "    mse = torch.mean((predictions - targets) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(predictions - targets))\n",
    "\n",
    "    # 计算 MAPE，避免除以零\n",
    "    non_zero_mask = targets != 0\n",
    "    if non_zero_mask.sum() > 0:\n",
    "        mape = torch.mean(\n",
    "            torch.abs((predictions[non_zero_mask] - targets[non_zero_mask]) / targets[non_zero_mask]))\n",
    "    else:\n",
    "        mape = torch.tensor(0.0)\n",
    "    return rmse.item(), mae.item(), mape.item()\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 设置所有GPU的随机种子\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "def load_data():\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    # 加载数据\n",
    "    speed = np.load('../data/Speed_完整批处理_3.17_Final_MCM_60.npy')  # 形状 [T, N, 2]\n",
    "    # speed = data[:, :, 0]  # 平均速度 [T, N]\n",
    "    od = np.load('../data/OD_完整批处理_3.17_Final_MCM_60.npy')  # 形状 [T, N, N]\n",
    "\n",
    "    # 设置均值和标准差\n",
    "    mean = 0.05\n",
    "    std_dev = 0.01\n",
    "    # 获取数据长度 T\n",
    "    T, N = speed.shape\n",
    "\n",
    "    # 生成T组高斯分布数据\n",
    "    x_random = np.random.normal(loc=mean, scale=std_dev, size=(T, N))\n",
    "\n",
    "    # 将数据裁剪到0到1之间\n",
    "    x_random = np.clip(x_random, 0, 0.1)\n",
    "\n",
    "    # 按顺序划分数据\n",
    "    train_size = int(T * 0.6)\n",
    "    val_size = int(T * 0.2)\n",
    "    train_size = int(T * 0.9537)\n",
    "    val_size = int(T * 0.0225)\n",
    "\n",
    "    # 顺序划分索引\n",
    "    train_indices = np.arange(0, train_size)\n",
    "    val_indices = np.arange(train_size, train_size + val_size)\n",
    "    test_indices = np.arange(train_size + val_size, T)\n",
    "\n",
    "    # 按索引划分数据\n",
    "    speed_train, speed_val, speed_test = speed[train_indices], speed[val_indices], speed[test_indices]\n",
    "    od_train, od_val, od_test = od[train_indices], od[val_indices], od[test_indices]\n",
    "    x_random_train, x_random_val, x_random_test = x_random[train_indices], x_random[val_indices], x_random[test_indices]\n",
    "\n",
    "    # 输出划分后的数据形状\n",
    "    print(\"6:2:2顺序划分的训练集Speed\", speed_train.shape, \"OD\", od_train.shape)\n",
    "    print(\"6:2:2顺序划分的验证集Speed\", speed_val.shape, \"OD\", od_val.shape)\n",
    "    print(\"6:2:2顺序划分的测试集Speed\", speed_test.shape, \"OD\", od_test.shape)\n",
    "\n",
    "\n",
    "    # 在训练集上计算 OD 出发总量\n",
    "    od_train_departures = np.sum(od_train, axis=-1)  # 形状 [T_train, N]\n",
    "\n",
    "    # 计算每个区域在 T_train 时间步的平均速度和平均出发总量\n",
    "    mean_speed = np.mean(speed_train, axis=0)  # 每个区域的平均速度 [N,]\n",
    "    mean_departures = np.mean(od_train_departures, axis=0)  # 每个区域的平均出发总量 [N,]\n",
    "\n",
    "    # 计算平均速度和平均出发总量的差值\n",
    "    temporal = mean_departures - mean_speed  # [N,]\n",
    "\n",
    "    # 输出结果\n",
    "    # print(\"temporal 变量形状：\", temporal.shape)\n",
    "\n",
    "    # 将 temporal 变量扩展到与输入数据时间维度匹配\n",
    "    temporal_expanded_train = np.tile(temporal, (speed_train.shape[0], 1))  # [T_train, N]\n",
    "    temporal_expanded_val = np.tile(temporal, (speed_val.shape[0], 1))  # [T_val, N]\n",
    "    temporal_expanded_test = np.tile(temporal, (speed_test.shape[0], 1))  # [T_test, N]\n",
    "\n",
    "    # freq\n",
    "    speed_freq = np.load('../data/速度的周期状态_对应25.1.14的速度数据集.npy')  # 形状 [N,]\n",
    "    od_freq = np.load('../data/OD的周期状态_对应25.1.14的OD数据集.npy')  # 形状 [N,]\n",
    "    # print(speed_freq.shape)\n",
    "    # print(od_freq.shape)\n",
    "    freq = od_freq - speed_freq\n",
    "\n",
    "    freq_expanded_train = np.tile(freq, (speed_train.shape[0], 1))  # [T_train, N]\n",
    "    freq_expanded_val = np.tile(freq, (speed_val.shape[0], 1))  # [T_val, N]\n",
    "    freq_expanded_test = np.tile(freq, (speed_test.shape[0], 1))  # [T_test, N]\n",
    "\n",
    "    # 添加到训练集、验证集和测试集\n",
    "    x_train = np.stack([speed_train, temporal_expanded_train, freq_expanded_train, x_random_train],\n",
    "                       axis=-1)  # [T_train, N, 3]\n",
    "    x_val = np.stack([speed_val, temporal_expanded_val, freq_expanded_val, x_random_val], axis=-1)  # [T_val, N, 3]\n",
    "    x_test = np.stack([speed_test, temporal_expanded_test, freq_expanded_test, x_random_test],\n",
    "                      axis=-1)  # [T_test, N, 3]\n",
    "\n",
    "    # 打印结果形状\n",
    "    print(\"特征处理后的训练集 shape:\", x_train.shape, \"OD形状\", od_train.shape)\n",
    "    print(\"特征处理后的验证集 shape:\", x_val.shape, \"OD形状\", od_val.shape)\n",
    "    print(\"特征处理后的测试集 shape:\", x_test.shape, \"OD形状\", od_test.shape)\n",
    "\n",
    "    # 归一化\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    train_3 = x_train[..., :3]\n",
    "    val_3 = x_val[..., :3]\n",
    "    test_3 = x_test[..., :3]\n",
    "\n",
    "    x_train[..., :3] = scaler.fit_transform(train_3.reshape(-1, 3)).reshape(train_3.shape)\n",
    "    x_val[..., :3] = scaler.transform(val_3.reshape(-1, 3)).reshape(val_3.shape)\n",
    "    x_test[..., :3] = scaler.transform(test_3.reshape(-1, 3)).reshape(test_3.shape)\n",
    "\n",
    "    train_data = x_train[...,0]\n",
    "    val_data = x_val[...,0]\n",
    "    test_data = x_test[...,0]\n",
    "    train_data = np.expand_dims(train_data, axis=-1)\n",
    "    val_data = np.expand_dims(val_data, axis=-1)\n",
    "    test_data = np.expand_dims(test_data, axis=-1)\n",
    "\n",
    "    print(train_data[0, 66:82, :])\n",
    "\n",
    "\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "    val_data = torch.tensor(val_data, dtype=torch.float32)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "    train_target = torch.tensor(od_train, dtype=torch.float32)\n",
    "    val_target = torch.tensor(od_val, dtype=torch.float32)\n",
    "    test_target = torch.tensor(od_test, dtype=torch.float32)\n",
    "\n",
    "    # 打印结果形状\n",
    "    print(\"归一化后的训练集 shape:\", train_data.shape, \"OD形状\", train_target.shape)\n",
    "    print(\"归一化后的验证集 shape:\", val_data.shape, \"OD形状\",val_target.shape)\n",
    "    print(\"归一化后的测试集 shape:\", test_data.shape, \"OD形状\", test_target.shape)\n",
    "\n",
    "\n",
    "    train_dataset = TensorDataset(train_data, train_target)\n",
    "    val_dataset = TensorDataset(val_data, val_target)\n",
    "    test_dataset = TensorDataset(test_data, test_target)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 测试\n",
    "def test_model(model, test_loader,lr=0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(\"../ANN/ckpt_仿真/best_model_feature1_25.1.14数据集版本_6.2873_1.0985_lr_0.004.pth\"))\n",
    "    # model.load_state_dict(torch.load(\"ckpt_仿真/best_model_feature1_25.1.14数据集版本_8.3251_1.1967_留档.pth\"))\n",
    "\n",
    "\n",
    "    #打印结构\n",
    "    # summary(model, input_size=(32, 110, 4))\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    rmse_total = 0\n",
    "    mae_total = 0\n",
    "    mape_total = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    N= 110\n",
    "\n",
    "    all_real_od = []\n",
    "    all_pred_od = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # 设置对角线掩码\n",
    "            mask = torch.ones_like(targets)\n",
    "            for i in range(N):\n",
    "                mask[:, i, i] = 0  # 对角线上的元素设为 0\n",
    "\n",
    "            print(f\"输入:{inputs.shape},标签:{targets.shape}\")\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # 计算 RMSE 和 MAE\n",
    "            rmse, mae, mape= calculate_rmse_mae(outputs * mask, targets)\n",
    "            rmse_total += rmse\n",
    "            mae_total += mae\n",
    "            mape_total += mape\n",
    "\n",
    "            all_real_od.append(targets.cpu().numpy())\n",
    "            all_pred_od.append(outputs.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    rmse_total /= len(test_loader)\n",
    "    mae_total /= len(test_loader)\n",
    "    mape_total /= len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse_total:.4f} Test MAE: {mae_total:.4f} Test MAPE: {mape_total:.4f}\")\n",
    "    \n",
    "    # 计算平均的OD矩阵\n",
    "    # 设置不使用科学计数法\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    all_real_od_t = np.concatenate(all_real_od, axis=0)\n",
    "    all_pred_od_t = np.concatenate(all_pred_od, axis=0)\n",
    "    all_real_od = np.mean(all_real_od_t, axis=0)\n",
    "    all_pred_od = np.mean(all_pred_od_t, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    # # print(\"-------------------不同时间步上---------------------\")\n",
    "    # for i in range(0, all_real_od_t.shape[0], 8):\n",
    "    #     print(\"-----真实值------\")\n",
    "    #     print(np.round(all_real_od_t[i, 60:68, 60:68].astype(np.float32)))  # 保留小数点后1位\n",
    "    #     print(\"-----预测值-----\")\n",
    "    #     print(np.round(all_pred_od_t[i, 60:68, 60:68].astype(np.float32)))  # 保留小数点后1位\n",
    "    # \n",
    "    print(\"-------------------平均时间步上---------------------\")\n",
    "    print(np.round(all_real_od[60:68, 60:68].astype(np.float32), 0).astype(int))  # 保留小数点后1位\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(np.round(all_pred_od[60:68, 60:68].astype(np.float32), 0).astype(int))  # 保留小数点后1位\n",
    "\n",
    "    vmin = min(all_pred_od.min(), all_real_od.min())\n",
    "    vmax = max(all_pred_od.max(), all_real_od.max())\n",
    "\n",
    "    true_max = all_real_od_t.max()\n",
    "    pred_max = all_pred_od_t.max()\n",
    "    print(f\"真实最大值{true_max},预测最大值，{pred_max}\")\n",
    "\n",
    "\n",
    "\n",
    "    colors = \"Blues\"  # Blues YlGn Greens YlGnBu\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # 绘制真实 OD 热力图\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(all_real_od, cmap=colors, cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average True OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "    # 绘制预测 OD 热力图\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(all_pred_od, cmap=colors, cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average Predicted OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "    # 调整布局并显示\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(\"ODE1.3_1.png\")\n",
    "\n",
    "\n",
    "    start_id = 30  # 35\n",
    "    end_id = 70  # 68\n",
    "    vmin = min(all_pred_od[start_id:end_id, start_id:end_id].min(), all_real_od[start_id:end_id, start_id:end_id].min())\n",
    "    vmax = max(all_pred_od[start_id:end_id, start_id:end_id].max(), all_real_od[start_id:end_id, start_id:end_id].max())\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    # 绘制真实 OD 热力图\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(all_real_od[start_id:end_id, start_id:end_id], cmap=colors, cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average True OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "    # 绘制预测 OD 热力图\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(all_pred_od[start_id:end_id, start_id:end_id], cmap=colors, cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average Predicted OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "   #  调整布局并显示\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"ODE1.3_2.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # 绘制散点图\n",
    "    all_real_od_flat = all_real_od_t.flatten()\n",
    "    all_pred_od_flat = all_pred_od_t.flatten()\n",
    "\n",
    "    plt.figure(figsize=(9, 8))\n",
    "    plt.scatter(all_real_od_flat, all_pred_od_flat, alpha=0.5)\n",
    "\n",
    "    # 设置坐标轴范围从 0 开始\n",
    "    max_val = np.max([np.max(all_real_od_flat), np.max(all_pred_od_flat)])\n",
    "    plt.xlim(0, max_val)\n",
    "    plt.ylim(0, max_val)\n",
    "\n",
    "    # 绘制对角线\n",
    "    lims = [0, max_val]\n",
    "    plt.plot(lims, lims, color='red', linewidth=2, linestyle='-', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('True OD')\n",
    "    plt.ylabel('Pred OD')\n",
    "    plt.title('The relationship between real and predicted OD')\n",
    "    # plt.savefig('ODE1.3_3.png')\n",
    "    plt.show()\n",
    "\n",
    "# 主程序\n",
    "def main():\n",
    "\n",
    "    lr_list = [0.004]\n",
    "\n",
    "    # 遍历学习率列表\n",
    "    for lr in lr_list:\n",
    "        print(f\"当前学习率: {lr}\")\n",
    "\n",
    "        train_loader, val_loader, test_loader = load_data()\n",
    "\n",
    "        model = ODModel(N=110, F=1)\n",
    "\n",
    "        # 训练模型\n",
    "        # train_model(model, train_loader, val_loader, epochs=2000, patience=20, learning_rate=lr, load=0)\n",
    "\n",
    "        # 测试模型\n",
    "        test_model(model, test_loader, lr=lr)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "982905752ceb706",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 206] 文件名或扩展名太长。: 'E:\\\\StudyFiles\\\\SoftWareFiles\\\\A_MUC\\\\IDE\\\\Anaconda\\\\envs\\\\AAD1\\\\lib\\\\site-packages\\\\torch\\\\lib'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n",
      "File \u001B[1;32mE:\\StudyFiles\\SoftWareFiles\\A_MUC\\IDE\\Anaconda\\envs\\AAD1\\lib\\site-packages\\torch\\__init__.py:100\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dll_path \u001B[38;5;129;01min\u001B[39;00m dll_paths:\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mversion_info \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m8\u001B[39m):\n\u001B[1;32m--> 100\u001B[0m         \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_dll_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdll_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m with_load_library_flags:\n\u001B[0;32m    102\u001B[0m         res \u001B[38;5;241m=\u001B[39m kernel32\u001B[38;5;241m.\u001B[39mAddDllDirectory(dll_path)\n",
      "File \u001B[1;32mE:\\StudyFiles\\SoftWareFiles\\A_MUC\\IDE\\Anaconda\\envs\\AAD1\\lib\\os.py:1105\u001B[0m, in \u001B[0;36madd_dll_directory\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m   1095\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Add a path to the DLL search path.\u001B[39;00m\n\u001B[0;32m   1096\u001B[0m \n\u001B[0;32m   1097\u001B[0m \u001B[38;5;124;03mThis search path is used when resolving dependencies for imported\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;124;03musing it in a with statement.\u001B[39;00m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnt\u001B[39;00m\n\u001B[1;32m-> 1105\u001B[0m cookie \u001B[38;5;241m=\u001B[39m \u001B[43mnt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_dll_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _AddedDllDirectory(\n\u001B[0;32m   1107\u001B[0m     path,\n\u001B[0;32m   1108\u001B[0m     cookie,\n\u001B[0;32m   1109\u001B[0m     nt\u001B[38;5;241m.\u001B[39m_remove_dll_directory\n\u001B[0;32m   1110\u001B[0m )\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 206] 文件名或扩展名太长。: 'E:\\\\StudyFiles\\\\SoftWareFiles\\\\A_MUC\\\\IDE\\\\Anaconda\\\\envs\\\\AAD1\\\\lib\\\\site-packages\\\\torch\\\\lib'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3120b327416c4303"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
