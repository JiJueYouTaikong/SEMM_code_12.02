{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-26T10:39:40.864926Z"
    }
   },
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 数据准备\n",
    "def normalize_data(data):\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    return (data - min_val) / (max_val - min_val), min_val, max_val\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "# 定义新模型\n",
    "class ODModel(nn.Module):\n",
    "    def __init__(self, N, temp, freq):\n",
    "        super(ODModel, self).__init__()\n",
    "\n",
    "        self.N = N  # 区域数\n",
    "        self.temp = temp  # 频域差距 [N,]\n",
    "        self.freq = freq  # 频域差距 [N,]\n",
    "        n1 = 128  # 隐藏层神经元1\n",
    "        n2 = 64  # 隐藏层神经元2\n",
    "\n",
    "        # 权重[α1,α2,α3] --> shape [N, 3]\n",
    "        self.weights = nn.Parameter(torch.randn(N, 3))\n",
    "\n",
    "        # MLP层 input [B,N] --> output [B,N*N]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(N, n1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n1, n2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n2, N * N)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        前向传播\n",
    "        :param x: Batch输入Speed --> [B,N]\n",
    "        :return: Batch输出OD     --> [B,N,N]\n",
    "        '''\n",
    "        B,N = x.shape  # [B,N]\n",
    "\n",
    "        x_temp = np.tile(self.temp, (B, 1))  # [B,N]\n",
    "        x_freq = np.tile(self.freq, (B, 1))  # [B,N]\n",
    "\n",
    "        x_random = np.random.normal(loc=0.05, scale=0.01, size=(B, N)).astype(float)  # [B,N]\n",
    "        x_random = np.clip(x_random, 0, 0.1)\n",
    "\n",
    "        # print(\"----------------------------\")\n",
    "        # print(f\"速度：{x[0, 66]}\\n三个Δ：\\n{x_temp[0, 66]}\"\n",
    "        #       f\"\\n{x_freq[0, 66]}\\n{x_random[0, 66]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x_temp_freq_rand = np.stack([x_temp, x_freq, x_random], axis=-1)  # [B,N,3]\n",
    "        tensor_delta_x = torch.tensor(x_temp_freq_rand,dtype=torch.float)\n",
    "\n",
    "        # print(f\"weight:{self.weights[66]}\")\n",
    "\n",
    "        # 等式计算 Production [B, N] = speed[B,N] + sum([B,N,3] * [1,N,3]) = speed[B,N]+sum([B,N,3]) = [B,N]\n",
    "\n",
    "        self.weights = self.weights.to(x.device)\n",
    "        weighted_sum = x + torch.sum(tensor_delta_x * self.weights.unsqueeze(0), dim=2)\n",
    "\n",
    "        # print(f\"预测的production:{weighted_sum[0,66]}\")\n",
    "\n",
    "        # 输入到 MLP 网络中\n",
    "        od_matrix_flat = self.mlp(weighted_sum)  # [B,N] --> [B, N * N]\n",
    "        # reshape 最终输出\n",
    "        od_matrix = od_matrix_flat.view(B, N, N)  # [B, N, N]\n",
    "        # pro = torch.sum(od_matrix, dim=-1)\n",
    "        # print(f\"production:{pro[0,66]}\")\n",
    "\n",
    "        return od_matrix\n",
    "\n",
    "\n",
    "# 保存日志文件\n",
    "log_filename = f\"log/v1_2/training_log_25.1.14版本_{time.strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "with open(log_filename, 'w') as log_file:\n",
    "    log_file.write(\"Epoch, Train Loss, Validation Loss\\n\")\n",
    "\n",
    "\n",
    "# 训练过程\n",
    "def train_model(model, train_loader, val_loader, epochs=100, patience=10, learning_rate=0.001, load=0):\n",
    "    if load == 1:\n",
    "        model.load_state_dict(torch.load('ckpt/v1_2/best_model_feature4_25.1.14数据集版本.pth'))\n",
    "        print(f\"best model loaded\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 学习率调度器\n",
    "    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    N = 110\n",
    "\n",
    "    # 训练过程\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # 计算训练集的平均损失\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # 验证过程\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # 计算验证集的平均损失\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # 保存每一轮的损失，并打印\n",
    "        with open(log_filename, 'a') as log_file:\n",
    "            log_file.write(f\"{epoch + 1}, {train_loss:.4f}, {val_loss:.4f}\\n\")\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "        # ({optimizer.param_groups[0]['lr']:.6f})\n",
    "\n",
    "        # 提前停止机制\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # 保存最佳模型\n",
    "            torch.save(model.state_dict(), \"ckpt/v1_2/best_model_feature4_25.1.14数据集版本.pth\")\n",
    "            print(f\"best saved at epoch{epoch + 1},best：{best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # 绘制训练过程中的损失曲线\n",
    "    with open(log_filename, 'r') as log_file:\n",
    "        epochs_list, train_loss_list, val_loss_list = [], [], []\n",
    "        for line in log_file.readlines()[1:]:\n",
    "            epoch, train_loss, val_loss = line.strip().split(\", \")\n",
    "            epochs_list.append(int(epoch))\n",
    "            train_loss_list.append(float(train_loss))\n",
    "            val_loss_list.append(float(val_loss))\n",
    "\n",
    "    plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
    "    plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'train and validation loss with lr={learning_rate}')\n",
    "    plt.savefig(\"loss_curve.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "def calculate_rmse_mae(predictions, targets):\n",
    "    mse = torch.mean((predictions - targets) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(predictions - targets))\n",
    "    return rmse.item(), mae.item()\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 设置所有GPU的随机种子\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "def load_data():\n",
    "    set_seed(42)\n",
    "\n",
    "    # 加载数据\n",
    "    data = np.load('data/武汉速度数据集_1KM_110区域_25.1.14.npy')  # 形状 [T, N, 2]\n",
    "    speed = data[:, :, 0]  # 平均速度 [T, N]\n",
    "\n",
    "    od = np.load('data/武汉OD数据集_1KM_110区域_过滤cnt_对角线0_25.1.14.npy')  # 形状 [T, N, N]\n",
    "\n",
    "    # 获取数据长度 T\n",
    "    T, N = speed.shape\n",
    "\n",
    "    # 按顺序划分数据\n",
    "    train_size = int(T * 0.6)\n",
    "    val_size = int(T * 0.2)\n",
    "\n",
    "    # 顺序划分索引\n",
    "    train_indices = np.arange(0, train_size)\n",
    "    val_indices = np.arange(train_size, train_size + val_size)\n",
    "    test_indices = np.arange(train_size + val_size, T)\n",
    "\n",
    "    # 按索引划分数据\n",
    "    speed_train, speed_val, speed_test = speed[train_indices], speed[val_indices], speed[test_indices]\n",
    "    od_train, od_val, od_test = od[train_indices], od[val_indices], od[test_indices]\n",
    "    # x_random_train, x_random_val, x_random_test = x_random[train_indices], x_random[val_indices], x_random[test_indices]\n",
    "\n",
    "    # 输出划分后的数据形状\n",
    "    print(\"6:2:2顺序划分的训练集Speed\", speed_train.shape, \"OD\", od_train.shape)\n",
    "    print(\"6:2:2顺序划分的验证集Speed\", speed_val.shape, \"OD\", od_val.shape)\n",
    "    print(\"6:2:2顺序划分的测试集Speed\", speed_test.shape, \"OD\", od_test.shape)\n",
    "\n",
    "    # 在训练集上计算 OD 出发总量\n",
    "    od_train_departures = np.sum(od_train, axis=-1)  # 形状 [T_train, N]\n",
    "\n",
    "    # 计算每个区域在 T_train 时间步的平均速度和平均出发总量\n",
    "    mean_speed = np.mean(speed_train, axis=0)  # 每个区域的平均速度 [N,]\n",
    "    mean_departures = np.mean(od_train_departures, axis=0)  # 每个区域的平均出发总量 [N,]\n",
    "    # 计算平均速度和平均出发总量的差值\n",
    "    temporal = (mean_departures - mean_speed).astype(float)  # [N,]\n",
    "\n",
    "    # freq\n",
    "    speed_freq = np.load('data/速度的周期状态_对应25.1.14的速度数据集.npy')  # 形状 [N,]\n",
    "    od_freq = np.load('data/OD的周期状态_对应25.1.14的OD数据集.npy')  # 形状 [N,]\n",
    "\n",
    "    freq = (od_freq - speed_freq).astype(float)\n",
    "\n",
    "    # 归一化\n",
    "    scaler = MinMaxScaler()\n",
    "    train_data = scaler.fit_transform(speed_train.reshape(-1, 1)).reshape(speed_train.shape)\n",
    "    val_data = scaler.transform(speed_val.reshape(-1, 1)).reshape(speed_val.shape)\n",
    "    test_data = scaler.transform(speed_test.reshape(-1, 1)).reshape(speed_test.shape)\n",
    "\n",
    "    print(f\"train_data: {train_data[:10, 66]}\")\n",
    "\n",
    "\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "    val_data = torch.tensor(val_data, dtype=torch.float32)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "    train_target = torch.tensor(od_train, dtype=torch.float32)\n",
    "    val_target = torch.tensor(od_val, dtype=torch.float32)\n",
    "    test_target = torch.tensor(od_test, dtype=torch.float32)\n",
    "\n",
    "    # 打印结果形状\n",
    "    print(\"归一化后的训练集 shape:\", train_data.shape, \"OD形状\", train_target.shape)\n",
    "    print(\"归一化后的验证集 shape:\", val_data.shape, \"OD形状\", val_target.shape)\n",
    "    print(\"归一化后的测试集 shape:\", test_data.shape, \"OD形状\", test_target.shape)\n",
    "\n",
    "    train_dataset = TensorDataset(train_data, train_target)\n",
    "    val_dataset = TensorDataset(val_data, val_target)\n",
    "    test_dataset = TensorDataset(test_data, test_target)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x_temp = scaler.fit_transform(temporal.reshape(-1, 1))\n",
    "    scaler = MinMaxScaler()\n",
    "    x_freq = scaler.fit_transform(freq.reshape(-1, 1))\n",
    "    x_temp = np.squeeze(x_temp, axis=-1)\n",
    "    x_freq = np.squeeze(x_freq, axis=-1)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, x_temp, x_freq\n",
    "\n",
    "\n",
    "# 测试\n",
    "def test_model(model, test_loader, lr: float):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(\"ckpt/v1_2/best_model_feature4_25.1.14数据集版本.pth\"))\n",
    "\n",
    "    # 打印结构\n",
    "    # summary(model, input_size=(32, 110, 4))\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    rmse_total = 0\n",
    "    mae_total = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    N = 110\n",
    "\n",
    "    all_real_od = []\n",
    "    all_pred_od = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # 设置对角线掩码\n",
    "            mask = torch.ones_like(targets)\n",
    "            for i in range(N):\n",
    "                mask[:, i, i] = 0  # 对角线上的元素设为 0\n",
    "\n",
    "            print(f\"输入:{inputs.shape},标签:{targets.shape}\")\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # 计算 RMSE 和 MAE\n",
    "            rmse, mae = calculate_rmse_mae(outputs * mask, targets)\n",
    "            rmse_total += rmse\n",
    "            mae_total += mae\n",
    "\n",
    "            all_real_od.append(targets.cpu().numpy())\n",
    "            all_pred_od.append(outputs.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    rmse_total /= len(test_loader)\n",
    "    mae_total /= len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse_total:.4f} Test MAE: {mae_total:.4f}\")\n",
    "    with open(log_filename, 'a') as log_file:\n",
    "        log_file.write(f\"Test RMSE: {rmse_total:.4f}, MAE: {mae_total:.4f}\\n\")\n",
    "    torch.save(model.state_dict(),\n",
    "               f\"ckpt/v1_2/best_model_feature4_25.1.14数据集版本_{test_loss:.4f}_{rmse_total:.4f}_{mae_total:.4f}_lr_{lr}.pth\")\n",
    "\n",
    "    # 计算平均的OD矩阵\n",
    "    # 设置不使用科学计数法\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    all_real_od_t = np.concatenate(all_real_od, axis=0)\n",
    "    all_pred_od_t = np.concatenate(all_pred_od, axis=0)\n",
    "    all_real_od = np.mean(all_real_od_t, axis=0)\n",
    "    all_pred_od = np.mean(all_pred_od_t, axis=0)\n",
    "\n",
    "    print(\"-------------------不同时间步上---------------------\")\n",
    "    for i in range(0, all_real_od_t.shape[0], 8):\n",
    "        print(\"-----真实值------\")\n",
    "        print(np.round(all_real_od_t[i, 60:68, 60:68].astype(np.float32)))  # 保留小数点后1位\n",
    "        print(\"-----预测值-----\")\n",
    "        print(np.round(all_pred_od_t[i, 60:68, 60:68].astype(np.float32)))  # 保留小数点后1位\n",
    "\n",
    "    print(\"-------------------平均时间步上---------------------\")\n",
    "    print(np.round(all_real_od[60:68, 60:68].astype(np.float32), 0).astype(int))  # 保留小数点后1位\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(np.round(all_pred_od[60:68, 60:68].astype(np.float32), 0).astype(int))  # 保留小数点后1位\n",
    "\n",
    "    vmin = min(all_pred_od.min(), all_real_od.min())\n",
    "    vmax = max(all_pred_od.max(), all_real_od.max())\n",
    "    \n",
    "    true_max = all_real_od_t.max()\n",
    "    pred_max = all_pred_od_t.max()\n",
    "    print(f\"真实最大值{true_max},预测最大值，{pred_max}\")\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # 绘制真实 OD 热力图\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(all_real_od, cmap=\"Blues\", cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average True OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "    # 绘制预测 OD 热力图\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(all_pred_od, cmap=\"Blues\", cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average Predicted OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "    # 调整布局并显示\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # 绘制真实 OD 热力图\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(all_real_od[35:68, 35:68], cmap=\"Blues\", cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average True OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "    # 绘制预测 OD 热力图\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(all_pred_od[35:68, 35:68], cmap=\"Blues\", cbar=True, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Average Predicted OD Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"Destination Zones\")\n",
    "    plt.ylabel(\"Origin Zones\")\n",
    "\n",
    "    # 调整布局并显示\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse_total:.4f} Test MAE: {mae_total:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# 主程序\n",
    "def main():\n",
    "    train_loader, val_loader, test_loader, temp, freq = load_data()\n",
    "    model = ODModel(N=110,temp=temp,freq=freq)  # N为区域数\n",
    "\n",
    "   \n",
    "    lr = 0.01  # best lr = 0.01\n",
    "    train_model(model, train_loader, val_loader, epochs=2000, patience=20, learning_rate=lr, load=0)\n",
    "\n",
    "    # 测试模型\n",
    "    test_model(model, test_loader, lr=lr)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "44194fb423d1765b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
