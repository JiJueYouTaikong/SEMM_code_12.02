2025-02-17 13:32:39,343 - -----------------------Starting training-------------------------
2025-02-17 13:32:39,343 - learning rate: 0.05
2025-02-17 13:32:39,904 - Epoch 1, Training Loss: 64559.05, Validation Loss: 224.62
2025-02-17 13:32:40,529 - Epoch 2, Training Loss: 450.21, Validation Loss: 184.37
2025-02-17 13:32:41,127 - Epoch 3, Training Loss: 127.24, Validation Loss: 137.87
2025-02-17 13:32:41,785 - Epoch 4, Training Loss: 101.35, Validation Loss: 110.24
2025-02-17 13:32:42,375 - Epoch 5, Training Loss: 96.93, Validation Loss: 84.79
2025-02-17 13:32:42,975 - Epoch 6, Training Loss: 80.44, Validation Loss: 76.77
2025-02-17 13:32:43,636 - Epoch 7, Training Loss: 75.72, Validation Loss: 85.12
2025-02-17 13:32:44,166 - Epoch 8, Training Loss: 71.19, Validation Loss: 90.24
2025-02-17 13:32:44,782 - Epoch 9, Training Loss: 78.93, Validation Loss: 69.26
2025-02-17 13:32:45,426 - Epoch 10, Training Loss: 81.59, Validation Loss: 62.99
2025-02-17 13:32:46,020 - Epoch 11, Training Loss: 66.21, Validation Loss: 65.44
2025-02-17 13:32:46,591 - Epoch 12, Training Loss: 68.19, Validation Loss: 71.51
2025-02-17 13:32:47,133 - Epoch 13, Training Loss: 77.00, Validation Loss: 67.64
2025-02-17 13:32:47,716 - Epoch 14, Training Loss: 76.29, Validation Loss: 67.68
2025-02-17 13:32:48,241 - Epoch 15, Training Loss: 70.80, Validation Loss: 72.71
2025-02-17 13:32:48,817 - Epoch 16, Training Loss: 71.07, Validation Loss: 79.36
2025-02-17 13:32:49,341 - Epoch 17, Training Loss: 74.51, Validation Loss: 61.64
2025-02-17 13:32:49,941 - Epoch 18, Training Loss: 71.02, Validation Loss: 65.87
2025-02-17 13:32:50,506 - Epoch 19, Training Loss: 77.17, Validation Loss: 73.65
2025-02-17 13:32:51,052 - Epoch 20, Training Loss: 69.85, Validation Loss: 60.92
2025-02-17 13:32:51,690 - Epoch 21, Training Loss: 72.78, Validation Loss: 65.40
2025-02-17 13:32:52,225 - Epoch 22, Training Loss: 78.20, Validation Loss: 66.46
2025-02-17 13:32:52,793 - Epoch 23, Training Loss: 77.33, Validation Loss: 67.38
2025-02-17 13:32:53,323 - Epoch 24, Training Loss: 78.77, Validation Loss: 93.12
2025-02-17 13:32:53,890 - Epoch 25, Training Loss: 80.88, Validation Loss: 60.00
2025-02-17 13:32:54,520 - Epoch 26, Training Loss: 88.32, Validation Loss: 68.12
2025-02-17 13:32:55,057 - Epoch 27, Training Loss: 76.40, Validation Loss: 93.00
2025-02-17 13:32:55,618 - Epoch 28, Training Loss: 72.22, Validation Loss: 62.43
2025-02-17 13:32:56,161 - Epoch 29, Training Loss: 74.28, Validation Loss: 60.14
2025-02-17 13:32:56,732 - Epoch 30, Training Loss: 81.65, Validation Loss: 61.92
2025-02-17 13:32:57,266 - Epoch 31, Training Loss: 75.55, Validation Loss: 64.24
2025-02-17 13:32:57,852 - Epoch 32, Training Loss: 74.85, Validation Loss: 80.28
2025-02-17 13:32:58,397 - Epoch 33, Training Loss: 76.63, Validation Loss: 89.76
2025-02-17 13:32:58,950 - Epoch 34, Training Loss: 76.33, Validation Loss: 60.35
2025-02-17 13:32:59,517 - Epoch 35, Training Loss: 74.00, Validation Loss: 59.86
2025-02-17 13:33:00,120 - Epoch 36, Training Loss: 77.35, Validation Loss: 75.81
2025-02-17 13:33:00,715 - Epoch 37, Training Loss: 85.57, Validation Loss: 103.19
2025-02-17 13:33:01,232 - Epoch 38, Training Loss: 86.89, Validation Loss: 65.38
2025-02-17 13:33:01,821 - Epoch 39, Training Loss: 72.68, Validation Loss: 61.24
2025-02-17 13:33:02,352 - Epoch 40, Training Loss: 69.46, Validation Loss: 72.48
2025-02-17 13:33:02,914 - Epoch 41, Training Loss: 76.42, Validation Loss: 64.05
2025-02-17 13:33:03,467 - Epoch 42, Training Loss: 78.29, Validation Loss: 59.32
2025-02-17 13:33:04,055 - Epoch 43, Training Loss: 71.56, Validation Loss: 69.56
2025-02-17 13:33:04,655 - Epoch 44, Training Loss: 65.83, Validation Loss: 69.60
2025-02-17 13:33:05,195 - Epoch 45, Training Loss: 71.22, Validation Loss: 64.29
2025-02-17 13:33:05,769 - Epoch 46, Training Loss: 75.66, Validation Loss: 63.19
2025-02-17 13:33:06,302 - Epoch 47, Training Loss: 68.19, Validation Loss: 67.61
2025-02-17 13:33:06,880 - Epoch 48, Training Loss: 74.44, Validation Loss: 59.03
2025-02-17 13:33:07,487 - Epoch 49, Training Loss: 73.40, Validation Loss: 70.82
2025-02-17 13:33:08,034 - Epoch 50, Training Loss: 85.26, Validation Loss: 85.17
2025-02-17 13:33:08,616 - Epoch 51, Training Loss: 75.21, Validation Loss: 60.20
2025-02-17 13:33:09,138 - Epoch 52, Training Loss: 72.66, Validation Loss: 60.42
2025-02-17 13:33:09,738 - Epoch 53, Training Loss: 73.10, Validation Loss: 77.40
2025-02-17 13:33:10,270 - Epoch 54, Training Loss: 69.43, Validation Loss: 92.04
2025-02-17 13:33:10,837 - Epoch 55, Training Loss: 72.72, Validation Loss: 71.46
2025-02-17 13:33:11,390 - Epoch 56, Training Loss: 70.98, Validation Loss: 60.24
2025-02-17 13:33:11,955 - Epoch 57, Training Loss: 68.50, Validation Loss: 64.57
2025-02-17 13:33:12,535 - Epoch 58, Training Loss: 82.17, Validation Loss: 72.77
2025-02-17 13:33:12,535 - Early stopping at epoch 58 due to no improvement in validation loss.
2025-02-17 13:33:12,826 - learning rate: 0.05
2025-02-17 13:33:12,826 - Test RMSE: 7.582245826721191, Test MAE: 1.3832574486732483
2025-02-17 13:33:48,299 - -----------------------Starting training-------------------------
2025-02-17 13:33:48,299 - learning rate: 0.1
2025-02-17 13:33:49,692 - Epoch 1, Training Loss: 4184211.22, Validation Loss: 230.69
2025-02-17 13:33:50,444 - Epoch 2, Training Loss: 3695.34, Validation Loss: 431.08
2025-02-17 13:33:51,086 - Epoch 3, Training Loss: 200.51, Validation Loss: 139.02
2025-02-17 13:33:51,734 - Epoch 4, Training Loss: 262.58, Validation Loss: 178.72
2025-02-17 13:33:52,285 - Epoch 5, Training Loss: 166.90, Validation Loss: 212.09
2025-02-17 13:33:53,201 - Epoch 6, Training Loss: 157.22, Validation Loss: 172.35
2025-02-17 13:33:54,211 - Epoch 7, Training Loss: 111.16, Validation Loss: 92.89
2025-02-17 13:33:55,124 - Epoch 8, Training Loss: 89.15, Validation Loss: 81.59
2025-02-17 13:33:55,913 - Epoch 9, Training Loss: 82.84, Validation Loss: 102.08
2025-02-17 13:33:57,607 - Epoch 10, Training Loss: 93.52, Validation Loss: 70.88
2025-02-17 13:33:58,322 - Epoch 11, Training Loss: 72.73, Validation Loss: 65.68
2025-02-17 13:33:59,049 - Epoch 12, Training Loss: 70.85, Validation Loss: 84.23
2025-02-17 13:33:59,769 - Epoch 13, Training Loss: 80.69, Validation Loss: 76.46
2025-02-17 13:34:00,417 - Epoch 14, Training Loss: 76.86, Validation Loss: 62.53
2025-02-17 13:34:01,046 - Epoch 15, Training Loss: 71.64, Validation Loss: 72.19
2025-02-17 13:34:01,650 - Epoch 16, Training Loss: 70.77, Validation Loss: 88.05
2025-02-17 13:34:02,264 - Epoch 17, Training Loss: 77.10, Validation Loss: 62.14
2025-02-17 13:34:02,905 - Epoch 18, Training Loss: 73.00, Validation Loss: 61.08
2025-02-17 13:34:03,581 - Epoch 19, Training Loss: 76.27, Validation Loss: 78.04
2025-02-17 13:34:04,192 - Epoch 20, Training Loss: 71.64, Validation Loss: 62.47
2025-02-17 13:34:04,804 - Epoch 21, Training Loss: 72.97, Validation Loss: 59.28
2025-02-17 13:34:05,473 - Epoch 22, Training Loss: 77.53, Validation Loss: 69.87
2025-02-17 13:34:06,368 - Epoch 23, Training Loss: 72.89, Validation Loss: 62.78
2025-02-17 13:34:07,997 - Epoch 24, Training Loss: 71.65, Validation Loss: 77.68
2025-02-17 13:34:08,702 - Epoch 25, Training Loss: 76.69, Validation Loss: 58.07
2025-02-17 13:34:09,357 - Epoch 26, Training Loss: 83.66, Validation Loss: 62.27
2025-02-17 13:34:09,952 - Epoch 27, Training Loss: 72.52, Validation Loss: 85.95
2025-02-17 13:34:10,543 - Epoch 28, Training Loss: 69.86, Validation Loss: 61.75
2025-02-17 13:34:11,097 - Epoch 29, Training Loss: 72.64, Validation Loss: 59.47
2025-02-17 13:34:11,721 - Epoch 30, Training Loss: 80.53, Validation Loss: 62.18
2025-02-17 13:34:12,283 - Epoch 31, Training Loss: 75.49, Validation Loss: 65.40
2025-02-17 13:34:12,876 - Epoch 32, Training Loss: 74.74, Validation Loss: 77.56
2025-02-17 13:34:13,486 - Epoch 33, Training Loss: 74.90, Validation Loss: 87.83
2025-02-17 13:34:14,050 - Epoch 34, Training Loss: 74.73, Validation Loss: 58.11
2025-02-17 13:34:14,648 - Epoch 35, Training Loss: 73.46, Validation Loss: 58.95
2025-02-17 13:34:14,649 - Early stopping at epoch 35 due to no improvement in validation loss.
2025-02-17 13:34:14,956 - learning rate: 0.1
2025-02-17 13:34:14,957 - Test RMSE: 7.743513107299805, Test MAE: 1.6202942728996277
2025-02-24 15:09:36,114 - -----------------------Starting training-------------------------
2025-02-24 15:09:36,114 - learning rate: 0.5
2025-02-24 15:09:36,326 - Epoch 1, Training Loss: 878.12, Validation Loss: 1347.19
2025-02-24 15:09:36,548 - Epoch 2, Training Loss: 631.79, Validation Loss: 591.36
2025-02-24 15:09:36,769 - Epoch 3, Training Loss: 496.21, Validation Loss: 152.56
2025-02-24 15:09:36,994 - Epoch 4, Training Loss: 292.59, Validation Loss: 205.63
2025-02-24 15:09:37,190 - Epoch 5, Training Loss: 178.77, Validation Loss: 237.81
2025-02-24 15:09:37,392 - Epoch 6, Training Loss: 162.34, Validation Loss: 125.46
2025-02-24 15:09:37,632 - Epoch 7, Training Loss: 144.70, Validation Loss: 92.86
2025-02-24 15:09:37,859 - Epoch 8, Training Loss: 103.34, Validation Loss: 106.53
2025-02-24 15:09:38,075 - Epoch 9, Training Loss: 92.39, Validation Loss: 91.77
2025-02-24 15:09:38,306 - Epoch 10, Training Loss: 95.56, Validation Loss: 77.75
2025-02-24 15:09:38,529 - Epoch 11, Training Loss: 88.96, Validation Loss: 73.48
2025-02-24 15:09:38,757 - Epoch 12, Training Loss: 81.91, Validation Loss: 71.00
2025-02-24 15:09:38,979 - Epoch 13, Training Loss: 76.64, Validation Loss: 74.83
2025-02-24 15:09:39,180 - Epoch 14, Training Loss: 72.79, Validation Loss: 75.16
2025-02-24 15:09:39,386 - Epoch 15, Training Loss: 82.38, Validation Loss: 71.53
2025-02-24 15:09:39,581 - Epoch 16, Training Loss: 75.44, Validation Loss: 66.84
2025-02-24 15:09:39,805 - Epoch 17, Training Loss: 92.64, Validation Loss: 67.79
2025-02-24 15:09:40,001 - Epoch 18, Training Loss: 88.73, Validation Loss: 64.34
2025-02-24 15:09:40,240 - Epoch 19, Training Loss: 73.63, Validation Loss: 75.13
2025-02-24 15:09:40,448 - Epoch 20, Training Loss: 75.69, Validation Loss: 71.03
2025-02-24 15:09:40,652 - Epoch 21, Training Loss: 72.82, Validation Loss: 65.45
2025-02-24 15:09:40,858 - Epoch 22, Training Loss: 75.02, Validation Loss: 64.34
2025-02-24 15:09:41,056 - Epoch 23, Training Loss: 70.07, Validation Loss: 67.53
2025-02-24 15:09:41,265 - Epoch 24, Training Loss: 75.15, Validation Loss: 67.17
2025-02-24 15:09:41,464 - Epoch 25, Training Loss: 71.76, Validation Loss: 67.57
2025-02-24 15:09:41,668 - Epoch 26, Training Loss: 80.17, Validation Loss: 66.50
2025-02-24 15:09:41,872 - Epoch 27, Training Loss: 69.15, Validation Loss: 70.93
2025-02-24 15:09:42,075 - Epoch 28, Training Loss: 72.99, Validation Loss: 67.99
2025-02-24 15:09:42,277 - Epoch 29, Training Loss: 74.75, Validation Loss: 62.33
2025-02-24 15:09:42,498 - Epoch 30, Training Loss: 73.55, Validation Loss: 62.40
2025-02-24 15:09:42,697 - Epoch 31, Training Loss: 72.27, Validation Loss: 65.46
2025-02-24 15:09:42,896 - Epoch 32, Training Loss: 75.33, Validation Loss: 63.87
2025-02-24 15:09:43,095 - Epoch 33, Training Loss: 72.59, Validation Loss: 68.55
2025-02-24 15:09:43,299 - Epoch 34, Training Loss: 73.17, Validation Loss: 69.01
2025-02-24 15:09:43,499 - Epoch 35, Training Loss: 71.01, Validation Loss: 70.18
2025-02-24 15:09:43,703 - Epoch 36, Training Loss: 73.25, Validation Loss: 66.60
2025-02-24 15:09:43,900 - Epoch 37, Training Loss: 79.38, Validation Loss: 65.42
2025-02-24 15:09:44,101 - Epoch 38, Training Loss: 76.80, Validation Loss: 66.09
2025-02-24 15:09:44,295 - Epoch 39, Training Loss: 66.82, Validation Loss: 67.09
2025-02-24 15:09:44,506 - Epoch 40, Training Loss: 71.91, Validation Loss: 70.20
2025-02-24 15:09:44,706 - Epoch 41, Training Loss: 71.25, Validation Loss: 65.66
2025-02-24 15:09:44,912 - Epoch 42, Training Loss: 73.51, Validation Loss: 61.72
2025-02-24 15:09:45,133 - Epoch 43, Training Loss: 72.65, Validation Loss: 64.18
2025-02-24 15:09:45,335 - Epoch 44, Training Loss: 78.77, Validation Loss: 64.47
2025-02-24 15:09:45,534 - Epoch 45, Training Loss: 68.20, Validation Loss: 68.22
2025-02-24 15:09:45,737 - Epoch 46, Training Loss: 79.62, Validation Loss: 67.83
2025-02-24 15:09:45,941 - Epoch 47, Training Loss: 76.45, Validation Loss: 68.79
2025-02-24 15:09:46,141 - Epoch 48, Training Loss: 73.63, Validation Loss: 72.33
2025-02-24 15:09:46,343 - Epoch 49, Training Loss: 83.45, Validation Loss: 70.34
2025-02-24 15:09:46,555 - Epoch 50, Training Loss: 75.09, Validation Loss: 69.14
2025-02-24 15:09:46,750 - Epoch 51, Training Loss: 82.24, Validation Loss: 70.33
2025-02-24 15:09:46,949 - Epoch 52, Training Loss: 74.27, Validation Loss: 79.13
2025-02-24 15:09:47,152 - Epoch 53, Training Loss: 81.38, Validation Loss: 68.59
2025-02-24 15:09:47,349 - Epoch 54, Training Loss: 83.38, Validation Loss: 67.66
2025-02-24 15:09:47,552 - Epoch 55, Training Loss: 81.10, Validation Loss: 73.52
2025-02-24 15:09:47,753 - Epoch 56, Training Loss: 77.03, Validation Loss: 72.64
2025-02-24 15:09:47,953 - Epoch 57, Training Loss: 69.59, Validation Loss: 73.63
2025-02-24 15:09:48,152 - Epoch 58, Training Loss: 80.08, Validation Loss: 64.64
2025-02-24 15:09:48,356 - Epoch 59, Training Loss: 78.81, Validation Loss: 63.33
2025-02-24 15:09:48,557 - Epoch 60, Training Loss: 82.63, Validation Loss: 66.42
2025-02-24 15:09:48,758 - Epoch 61, Training Loss: 75.18, Validation Loss: 66.17
2025-02-24 15:09:48,959 - Epoch 62, Training Loss: 77.54, Validation Loss: 69.10
2025-02-24 15:09:48,959 - Early stopping at epoch 62 due to no improvement in validation loss.
2025-02-24 15:09:49,185 - learning rate: 0.5
2025-02-24 15:09:49,185 - Test RMSE: 7.7761077880859375, Test MAE: 1.350328803062439
2025-02-24 15:21:07,354 - -----------------------Starting training-------------------------
2025-02-24 15:21:07,354 - learning rate: 0.5
2025-02-24 15:21:07,557 - Epoch 1, Training Loss: 879.85, Validation Loss: 1353.95
2025-02-24 15:21:07,786 - Epoch 2, Training Loss: 643.02, Validation Loss: 586.75
2025-02-24 15:21:08,013 - Epoch 3, Training Loss: 500.10, Validation Loss: 165.21
2025-02-24 15:21:08,234 - Epoch 4, Training Loss: 291.22, Validation Loss: 217.74
2025-02-24 15:21:08,437 - Epoch 5, Training Loss: 184.80, Validation Loss: 228.50
2025-02-24 15:21:08,641 - Epoch 6, Training Loss: 165.55, Validation Loss: 124.41
2025-02-24 15:21:08,891 - Epoch 7, Training Loss: 142.48, Validation Loss: 101.71
2025-02-24 15:21:09,130 - Epoch 8, Training Loss: 103.96, Validation Loss: 106.85
2025-02-24 15:21:09,338 - Epoch 9, Training Loss: 94.60, Validation Loss: 87.80
2025-02-24 15:21:09,560 - Epoch 10, Training Loss: 95.70, Validation Loss: 77.70
2025-02-24 15:21:09,795 - Epoch 11, Training Loss: 88.42, Validation Loss: 75.55
2025-02-24 15:21:10,010 - Epoch 12, Training Loss: 81.88, Validation Loss: 72.02
2025-02-24 15:21:10,244 - Epoch 13, Training Loss: 76.96, Validation Loss: 74.45
2025-02-24 15:21:10,468 - Epoch 14, Training Loss: 72.99, Validation Loss: 74.61
2025-02-24 15:21:10,670 - Epoch 15, Training Loss: 82.48, Validation Loss: 71.33
2025-02-24 15:21:10,903 - Epoch 16, Training Loss: 75.46, Validation Loss: 66.82
2025-02-24 15:21:11,115 - Epoch 17, Training Loss: 92.57, Validation Loss: 67.80
2025-02-24 15:21:11,318 - Epoch 18, Training Loss: 88.58, Validation Loss: 64.34
2025-02-24 15:21:11,540 - Epoch 19, Training Loss: 73.53, Validation Loss: 75.35
2025-02-24 15:21:11,750 - Epoch 20, Training Loss: 75.67, Validation Loss: 71.07
2025-02-24 15:21:11,967 - Epoch 21, Training Loss: 72.83, Validation Loss: 65.48
2025-02-24 15:21:12,176 - Epoch 22, Training Loss: 75.02, Validation Loss: 64.27
2025-02-24 15:21:12,416 - Epoch 23, Training Loss: 70.02, Validation Loss: 67.58
2025-02-24 15:21:12,650 - Epoch 24, Training Loss: 75.11, Validation Loss: 67.12
2025-02-24 15:21:12,876 - Epoch 25, Training Loss: 71.74, Validation Loss: 67.51
2025-02-24 15:21:13,074 - Epoch 26, Training Loss: 80.15, Validation Loss: 66.41
2025-02-24 15:21:13,277 - Epoch 27, Training Loss: 69.13, Validation Loss: 70.90
2025-02-24 15:21:13,483 - Epoch 28, Training Loss: 72.99, Validation Loss: 67.92
2025-02-24 15:21:13,688 - Epoch 29, Training Loss: 74.76, Validation Loss: 62.28
2025-02-24 15:21:13,922 - Epoch 30, Training Loss: 73.56, Validation Loss: 62.27
2025-02-24 15:21:14,147 - Epoch 31, Training Loss: 72.29, Validation Loss: 65.41
2025-02-24 15:21:14,355 - Epoch 32, Training Loss: 75.31, Validation Loss: 63.74
2025-02-24 15:21:14,556 - Epoch 33, Training Loss: 72.57, Validation Loss: 68.48
2025-02-24 15:21:14,766 - Epoch 34, Training Loss: 73.17, Validation Loss: 68.98
2025-02-24 15:21:14,969 - Epoch 35, Training Loss: 71.01, Validation Loss: 70.14
2025-02-24 15:21:15,166 - Epoch 36, Training Loss: 73.22, Validation Loss: 66.48
2025-02-24 15:21:15,369 - Epoch 37, Training Loss: 79.38, Validation Loss: 65.38
2025-02-24 15:21:15,577 - Epoch 38, Training Loss: 76.81, Validation Loss: 66.03
2025-02-24 15:21:15,795 - Epoch 39, Training Loss: 66.82, Validation Loss: 67.12
2025-02-24 15:21:15,998 - Epoch 40, Training Loss: 71.90, Validation Loss: 70.27
2025-02-24 15:21:16,194 - Epoch 41, Training Loss: 71.23, Validation Loss: 65.65
2025-02-24 15:21:16,409 - Epoch 42, Training Loss: 73.50, Validation Loss: 61.68
2025-02-24 15:21:16,628 - Epoch 43, Training Loss: 72.64, Validation Loss: 64.14
2025-02-24 15:21:16,842 - Epoch 44, Training Loss: 78.77, Validation Loss: 64.44
2025-02-24 15:21:17,046 - Epoch 45, Training Loss: 68.18, Validation Loss: 68.29
2025-02-24 15:21:17,255 - Epoch 46, Training Loss: 79.63, Validation Loss: 67.84
2025-02-24 15:21:17,465 - Epoch 47, Training Loss: 76.44, Validation Loss: 68.82
2025-02-24 15:21:17,678 - Epoch 48, Training Loss: 73.64, Validation Loss: 72.27
2025-02-24 15:21:17,890 - Epoch 49, Training Loss: 83.48, Validation Loss: 70.25
2025-02-24 15:21:18,083 - Epoch 50, Training Loss: 75.12, Validation Loss: 69.10
2025-02-24 15:21:18,285 - Epoch 51, Training Loss: 82.31, Validation Loss: 70.41
2025-02-24 15:21:18,484 - Epoch 52, Training Loss: 74.29, Validation Loss: 79.34
2025-02-24 15:21:18,685 - Epoch 53, Training Loss: 81.44, Validation Loss: 68.63
2025-02-24 15:21:18,893 - Epoch 54, Training Loss: 83.43, Validation Loss: 67.52
2025-02-24 15:21:19,096 - Epoch 55, Training Loss: 81.10, Validation Loss: 73.50
2025-02-24 15:21:19,295 - Epoch 56, Training Loss: 77.05, Validation Loss: 72.67
2025-02-24 15:21:19,512 - Epoch 57, Training Loss: 69.64, Validation Loss: 73.71
2025-02-24 15:21:19,716 - Epoch 58, Training Loss: 80.09, Validation Loss: 64.63
2025-02-24 15:21:19,922 - Epoch 59, Training Loss: 78.79, Validation Loss: 63.24
2025-02-24 15:21:20,122 - Epoch 60, Training Loss: 82.62, Validation Loss: 66.41
2025-02-24 15:21:20,321 - Epoch 61, Training Loss: 75.17, Validation Loss: 66.22
2025-02-24 15:21:20,525 - Epoch 62, Training Loss: 77.56, Validation Loss: 69.16
2025-02-24 15:21:20,525 - Early stopping at epoch 62 due to no improvement in validation loss.
2025-02-24 15:21:20,745 - learning rate: 0.5
2025-02-24 15:21:20,745 - Test RMSE: 7.775742769241333, Test MAE: 1.3513355255126953
2025-02-24 15:31:36,384 - -----------------------Starting training-------------------------
2025-02-24 15:31:36,384 - learning rate: 0.5
2025-02-24 15:31:36,595 - Epoch 1, Training Loss: 879.85, Validation Loss: 1353.95
2025-02-24 15:31:36,829 - Epoch 2, Training Loss: 643.02, Validation Loss: 586.75
2025-02-24 15:31:37,073 - Epoch 3, Training Loss: 500.10, Validation Loss: 165.21
2025-02-24 15:31:37,308 - Epoch 4, Training Loss: 291.22, Validation Loss: 217.74
2025-02-24 15:31:37,513 - Epoch 5, Training Loss: 184.80, Validation Loss: 228.50
2025-02-24 15:31:37,716 - Epoch 6, Training Loss: 165.55, Validation Loss: 124.41
2025-02-24 15:31:37,954 - Epoch 7, Training Loss: 142.48, Validation Loss: 101.71
2025-02-24 15:31:38,174 - Epoch 8, Training Loss: 103.96, Validation Loss: 106.85
2025-02-24 15:31:38,402 - Epoch 9, Training Loss: 94.60, Validation Loss: 87.80
2025-02-24 15:31:38,650 - Epoch 10, Training Loss: 95.70, Validation Loss: 77.70
2025-02-24 15:31:38,893 - Epoch 11, Training Loss: 88.42, Validation Loss: 75.55
2025-02-24 15:31:39,126 - Epoch 12, Training Loss: 81.88, Validation Loss: 72.02
2025-02-24 15:31:39,357 - Epoch 13, Training Loss: 76.96, Validation Loss: 74.45
2025-02-24 15:31:39,563 - Epoch 14, Training Loss: 72.99, Validation Loss: 74.61
2025-02-24 15:31:39,782 - Epoch 15, Training Loss: 82.48, Validation Loss: 71.33
2025-02-24 15:31:40,015 - Epoch 16, Training Loss: 75.46, Validation Loss: 66.82
2025-02-24 15:31:40,243 - Epoch 17, Training Loss: 92.57, Validation Loss: 67.80
2025-02-24 15:31:40,471 - Epoch 18, Training Loss: 88.58, Validation Loss: 64.34
2025-02-24 15:31:40,707 - Epoch 19, Training Loss: 73.53, Validation Loss: 75.35
2025-02-24 15:31:40,909 - Epoch 20, Training Loss: 75.67, Validation Loss: 71.07
2025-02-24 15:31:41,123 - Epoch 21, Training Loss: 72.83, Validation Loss: 65.48
2025-02-24 15:31:41,346 - Epoch 22, Training Loss: 75.02, Validation Loss: 64.27
2025-02-24 15:31:41,585 - Epoch 23, Training Loss: 70.02, Validation Loss: 67.58
2025-02-24 15:31:41,803 - Epoch 24, Training Loss: 75.11, Validation Loss: 67.12
2025-02-24 15:31:42,026 - Epoch 25, Training Loss: 71.74, Validation Loss: 67.51
2025-02-24 15:31:42,247 - Epoch 26, Training Loss: 80.15, Validation Loss: 66.41
2025-02-24 15:31:42,474 - Epoch 27, Training Loss: 69.13, Validation Loss: 70.90
2025-02-24 15:31:42,691 - Epoch 28, Training Loss: 72.99, Validation Loss: 67.92
2025-02-24 15:31:42,920 - Epoch 29, Training Loss: 74.76, Validation Loss: 62.28
2025-02-24 15:31:43,161 - Epoch 30, Training Loss: 73.56, Validation Loss: 62.27
2025-02-24 15:31:43,402 - Epoch 31, Training Loss: 72.29, Validation Loss: 65.41
2025-02-24 15:31:43,622 - Epoch 32, Training Loss: 75.31, Validation Loss: 63.74
2025-02-24 15:31:43,851 - Epoch 33, Training Loss: 72.57, Validation Loss: 68.48
2025-02-24 15:31:44,061 - Epoch 34, Training Loss: 73.17, Validation Loss: 68.98
2025-02-24 15:31:44,263 - Epoch 35, Training Loss: 71.01, Validation Loss: 70.14
2025-02-24 15:31:44,476 - Epoch 36, Training Loss: 73.22, Validation Loss: 66.48
2025-02-24 15:31:44,676 - Epoch 37, Training Loss: 79.38, Validation Loss: 65.38
2025-02-24 15:31:44,886 - Epoch 38, Training Loss: 76.81, Validation Loss: 66.03
2025-02-24 15:31:45,088 - Epoch 39, Training Loss: 66.82, Validation Loss: 67.12
2025-02-24 15:31:45,290 - Epoch 40, Training Loss: 71.90, Validation Loss: 70.27
2025-02-24 15:31:45,497 - Epoch 41, Training Loss: 71.23, Validation Loss: 65.65
2025-02-24 15:31:45,700 - Epoch 42, Training Loss: 73.50, Validation Loss: 61.68
2025-02-24 15:31:45,935 - Epoch 43, Training Loss: 72.64, Validation Loss: 64.14
2025-02-24 15:31:46,147 - Epoch 44, Training Loss: 78.77, Validation Loss: 64.44
2025-02-24 15:31:46,347 - Epoch 45, Training Loss: 68.18, Validation Loss: 68.29
2025-02-24 15:31:46,553 - Epoch 46, Training Loss: 79.63, Validation Loss: 67.84
2025-02-24 15:31:46,772 - Epoch 47, Training Loss: 76.44, Validation Loss: 68.82
2025-02-24 15:31:46,972 - Epoch 48, Training Loss: 73.64, Validation Loss: 72.27
2025-02-24 15:31:47,181 - Epoch 49, Training Loss: 83.48, Validation Loss: 70.25
2025-02-24 15:31:47,379 - Epoch 50, Training Loss: 75.12, Validation Loss: 69.10
2025-02-24 15:31:47,591 - Epoch 51, Training Loss: 82.31, Validation Loss: 70.41
2025-02-24 15:31:47,793 - Epoch 52, Training Loss: 74.29, Validation Loss: 79.34
2025-02-24 15:31:47,997 - Epoch 53, Training Loss: 81.44, Validation Loss: 68.63
2025-02-24 15:31:48,195 - Epoch 54, Training Loss: 83.43, Validation Loss: 67.52
2025-02-24 15:31:48,397 - Epoch 55, Training Loss: 81.10, Validation Loss: 73.50
2025-02-24 15:31:48,623 - Epoch 56, Training Loss: 77.05, Validation Loss: 72.67
2025-02-24 15:31:48,819 - Epoch 57, Training Loss: 69.64, Validation Loss: 73.71
2025-02-24 15:31:49,034 - Epoch 58, Training Loss: 80.09, Validation Loss: 64.63
2025-02-24 15:31:49,234 - Epoch 59, Training Loss: 78.79, Validation Loss: 63.24
2025-02-24 15:31:49,446 - Epoch 60, Training Loss: 82.62, Validation Loss: 66.41
2025-02-24 15:31:49,644 - Epoch 61, Training Loss: 75.17, Validation Loss: 66.22
2025-02-24 15:31:49,845 - Epoch 62, Training Loss: 77.56, Validation Loss: 69.16
2025-02-24 15:31:49,846 - Early stopping at epoch 62 due to no improvement in validation loss.
2025-02-24 15:31:50,066 - learning rate: 0.5
2025-02-24 15:31:50,067 - Test RMSE: 7.775742769241333, Test MAE: 1.3513355255126953
2025-02-24 15:32:51,564 - -----------------------Starting training-------------------------
2025-02-24 15:32:51,564 - learning rate: 0.2
2025-02-24 15:32:51,767 - Epoch 1, Training Loss: 268.86, Validation Loss: 314.04
2025-02-24 15:32:51,982 - Epoch 2, Training Loss: 178.73, Validation Loss: 168.00
2025-02-24 15:32:52,209 - Epoch 3, Training Loss: 151.07, Validation Loss: 94.26
2025-02-24 15:32:52,432 - Epoch 4, Training Loss: 111.68, Validation Loss: 93.03
2025-02-24 15:32:52,656 - Epoch 5, Training Loss: 92.34, Validation Loss: 93.04
2025-02-24 15:32:52,864 - Epoch 6, Training Loss: 79.95, Validation Loss: 75.46
2025-02-24 15:32:53,101 - Epoch 7, Training Loss: 84.76, Validation Loss: 69.75
2025-02-24 15:32:53,332 - Epoch 8, Training Loss: 71.54, Validation Loss: 71.76
2025-02-24 15:32:53,542 - Epoch 9, Training Loss: 72.39, Validation Loss: 66.78
2025-02-24 15:32:53,780 - Epoch 10, Training Loss: 79.19, Validation Loss: 64.18
2025-02-24 15:32:54,008 - Epoch 11, Training Loss: 77.50, Validation Loss: 65.23
2025-02-24 15:32:54,215 - Epoch 12, Training Loss: 74.27, Validation Loss: 65.28
2025-02-24 15:32:54,424 - Epoch 13, Training Loss: 72.23, Validation Loss: 66.03
2025-02-24 15:32:54,633 - Epoch 14, Training Loss: 69.36, Validation Loss: 68.21
2025-02-24 15:32:54,835 - Epoch 15, Training Loss: 77.56, Validation Loss: 70.36
2025-02-24 15:32:55,042 - Epoch 16, Training Loss: 70.42, Validation Loss: 67.80
2025-02-24 15:32:55,261 - Epoch 17, Training Loss: 88.87, Validation Loss: 68.15
2025-02-24 15:32:55,889 - Epoch 18, Training Loss: 81.86, Validation Loss: 64.45
2025-02-24 15:32:56,102 - Epoch 19, Training Loss: 71.31, Validation Loss: 66.62
2025-02-24 15:32:56,319 - Epoch 20, Training Loss: 71.97, Validation Loss: 68.41
2025-02-24 15:32:57,123 - Epoch 21, Training Loss: 70.57, Validation Loss: 66.60
2025-02-24 15:32:57,351 - Epoch 22, Training Loss: 72.51, Validation Loss: 63.86
2025-02-24 15:32:57,604 - Epoch 23, Training Loss: 67.97, Validation Loss: 65.07
2025-02-24 15:32:57,823 - Epoch 24, Training Loss: 73.69, Validation Loss: 65.39
2025-02-24 15:32:58,621 - Epoch 25, Training Loss: 70.08, Validation Loss: 65.12
2025-02-24 15:32:58,879 - Epoch 26, Training Loss: 78.81, Validation Loss: 64.59
2025-02-24 15:32:59,949 - Epoch 27, Training Loss: 67.64, Validation Loss: 67.60
2025-02-24 15:33:00,233 - Epoch 28, Training Loss: 71.34, Validation Loss: 68.23
2025-02-24 15:33:00,474 - Epoch 29, Training Loss: 73.85, Validation Loss: 64.48
2025-02-24 15:33:00,699 - Epoch 30, Training Loss: 70.21, Validation Loss: 62.75
2025-02-24 15:33:00,974 - Epoch 31, Training Loss: 68.68, Validation Loss: 63.15
2025-02-24 15:33:01,229 - Epoch 32, Training Loss: 72.91, Validation Loss: 62.47
2025-02-24 15:33:01,489 - Epoch 33, Training Loss: 71.29, Validation Loss: 65.56
2025-02-24 15:33:01,706 - Epoch 34, Training Loss: 72.00, Validation Loss: 66.65
2025-02-24 15:33:01,941 - Epoch 35, Training Loss: 69.72, Validation Loss: 65.72
2025-02-24 15:33:02,155 - Epoch 36, Training Loss: 71.28, Validation Loss: 65.14
2025-02-24 15:33:02,380 - Epoch 37, Training Loss: 77.37, Validation Loss: 64.68
2025-02-24 15:33:02,607 - Epoch 38, Training Loss: 74.30, Validation Loss: 66.94
2025-02-24 15:33:02,818 - Epoch 39, Training Loss: 64.79, Validation Loss: 65.74
2025-02-24 15:33:03,052 - Epoch 40, Training Loss: 69.35, Validation Loss: 66.60
2025-02-24 15:33:03,275 - Epoch 41, Training Loss: 68.84, Validation Loss: 64.86
2025-02-24 15:33:03,486 - Epoch 42, Training Loss: 71.17, Validation Loss: 61.76
2025-02-24 15:33:03,743 - Epoch 43, Training Loss: 70.88, Validation Loss: 62.63
2025-02-24 15:33:03,967 - Epoch 44, Training Loss: 76.92, Validation Loss: 63.07
2025-02-24 15:33:04,200 - Epoch 45, Training Loss: 67.22, Validation Loss: 64.96
2025-02-24 15:33:04,413 - Epoch 46, Training Loss: 77.79, Validation Loss: 66.29
2025-02-24 15:33:04,631 - Epoch 47, Training Loss: 74.44, Validation Loss: 65.82
2025-02-24 15:33:04,855 - Epoch 48, Training Loss: 71.00, Validation Loss: 68.95
2025-02-24 15:33:05,055 - Epoch 49, Training Loss: 79.88, Validation Loss: 67.61
2025-02-24 15:33:05,255 - Epoch 50, Training Loss: 72.65, Validation Loss: 67.01
2025-02-24 15:33:05,451 - Epoch 51, Training Loss: 76.01, Validation Loss: 66.22
2025-02-24 15:33:05,658 - Epoch 52, Training Loss: 71.09, Validation Loss: 72.58
2025-02-24 15:33:05,887 - Epoch 53, Training Loss: 77.23, Validation Loss: 68.63
2025-02-24 15:33:06,085 - Epoch 54, Training Loss: 76.09, Validation Loss: 63.46
2025-02-24 15:33:06,285 - Epoch 55, Training Loss: 76.21, Validation Loss: 67.06
2025-02-24 15:33:06,488 - Epoch 56, Training Loss: 73.60, Validation Loss: 67.41
2025-02-24 15:33:06,685 - Epoch 57, Training Loss: 65.49, Validation Loss: 69.26
2025-02-24 15:33:06,890 - Epoch 58, Training Loss: 78.74, Validation Loss: 66.03
2025-02-24 15:33:07,092 - Epoch 59, Training Loss: 74.83, Validation Loss: 62.91
2025-02-24 15:33:07,298 - Epoch 60, Training Loss: 79.76, Validation Loss: 63.55
2025-02-24 15:33:07,495 - Epoch 61, Training Loss: 73.47, Validation Loss: 63.24
2025-02-24 15:33:07,701 - Epoch 62, Training Loss: 75.09, Validation Loss: 65.26
2025-02-24 15:33:07,701 - Early stopping at epoch 62 due to no improvement in validation loss.
2025-02-24 15:33:07,915 - learning rate: 0.2
2025-02-24 15:33:07,915 - Test RMSE: 7.662822961807251, Test MAE: 1.3073937892913818
2025-02-24 15:33:39,003 - -----------------------Starting training-------------------------
2025-02-24 15:33:39,003 - learning rate: 0.1
2025-02-24 15:33:39,205 - Epoch 1, Training Loss: 197.68, Validation Loss: 196.16
2025-02-24 15:33:39,433 - Epoch 2, Training Loss: 132.83, Validation Loss: 139.34
2025-02-24 15:33:39,663 - Epoch 3, Training Loss: 115.76, Validation Loss: 104.91
2025-02-24 15:33:39,875 - Epoch 4, Training Loss: 89.93, Validation Loss: 92.14
2025-02-24 15:33:40,108 - Epoch 5, Training Loss: 85.92, Validation Loss: 87.74
2025-02-24 15:33:40,332 - Epoch 6, Training Loss: 74.18, Validation Loss: 79.41
2025-02-24 15:33:40,541 - Epoch 7, Training Loss: 77.30, Validation Loss: 73.24
2025-02-24 15:33:40,753 - Epoch 8, Training Loss: 68.79, Validation Loss: 71.40
2025-02-24 15:33:40,974 - Epoch 9, Training Loss: 69.14, Validation Loss: 68.30
2025-02-24 15:33:41,219 - Epoch 10, Training Loss: 75.36, Validation Loss: 65.81
2025-02-24 15:33:41,428 - Epoch 11, Training Loss: 74.52, Validation Loss: 65.43
2025-02-24 15:33:41,636 - Epoch 12, Training Loss: 72.17, Validation Loss: 65.16
2025-02-24 15:33:41,844 - Epoch 13, Training Loss: 71.10, Validation Loss: 65.86
2025-02-24 15:33:42,044 - Epoch 14, Training Loss: 68.86, Validation Loss: 66.21
2025-02-24 15:33:42,256 - Epoch 15, Training Loss: 75.36, Validation Loss: 66.69
2025-02-24 15:33:42,441 - Epoch 16, Training Loss: 69.60, Validation Loss: 65.40
2025-02-24 15:33:42,630 - Epoch 17, Training Loss: 86.65, Validation Loss: 65.45
2025-02-24 15:33:42,812 - Epoch 18, Training Loss: 80.06, Validation Loss: 63.25
2025-02-24 15:33:43,031 - Epoch 19, Training Loss: 69.71, Validation Loss: 64.32
2025-02-24 15:33:43,240 - Epoch 20, Training Loss: 70.62, Validation Loss: 65.63
2025-02-24 15:33:43,426 - Epoch 21, Training Loss: 69.84, Validation Loss: 65.63
2025-02-24 15:33:43,618 - Epoch 22, Training Loss: 71.63, Validation Loss: 64.61
2025-02-24 15:33:43,815 - Epoch 23, Training Loss: 67.45, Validation Loss: 64.84
2025-02-24 15:33:44,022 - Epoch 24, Training Loss: 73.05, Validation Loss: 65.49
2025-02-24 15:33:44,233 - Epoch 25, Training Loss: 69.66, Validation Loss: 65.91
2025-02-24 15:33:44,429 - Epoch 26, Training Loss: 78.01, Validation Loss: 65.00
2025-02-24 15:33:44,622 - Epoch 27, Training Loss: 67.09, Validation Loss: 66.10
2025-02-24 15:33:44,808 - Epoch 28, Training Loss: 70.69, Validation Loss: 66.77
2025-02-24 15:33:44,998 - Epoch 29, Training Loss: 73.43, Validation Loss: 64.69
2025-02-24 15:33:45,206 - Epoch 30, Training Loss: 68.63, Validation Loss: 62.89
2025-02-24 15:33:45,419 - Epoch 31, Training Loss: 67.27, Validation Loss: 62.80
2025-02-24 15:33:45,632 - Epoch 32, Training Loss: 71.90, Validation Loss: 62.40
2025-02-24 15:33:45,850 - Epoch 33, Training Loss: 70.83, Validation Loss: 64.17
2025-02-24 15:33:46,044 - Epoch 34, Training Loss: 71.00, Validation Loss: 65.40
2025-02-24 15:33:46,242 - Epoch 35, Training Loss: 69.04, Validation Loss: 65.22
2025-02-24 15:33:46,433 - Epoch 36, Training Loss: 70.45, Validation Loss: 64.88
2025-02-24 15:33:46,623 - Epoch 37, Training Loss: 76.67, Validation Loss: 64.06
2025-02-24 15:33:46,817 - Epoch 38, Training Loss: 73.40, Validation Loss: 65.40
2025-02-24 15:33:47,017 - Epoch 39, Training Loss: 63.92, Validation Loss: 65.23
2025-02-24 15:33:47,231 - Epoch 40, Training Loss: 68.71, Validation Loss: 65.92
2025-02-24 15:33:47,417 - Epoch 41, Training Loss: 67.90, Validation Loss: 64.85
2025-02-24 15:33:47,605 - Epoch 42, Training Loss: 70.47, Validation Loss: 62.63
2025-02-24 15:33:47,790 - Epoch 43, Training Loss: 70.09, Validation Loss: 62.79
2025-02-24 15:33:47,988 - Epoch 44, Training Loss: 76.54, Validation Loss: 63.05
2025-02-24 15:33:48,206 - Epoch 45, Training Loss: 66.73, Validation Loss: 63.91
2025-02-24 15:33:48,392 - Epoch 46, Training Loss: 77.11, Validation Loss: 65.41
2025-02-24 15:33:48,580 - Epoch 47, Training Loss: 73.56, Validation Loss: 65.30
2025-02-24 15:33:48,764 - Epoch 48, Training Loss: 70.79, Validation Loss: 66.66
2025-02-24 15:33:48,958 - Epoch 49, Training Loss: 78.94, Validation Loss: 65.93
2025-02-24 15:33:49,160 - Epoch 50, Training Loss: 70.98, Validation Loss: 65.62
2025-02-24 15:33:49,358 - Epoch 51, Training Loss: 74.48, Validation Loss: 64.70
2025-02-24 15:33:49,551 - Epoch 52, Training Loss: 70.48, Validation Loss: 68.24
2025-02-24 15:33:49,551 - Early stopping at epoch 52 due to no improvement in validation loss.
2025-02-24 15:33:49,757 - learning rate: 0.1
2025-02-24 15:33:49,757 - Test RMSE: 7.525064945220947, Test MAE: 1.2544775605201721
2025-02-24 15:34:39,174 - -----------------------Starting training-------------------------
2025-02-24 15:34:39,174 - learning rate: 0.05
2025-02-24 15:34:39,363 - Epoch 1, Training Loss: 189.90, Validation Loss: 187.83
2025-02-24 15:34:39,577 - Epoch 2, Training Loss: 136.64, Validation Loss: 156.52
2025-02-24 15:34:39,804 - Epoch 3, Training Loss: 121.94, Validation Loss: 135.01
2025-02-24 15:34:40,019 - Epoch 4, Training Loss: 99.08, Validation Loss: 119.85
2025-02-24 15:34:40,234 - Epoch 5, Training Loss: 101.04, Validation Loss: 109.78
2025-02-24 15:34:40,441 - Epoch 6, Training Loss: 87.77, Validation Loss: 101.09
2025-02-24 15:34:40,664 - Epoch 7, Training Loss: 83.36, Validation Loss: 94.06
2025-02-24 15:34:40,891 - Epoch 8, Training Loss: 78.30, Validation Loss: 89.45
2025-02-24 15:34:41,098 - Epoch 9, Training Loss: 81.36, Validation Loss: 84.74
2025-02-24 15:34:41,301 - Epoch 10, Training Loss: 82.47, Validation Loss: 80.53
2025-02-24 15:34:41,516 - Epoch 11, Training Loss: 79.78, Validation Loss: 77.88
2025-02-24 15:34:41,741 - Epoch 12, Training Loss: 75.02, Validation Loss: 75.78
2025-02-24 15:34:41,950 - Epoch 13, Training Loss: 72.75, Validation Loss: 74.56
2025-02-24 15:34:42,162 - Epoch 14, Training Loss: 68.88, Validation Loss: 73.76
2025-02-24 15:34:42,374 - Epoch 15, Training Loss: 77.61, Validation Loss: 73.22
2025-02-24 15:34:42,624 - Epoch 16, Training Loss: 69.19, Validation Loss: 71.55
2025-02-24 15:34:42,881 - Epoch 17, Training Loss: 87.72, Validation Loss: 70.76
2025-02-24 15:34:43,122 - Epoch 18, Training Loss: 79.93, Validation Loss: 68.71
2025-02-24 15:34:43,342 - Epoch 19, Training Loss: 69.15, Validation Loss: 67.96
2025-02-24 15:34:43,584 - Epoch 20, Training Loss: 70.81, Validation Loss: 68.00
2025-02-24 15:34:43,827 - Epoch 21, Training Loss: 70.11, Validation Loss: 67.67
2025-02-24 15:34:44,042 - Epoch 22, Training Loss: 71.37, Validation Loss: 66.93
2025-02-24 15:34:44,248 - Epoch 23, Training Loss: 67.55, Validation Loss: 66.69
2025-02-24 15:34:44,458 - Epoch 24, Training Loss: 72.70, Validation Loss: 66.65
2025-02-24 15:34:44,686 - Epoch 25, Training Loss: 69.72, Validation Loss: 66.81
2025-02-24 15:34:44,888 - Epoch 26, Training Loss: 77.29, Validation Loss: 66.39
2025-02-24 15:34:45,096 - Epoch 27, Training Loss: 66.80, Validation Loss: 66.73
2025-02-24 15:34:45,285 - Epoch 28, Training Loss: 70.26, Validation Loss: 66.87
2025-02-24 15:34:45,469 - Epoch 29, Training Loss: 73.08, Validation Loss: 65.61
2025-02-24 15:34:45,690 - Epoch 30, Training Loss: 68.02, Validation Loss: 64.21
2025-02-24 15:34:45,902 - Epoch 31, Training Loss: 66.91, Validation Loss: 63.88
2025-02-24 15:34:46,126 - Epoch 32, Training Loss: 71.02, Validation Loss: 63.31
2025-02-24 15:34:46,337 - Epoch 33, Training Loss: 70.41, Validation Loss: 63.82
2025-02-24 15:34:46,540 - Epoch 34, Training Loss: 70.45, Validation Loss: 64.55
2025-02-24 15:34:46,753 - Epoch 35, Training Loss: 68.60, Validation Loss: 64.64
2025-02-24 15:34:46,948 - Epoch 36, Training Loss: 70.08, Validation Loss: 64.52
2025-02-24 15:34:47,135 - Epoch 37, Training Loss: 76.22, Validation Loss: 64.06
2025-02-24 15:34:47,325 - Epoch 38, Training Loss: 72.96, Validation Loss: 64.64
2025-02-24 15:34:47,511 - Epoch 39, Training Loss: 63.54, Validation Loss: 64.56
2025-02-24 15:34:47,719 - Epoch 40, Training Loss: 68.26, Validation Loss: 65.12
2025-02-24 15:34:47,914 - Epoch 41, Training Loss: 67.41, Validation Loss: 64.80
2025-02-24 15:34:48,097 - Epoch 42, Training Loss: 70.15, Validation Loss: 63.36
2025-02-24 15:34:48,279 - Epoch 43, Training Loss: 69.73, Validation Loss: 62.97
2025-02-24 15:34:48,493 - Epoch 44, Training Loss: 75.94, Validation Loss: 63.08
2025-02-24 15:34:48,690 - Epoch 45, Training Loss: 66.53, Validation Loss: 63.39
2025-02-24 15:34:48,893 - Epoch 46, Training Loss: 76.92, Validation Loss: 64.29
2025-02-24 15:34:49,079 - Epoch 47, Training Loss: 72.83, Validation Loss: 64.77
2025-02-24 15:34:49,262 - Epoch 48, Training Loss: 70.29, Validation Loss: 65.89
2025-02-24 15:34:49,451 - Epoch 49, Training Loss: 78.39, Validation Loss: 65.46
2025-02-24 15:34:49,642 - Epoch 50, Training Loss: 70.14, Validation Loss: 65.14
2025-02-24 15:34:49,850 - Epoch 51, Training Loss: 73.20, Validation Loss: 64.18
2025-02-24 15:34:50,032 - Epoch 52, Training Loss: 70.15, Validation Loss: 65.60
2025-02-24 15:34:50,223 - Epoch 53, Training Loss: 73.45, Validation Loss: 65.98
2025-02-24 15:34:50,416 - Epoch 54, Training Loss: 72.00, Validation Loss: 64.43
2025-02-24 15:34:50,609 - Epoch 55, Training Loss: 73.75, Validation Loss: 64.87
2025-02-24 15:34:50,816 - Epoch 56, Training Loss: 71.27, Validation Loss: 65.07
2025-02-24 15:34:51,012 - Epoch 57, Training Loss: 63.09, Validation Loss: 65.99
2025-02-24 15:34:51,193 - Epoch 58, Training Loss: 76.29, Validation Loss: 65.38
2025-02-24 15:34:51,378 - Epoch 59, Training Loss: 72.39, Validation Loss: 63.98
2025-02-24 15:34:51,567 - Epoch 60, Training Loss: 78.70, Validation Loss: 63.71
2025-02-24 15:34:51,779 - Epoch 61, Training Loss: 71.68, Validation Loss: 63.45
2025-02-24 15:34:51,967 - Epoch 62, Training Loss: 73.66, Validation Loss: 63.94
2025-02-24 15:34:52,152 - Epoch 63, Training Loss: 77.99, Validation Loss: 63.73
2025-02-24 15:34:52,152 - Early stopping at epoch 63 due to no improvement in validation loss.
2025-02-24 15:34:52,387 - learning rate: 0.05
2025-02-24 15:34:52,387 - Test RMSE: 7.5248353481292725, Test MAE: 1.2346936464309692
2025-02-24 15:35:11,623 - -----------------------Starting training-------------------------
2025-02-24 15:35:11,624 - learning rate: 0.02
2025-02-24 15:35:11,816 - Epoch 1, Training Loss: 191.50, Validation Loss: 200.15
2025-02-24 15:35:12,026 - Epoch 2, Training Loss: 150.45, Validation Loss: 183.70
2025-02-24 15:35:12,258 - Epoch 3, Training Loss: 139.05, Validation Loss: 170.36
2025-02-24 15:35:12,467 - Epoch 4, Training Loss: 118.08, Validation Loss: 159.44
2025-02-24 15:35:12,685 - Epoch 5, Training Loss: 126.07, Validation Loss: 150.31
2025-02-24 15:35:12,909 - Epoch 6, Training Loss: 115.46, Validation Loss: 142.11
2025-02-24 15:35:13,137 - Epoch 7, Training Loss: 104.73, Validation Loss: 134.98
2025-02-24 15:35:13,877 - Epoch 8, Training Loss: 104.22, Validation Loss: 129.04
2025-02-24 15:35:14,090 - Epoch 9, Training Loss: 112.58, Validation Loss: 123.35
2025-02-24 15:35:14,330 - Epoch 10, Training Loss: 108.90, Validation Loss: 117.99
2025-02-24 15:35:14,545 - Epoch 11, Training Loss: 104.25, Validation Loss: 113.46
2025-02-24 15:35:14,749 - Epoch 12, Training Loss: 93.98, Validation Loss: 109.49
2025-02-24 15:35:14,963 - Epoch 13, Training Loss: 89.72, Validation Loss: 106.18
2025-02-24 15:35:15,190 - Epoch 14, Training Loss: 80.34, Validation Loss: 103.47
2025-02-24 15:35:15,409 - Epoch 15, Training Loss: 98.55, Validation Loss: 101.14
2025-02-24 15:35:15,616 - Epoch 16, Training Loss: 80.02, Validation Loss: 98.49
2025-02-24 15:35:15,825 - Epoch 17, Training Loss: 110.49, Validation Loss: 96.28
2025-02-24 15:35:16,064 - Epoch 18, Training Loss: 90.94, Validation Loss: 93.56
2025-02-24 15:35:16,309 - Epoch 19, Training Loss: 78.36, Validation Loss: 91.37
2025-02-24 15:35:16,518 - Epoch 20, Training Loss: 82.63, Validation Loss: 89.66
2025-02-24 15:35:16,743 - Epoch 21, Training Loss: 81.00, Validation Loss: 87.98
2025-02-24 15:35:16,955 - Epoch 22, Training Loss: 78.53, Validation Loss: 86.26
2025-02-24 15:35:17,180 - Epoch 23, Training Loss: 75.83, Validation Loss: 84.83
2025-02-24 15:35:17,407 - Epoch 24, Training Loss: 78.25, Validation Loss: 83.62
2025-02-24 15:35:17,619 - Epoch 25, Training Loss: 78.09, Validation Loss: 82.60
2025-02-24 15:35:17,827 - Epoch 26, Training Loss: 80.96, Validation Loss: 81.49
2025-02-24 15:35:18,042 - Epoch 27, Training Loss: 71.15, Validation Loss: 80.76
2025-02-24 15:35:18,290 - Epoch 28, Training Loss: 75.94, Validation Loss: 80.07
2025-02-24 15:35:18,509 - Epoch 29, Training Loss: 80.47, Validation Loss: 78.81
2025-02-24 15:35:18,723 - Epoch 30, Training Loss: 72.94, Validation Loss: 77.36
2025-02-24 15:35:18,948 - Epoch 31, Training Loss: 73.14, Validation Loss: 76.33
2025-02-24 15:35:19,172 - Epoch 32, Training Loss: 72.77, Validation Loss: 75.30
2025-02-24 15:35:19,393 - Epoch 33, Training Loss: 72.70, Validation Loss: 74.73
2025-02-24 15:35:19,602 - Epoch 34, Training Loss: 72.94, Validation Loss: 74.41
2025-02-24 15:35:19,810 - Epoch 35, Training Loss: 71.45, Validation Loss: 73.94
2025-02-24 15:35:20,031 - Epoch 36, Training Loss: 73.96, Validation Loss: 73.40
2025-02-24 15:35:20,265 - Epoch 37, Training Loss: 77.98, Validation Loss: 72.72
2025-02-24 15:35:20,490 - Epoch 38, Training Loss: 74.01, Validation Loss: 72.48
2025-02-24 15:35:20,709 - Epoch 39, Training Loss: 64.79, Validation Loss: 72.07
2025-02-24 15:35:20,924 - Epoch 40, Training Loss: 69.36, Validation Loss: 71.87
2025-02-24 15:35:21,156 - Epoch 41, Training Loss: 70.01, Validation Loss: 71.39
2025-02-24 15:35:21,391 - Epoch 42, Training Loss: 71.79, Validation Loss: 70.45
2025-02-24 15:35:21,670 - Epoch 43, Training Loss: 71.43, Validation Loss: 69.79
2025-02-24 15:35:21,890 - Epoch 44, Training Loss: 76.36, Validation Loss: 69.30
2025-02-24 15:35:22,117 - Epoch 45, Training Loss: 66.92, Validation Loss: 69.03
2025-02-24 15:35:22,366 - Epoch 46, Training Loss: 78.37, Validation Loss: 68.98
2025-02-24 15:35:22,585 - Epoch 47, Training Loss: 71.83, Validation Loss: 68.85
2025-02-24 15:35:22,806 - Epoch 48, Training Loss: 70.76, Validation Loss: 69.16
2025-02-24 15:35:23,011 - Epoch 49, Training Loss: 78.17, Validation Loss: 68.99
2025-02-24 15:35:23,234 - Epoch 50, Training Loss: 71.39, Validation Loss: 68.80
2025-02-24 15:35:23,459 - Epoch 51, Training Loss: 71.62, Validation Loss: 68.25
2025-02-24 15:35:23,678 - Epoch 52, Training Loss: 69.86, Validation Loss: 68.61
2025-02-24 15:35:23,867 - Epoch 53, Training Loss: 74.09, Validation Loss: 68.61
2025-02-24 15:35:24,062 - Epoch 54, Training Loss: 71.41, Validation Loss: 67.71
2025-02-24 15:35:24,287 - Epoch 55, Training Loss: 73.51, Validation Loss: 67.55
2025-02-24 15:35:24,499 - Epoch 56, Training Loss: 70.59, Validation Loss: 67.47
2025-02-24 15:35:24,711 - Epoch 57, Training Loss: 63.33, Validation Loss: 67.81
2025-02-24 15:35:24,901 - Epoch 58, Training Loss: 76.51, Validation Loss: 67.54
2025-02-24 15:35:25,098 - Epoch 59, Training Loss: 72.21, Validation Loss: 66.77
2025-02-24 15:35:25,330 - Epoch 60, Training Loss: 79.17, Validation Loss: 66.41
2025-02-24 15:35:25,536 - Epoch 61, Training Loss: 71.14, Validation Loss: 66.10
2025-02-24 15:35:25,742 - Epoch 62, Training Loss: 73.51, Validation Loss: 66.13
2025-02-24 15:35:25,935 - Epoch 63, Training Loss: 77.71, Validation Loss: 65.96
2025-02-24 15:35:26,157 - Epoch 64, Training Loss: 70.83, Validation Loss: 65.89
2025-02-24 15:35:26,383 - Epoch 65, Training Loss: 76.90, Validation Loss: 65.79
2025-02-24 15:35:26,592 - Epoch 66, Training Loss: 70.71, Validation Loss: 65.92
2025-02-24 15:35:26,777 - Epoch 67, Training Loss: 67.80, Validation Loss: 65.79
2025-02-24 15:35:26,991 - Epoch 68, Training Loss: 72.15, Validation Loss: 65.57
2025-02-24 15:35:27,225 - Epoch 69, Training Loss: 66.32, Validation Loss: 65.59
2025-02-24 15:35:27,420 - Epoch 70, Training Loss: 68.23, Validation Loss: 65.30
2025-02-24 15:35:27,626 - Epoch 71, Training Loss: 66.03, Validation Loss: 65.65
2025-02-24 15:35:27,815 - Epoch 72, Training Loss: 70.50, Validation Loss: 66.35
2025-02-24 15:35:28,010 - Epoch 73, Training Loss: 65.05, Validation Loss: 67.34
2025-02-24 15:35:28,223 - Epoch 74, Training Loss: 80.31, Validation Loss: 66.97
2025-02-24 15:35:28,417 - Epoch 75, Training Loss: 81.51, Validation Loss: 65.89
2025-02-24 15:35:28,610 - Epoch 76, Training Loss: 67.24, Validation Loss: 65.08
2025-02-24 15:35:28,818 - Epoch 77, Training Loss: 69.81, Validation Loss: 64.87
2025-02-24 15:35:29,037 - Epoch 78, Training Loss: 68.03, Validation Loss: 64.88
2025-02-24 15:35:29,250 - Epoch 79, Training Loss: 66.29, Validation Loss: 64.48
2025-02-24 15:35:29,461 - Epoch 80, Training Loss: 75.50, Validation Loss: 63.97
2025-02-24 15:35:29,669 - Epoch 81, Training Loss: 67.59, Validation Loss: 63.54
2025-02-24 15:35:29,904 - Epoch 82, Training Loss: 74.18, Validation Loss: 63.73
2025-02-24 15:35:30,105 - Epoch 83, Training Loss: 76.80, Validation Loss: 63.97
2025-02-24 15:35:30,316 - Epoch 84, Training Loss: 81.13, Validation Loss: 63.62
2025-02-24 15:35:30,503 - Epoch 85, Training Loss: 76.12, Validation Loss: 62.79
2025-02-24 15:35:30,715 - Epoch 86, Training Loss: 76.15, Validation Loss: 62.51
2025-02-24 15:35:30,944 - Epoch 87, Training Loss: 68.20, Validation Loss: 62.26
2025-02-24 15:35:31,177 - Epoch 88, Training Loss: 70.27, Validation Loss: 62.25
2025-02-24 15:35:31,401 - Epoch 89, Training Loss: 66.17, Validation Loss: 62.66
2025-02-24 15:35:31,587 - Epoch 90, Training Loss: 68.57, Validation Loss: 63.47
2025-02-24 15:35:31,782 - Epoch 91, Training Loss: 66.69, Validation Loss: 63.90
2025-02-24 15:35:31,973 - Epoch 92, Training Loss: 68.29, Validation Loss: 63.78
2025-02-24 15:35:32,181 - Epoch 93, Training Loss: 67.15, Validation Loss: 64.03
2025-02-24 15:35:32,381 - Epoch 94, Training Loss: 76.76, Validation Loss: 64.03
2025-02-24 15:35:32,577 - Epoch 95, Training Loss: 67.32, Validation Loss: 64.09
2025-02-24 15:35:32,761 - Epoch 96, Training Loss: 73.11, Validation Loss: 64.44
2025-02-24 15:35:32,955 - Epoch 97, Training Loss: 68.73, Validation Loss: 64.09
2025-02-24 15:35:33,158 - Epoch 98, Training Loss: 70.86, Validation Loss: 63.77
2025-02-24 15:35:33,369 - Epoch 99, Training Loss: 80.19, Validation Loss: 64.73
2025-02-24 15:35:33,557 - Epoch 100, Training Loss: 70.22, Validation Loss: 65.19
2025-02-24 15:35:33,752 - Epoch 101, Training Loss: 78.38, Validation Loss: 66.05
2025-02-24 15:35:33,945 - Epoch 102, Training Loss: 76.50, Validation Loss: 66.43
2025-02-24 15:35:34,142 - Epoch 103, Training Loss: 75.31, Validation Loss: 65.94
2025-02-24 15:35:34,358 - Epoch 104, Training Loss: 77.82, Validation Loss: 65.18
2025-02-24 15:35:34,549 - Epoch 105, Training Loss: 76.86, Validation Loss: 64.84
2025-02-24 15:35:34,742 - Epoch 106, Training Loss: 78.16, Validation Loss: 64.36
2025-02-24 15:35:34,930 - Epoch 107, Training Loss: 68.08, Validation Loss: 64.27
2025-02-24 15:35:35,136 - Epoch 108, Training Loss: 74.26, Validation Loss: 64.34
2025-02-24 15:35:35,136 - Early stopping at epoch 108 due to no improvement in validation loss.
2025-02-24 15:35:35,387 - learning rate: 0.02
2025-02-24 15:35:35,387 - Test RMSE: 7.444543838500977, Test MAE: 1.1670073866844177
2025-02-24 15:35:45,070 - -----------------------Starting training-------------------------
2025-02-24 15:35:45,070 - learning rate: 0.01
2025-02-24 15:35:45,269 - Epoch 1, Training Loss: 195.68, Validation Loss: 209.62
2025-02-24 15:35:45,485 - Epoch 2, Training Loss: 158.99, Validation Loss: 198.92
2025-02-24 15:35:45,692 - Epoch 3, Training Loss: 149.65, Validation Loss: 189.23
2025-02-24 15:35:45,903 - Epoch 4, Training Loss: 130.08, Validation Loss: 180.71
2025-02-24 15:35:46,120 - Epoch 5, Training Loss: 140.92, Validation Loss: 173.22
2025-02-24 15:35:46,358 - Epoch 6, Training Loss: 132.15, Validation Loss: 166.30
2025-02-24 15:35:46,564 - Epoch 7, Training Loss: 118.76, Validation Loss: 160.05
2025-02-24 15:35:46,775 - Epoch 8, Training Loss: 121.50, Validation Loss: 154.60
2025-02-24 15:35:46,990 - Epoch 9, Training Loss: 132.72, Validation Loss: 149.40
2025-02-24 15:35:47,214 - Epoch 10, Training Loss: 126.95, Validation Loss: 144.37
2025-02-24 15:35:47,452 - Epoch 11, Training Loss: 122.68, Validation Loss: 139.90
2025-02-24 15:35:47,671 - Epoch 12, Training Loss: 110.43, Validation Loss: 135.72
2025-02-24 15:35:47,890 - Epoch 13, Training Loss: 105.86, Validation Loss: 132.02
2025-02-24 15:35:48,107 - Epoch 14, Training Loss: 93.62, Validation Loss: 128.79
2025-02-24 15:35:48,334 - Epoch 15, Training Loss: 117.96, Validation Loss: 125.86
2025-02-24 15:35:48,543 - Epoch 16, Training Loss: 93.54, Validation Loss: 122.76
2025-02-24 15:35:48,763 - Epoch 17, Training Loss: 132.70, Validation Loss: 120.00
2025-02-24 15:35:48,977 - Epoch 18, Training Loss: 105.42, Validation Loss: 116.99
2025-02-24 15:35:49,205 - Epoch 19, Training Loss: 91.95, Validation Loss: 114.35
2025-02-24 15:35:49,438 - Epoch 20, Training Loss: 97.98, Validation Loss: 112.05
2025-02-24 15:35:49,645 - Epoch 21, Training Loss: 95.49, Validation Loss: 109.86
2025-02-24 15:35:49,854 - Epoch 22, Training Loss: 90.82, Validation Loss: 107.70
2025-02-24 15:35:50,070 - Epoch 23, Training Loss: 88.82, Validation Loss: 105.74
2025-02-24 15:35:50,298 - Epoch 24, Training Loss: 89.16, Validation Loss: 103.95
2025-02-24 15:35:50,513 - Epoch 25, Training Loss: 91.00, Validation Loss: 102.35
2025-02-24 15:35:50,718 - Epoch 26, Training Loss: 90.88, Validation Loss: 100.75
2025-02-24 15:35:50,935 - Epoch 27, Training Loss: 80.39, Validation Loss: 99.42
2025-02-24 15:35:51,157 - Epoch 28, Training Loss: 88.09, Validation Loss: 98.17
2025-02-24 15:35:51,395 - Epoch 29, Training Loss: 94.81, Validation Loss: 96.60
2025-02-24 15:35:51,599 - Epoch 30, Training Loss: 83.30, Validation Loss: 94.89
2025-02-24 15:35:51,804 - Epoch 31, Training Loss: 85.45, Validation Loss: 93.43
2025-02-24 15:35:52,017 - Epoch 32, Training Loss: 80.67, Validation Loss: 92.03
2025-02-24 15:35:52,239 - Epoch 33, Training Loss: 81.05, Validation Loss: 90.94
2025-02-24 15:35:52,463 - Epoch 34, Training Loss: 81.55, Validation Loss: 90.03
2025-02-24 15:35:52,670 - Epoch 35, Training Loss: 80.25, Validation Loss: 89.03
2025-02-24 15:35:52,879 - Epoch 36, Training Loss: 83.84, Validation Loss: 88.05
2025-02-24 15:35:53,098 - Epoch 37, Training Loss: 85.19, Validation Loss: 87.00
2025-02-24 15:35:53,328 - Epoch 38, Training Loss: 80.53, Validation Loss: 86.25
2025-02-24 15:35:53,538 - Epoch 39, Training Loss: 70.62, Validation Loss: 85.45
2025-02-24 15:35:53,747 - Epoch 40, Training Loss: 75.48, Validation Loss: 84.82
2025-02-24 15:35:53,958 - Epoch 41, Training Loss: 77.95, Validation Loss: 84.05
2025-02-24 15:35:54,177 - Epoch 42, Training Loss: 78.25, Validation Loss: 82.98
2025-02-24 15:35:54,409 - Epoch 43, Training Loss: 77.44, Validation Loss: 82.05
2025-02-24 15:35:54,613 - Epoch 44, Training Loss: 82.04, Validation Loss: 81.25
2025-02-24 15:35:54,827 - Epoch 45, Training Loss: 71.31, Validation Loss: 80.61
2025-02-24 15:35:55,043 - Epoch 46, Training Loss: 84.86, Validation Loss: 80.14
2025-02-24 15:35:55,270 - Epoch 47, Training Loss: 73.63, Validation Loss: 79.64
2025-02-24 15:35:55,493 - Epoch 48, Training Loss: 75.86, Validation Loss: 79.38
2025-02-24 15:35:55,708 - Epoch 49, Training Loss: 81.87, Validation Loss: 78.89
2025-02-24 15:35:55,939 - Epoch 50, Training Loss: 77.95, Validation Loss: 78.42
2025-02-24 15:35:56,158 - Epoch 51, Training Loss: 72.93, Validation Loss: 77.76
2025-02-24 15:35:56,399 - Epoch 52, Training Loss: 72.55, Validation Loss: 77.62
2025-02-24 15:35:56,609 - Epoch 53, Training Loss: 79.66, Validation Loss: 77.38
2025-02-24 15:35:56,821 - Epoch 54, Training Loss: 73.67, Validation Loss: 76.59
2025-02-24 15:35:57,039 - Epoch 55, Training Loss: 76.30, Validation Loss: 76.15
2025-02-24 15:35:57,270 - Epoch 56, Training Loss: 71.93, Validation Loss: 75.79
2025-02-24 15:35:57,483 - Epoch 57, Training Loss: 66.43, Validation Loss: 75.71
2025-02-24 15:35:57,697 - Epoch 58, Training Loss: 80.98, Validation Loss: 75.32
2025-02-24 15:35:57,911 - Epoch 59, Training Loss: 74.62, Validation Loss: 74.62
2025-02-24 15:35:58,127 - Epoch 60, Training Loss: 83.00, Validation Loss: 74.10
2025-02-24 15:35:58,356 - Epoch 61, Training Loss: 72.82, Validation Loss: 73.62
2025-02-24 15:35:58,589 - Epoch 62, Training Loss: 75.98, Validation Loss: 73.37
2025-02-24 15:35:58,811 - Epoch 63, Training Loss: 79.48, Validation Loss: 73.03
2025-02-24 15:35:59,033 - Epoch 64, Training Loss: 74.59, Validation Loss: 72.77
2025-02-24 15:35:59,299 - Epoch 65, Training Loss: 77.12, Validation Loss: 72.48
2025-02-24 15:35:59,544 - Epoch 66, Training Loss: 73.62, Validation Loss: 72.32
2025-02-24 15:35:59,785 - Epoch 67, Training Loss: 70.13, Validation Loss: 72.02
2025-02-24 15:36:00,045 - Epoch 68, Training Loss: 73.47, Validation Loss: 71.69
2025-02-24 15:36:00,296 - Epoch 69, Training Loss: 69.21, Validation Loss: 71.52
2025-02-24 15:36:00,530 - Epoch 70, Training Loss: 68.30, Validation Loss: 71.18
2025-02-24 15:36:00,801 - Epoch 71, Training Loss: 67.15, Validation Loss: 71.20
2025-02-24 15:36:01,034 - Epoch 72, Training Loss: 69.85, Validation Loss: 71.45
2025-02-24 15:36:01,259 - Epoch 73, Training Loss: 66.65, Validation Loss: 71.94
2025-02-24 15:36:01,488 - Epoch 74, Training Loss: 81.99, Validation Loss: 71.70
2025-02-24 15:36:01,674 - Epoch 75, Training Loss: 83.89, Validation Loss: 70.95
2025-02-24 15:36:01,883 - Epoch 76, Training Loss: 68.12, Validation Loss: 70.27
2025-02-24 15:36:02,110 - Epoch 77, Training Loss: 69.92, Validation Loss: 69.92
2025-02-24 15:36:02,346 - Epoch 78, Training Loss: 69.89, Validation Loss: 69.73
2025-02-24 15:36:02,549 - Epoch 79, Training Loss: 67.72, Validation Loss: 69.32
2025-02-24 15:36:02,759 - Epoch 80, Training Loss: 77.93, Validation Loss: 68.79
2025-02-24 15:36:02,970 - Epoch 81, Training Loss: 67.80, Validation Loss: 68.29
2025-02-24 15:36:03,192 - Epoch 82, Training Loss: 74.61, Validation Loss: 68.18
2025-02-24 15:36:03,415 - Epoch 83, Training Loss: 77.85, Validation Loss: 68.16
2025-02-24 15:36:03,628 - Epoch 84, Training Loss: 83.02, Validation Loss: 67.86
2025-02-24 15:36:03,841 - Epoch 85, Training Loss: 76.99, Validation Loss: 67.22
2025-02-24 15:36:04,056 - Epoch 86, Training Loss: 77.17, Validation Loss: 66.84
2025-02-24 15:36:04,285 - Epoch 87, Training Loss: 68.83, Validation Loss: 66.49
2025-02-24 15:36:04,496 - Epoch 88, Training Loss: 71.07, Validation Loss: 66.28
2025-02-24 15:36:04,710 - Epoch 89, Training Loss: 65.93, Validation Loss: 66.35
2025-02-24 15:36:04,906 - Epoch 90, Training Loss: 68.59, Validation Loss: 66.72
2025-02-24 15:36:05,102 - Epoch 91, Training Loss: 67.84, Validation Loss: 66.92
2025-02-24 15:36:05,312 - Epoch 92, Training Loss: 68.22, Validation Loss: 66.78
2025-02-24 15:36:05,507 - Epoch 93, Training Loss: 67.34, Validation Loss: 66.87
2025-02-24 15:36:05,694 - Epoch 94, Training Loss: 77.50, Validation Loss: 66.83
2025-02-24 15:36:05,883 - Epoch 95, Training Loss: 67.00, Validation Loss: 66.82
2025-02-24 15:36:06,073 - Epoch 96, Training Loss: 74.03, Validation Loss: 66.99
2025-02-24 15:36:06,276 - Epoch 97, Training Loss: 69.22, Validation Loss: 66.76
2025-02-24 15:36:06,472 - Epoch 98, Training Loss: 69.82, Validation Loss: 66.49
2025-02-24 15:36:06,659 - Epoch 99, Training Loss: 80.04, Validation Loss: 66.94
2025-02-24 15:36:06,850 - Epoch 100, Training Loss: 69.84, Validation Loss: 67.20
2025-02-24 15:36:07,049 - Epoch 101, Training Loss: 78.13, Validation Loss: 67.71
2025-02-24 15:36:07,243 - Epoch 102, Training Loss: 76.62, Validation Loss: 67.98
2025-02-24 15:36:07,446 - Epoch 103, Training Loss: 75.58, Validation Loss: 67.74
2025-02-24 15:36:07,625 - Epoch 104, Training Loss: 77.70, Validation Loss: 67.27
2025-02-24 15:36:07,814 - Epoch 105, Training Loss: 77.15, Validation Loss: 67.00
2025-02-24 15:36:08,000 - Epoch 106, Training Loss: 78.12, Validation Loss: 66.63
2025-02-24 15:36:08,198 - Epoch 107, Training Loss: 67.89, Validation Loss: 66.47
2025-02-24 15:36:08,403 - Epoch 108, Training Loss: 74.52, Validation Loss: 66.37
2025-02-24 15:36:08,403 - Early stopping at epoch 108 due to no improvement in validation loss.
2025-02-24 15:36:08,613 - learning rate: 0.01
2025-02-24 15:36:08,614 - Test RMSE: 7.49436092376709, Test MAE: 1.153751790523529
2025-02-24 15:36:33,894 - -----------------------Starting training-------------------------
2025-02-24 15:36:33,894 - learning rate: 0.005
2025-02-24 15:36:34,082 - Epoch 1, Training Loss: 198.13, Validation Loss: 216.05
2025-02-24 15:36:34,317 - Epoch 2, Training Loss: 164.15, Validation Loss: 206.47
2025-02-24 15:36:34,531 - Epoch 3, Training Loss: 154.92, Validation Loss: 197.81
2025-02-24 15:36:34,748 - Epoch 4, Training Loss: 135.83, Validation Loss: 190.55
2025-02-24 15:36:34,973 - Epoch 5, Training Loss: 148.10, Validation Loss: 183.97
2025-02-24 15:36:35,211 - Epoch 6, Training Loss: 140.25, Validation Loss: 177.74
2025-02-24 15:36:35,433 - Epoch 7, Training Loss: 125.84, Validation Loss: 172.01
2025-02-24 15:36:35,647 - Epoch 8, Training Loss: 130.07, Validation Loss: 166.89
2025-02-24 15:36:35,875 - Epoch 9, Training Loss: 142.50, Validation Loss: 162.01
2025-02-24 15:36:36,096 - Epoch 10, Training Loss: 135.80, Validation Loss: 157.38
2025-02-24 15:36:36,331 - Epoch 11, Training Loss: 131.96, Validation Loss: 153.22
2025-02-24 15:36:36,533 - Epoch 12, Training Loss: 119.03, Validation Loss: 149.42
2025-02-24 15:36:36,751 - Epoch 13, Training Loss: 114.68, Validation Loss: 146.00
2025-02-24 15:36:36,982 - Epoch 14, Training Loss: 101.28, Validation Loss: 142.96
2025-02-24 15:36:37,230 - Epoch 15, Training Loss: 128.89, Validation Loss: 140.20
2025-02-24 15:36:37,445 - Epoch 16, Training Loss: 101.74, Validation Loss: 137.33
2025-02-24 15:36:37,665 - Epoch 17, Training Loss: 146.04, Validation Loss: 134.71
2025-02-24 15:36:37,886 - Epoch 18, Training Loss: 114.99, Validation Loss: 131.90
2025-02-24 15:36:38,114 - Epoch 19, Training Loss: 101.24, Validation Loss: 129.38
2025-02-24 15:36:38,343 - Epoch 20, Training Loss: 108.60, Validation Loss: 127.10
2025-02-24 15:36:38,588 - Epoch 21, Training Loss: 105.80, Validation Loss: 124.92
2025-02-24 15:36:38,831 - Epoch 22, Training Loss: 100.10, Validation Loss: 122.78
2025-02-24 15:36:39,104 - Epoch 23, Training Loss: 98.70, Validation Loss: 120.79
2025-02-24 15:36:39,397 - Epoch 24, Training Loss: 98.07, Validation Loss: 118.93
2025-02-24 15:36:39,642 - Epoch 25, Training Loss: 101.19, Validation Loss: 117.20
2025-02-24 15:36:39,875 - Epoch 26, Training Loss: 99.57, Validation Loss: 115.49
2025-02-24 15:36:40,150 - Epoch 27, Training Loss: 88.57, Validation Loss: 113.99
2025-02-24 15:36:40,412 - Epoch 28, Training Loss: 98.38, Validation Loss: 112.57
2025-02-24 15:36:40,637 - Epoch 29, Training Loss: 106.82, Validation Loss: 110.91
2025-02-24 15:36:40,870 - Epoch 30, Training Loss: 92.65, Validation Loss: 109.15
2025-02-24 15:36:41,079 - Epoch 31, Training Loss: 96.32, Validation Loss: 107.57
2025-02-24 15:36:41,317 - Epoch 32, Training Loss: 88.66, Validation Loss: 106.02
2025-02-24 15:36:41,534 - Epoch 33, Training Loss: 89.48, Validation Loss: 104.73
2025-02-24 15:36:41,743 - Epoch 34, Training Loss: 90.22, Validation Loss: 103.59
2025-02-24 15:36:41,968 - Epoch 35, Training Loss: 89.08, Validation Loss: 102.44
2025-02-24 15:36:42,204 - Epoch 36, Training Loss: 93.59, Validation Loss: 101.29
2025-02-24 15:36:42,416 - Epoch 37, Training Loss: 93.01, Validation Loss: 100.08
2025-02-24 15:36:42,620 - Epoch 38, Training Loss: 88.14, Validation Loss: 99.11
2025-02-24 15:36:42,828 - Epoch 39, Training Loss: 77.49, Validation Loss: 98.12
2025-02-24 15:36:43,050 - Epoch 40, Training Loss: 82.86, Validation Loss: 97.26
2025-02-24 15:36:43,282 - Epoch 41, Training Loss: 86.69, Validation Loss: 96.33
2025-02-24 15:36:43,500 - Epoch 42, Training Loss: 85.85, Validation Loss: 95.20
2025-02-24 15:36:43,708 - Epoch 43, Training Loss: 84.55, Validation Loss: 94.16
2025-02-24 15:36:43,924 - Epoch 44, Training Loss: 89.49, Validation Loss: 93.20
2025-02-24 15:36:44,154 - Epoch 45, Training Loss: 77.35, Validation Loss: 92.36
2025-02-24 15:36:44,375 - Epoch 46, Training Loss: 92.98, Validation Loss: 91.66
2025-02-24 15:36:44,578 - Epoch 47, Training Loss: 77.62, Validation Loss: 90.96
2025-02-24 15:36:44,796 - Epoch 48, Training Loss: 82.45, Validation Loss: 90.45
2025-02-24 15:36:45,022 - Epoch 49, Training Loss: 87.65, Validation Loss: 89.78
2025-02-24 15:36:45,258 - Epoch 50, Training Loss: 86.25, Validation Loss: 89.12
2025-02-24 15:36:45,463 - Epoch 51, Training Loss: 76.40, Validation Loss: 88.32
2025-02-24 15:36:45,677 - Epoch 52, Training Loss: 77.20, Validation Loss: 87.90
2025-02-24 15:36:45,896 - Epoch 53, Training Loss: 87.28, Validation Loss: 87.44
2025-02-24 15:36:46,121 - Epoch 54, Training Loss: 77.69, Validation Loss: 86.63
2025-02-24 15:36:46,350 - Epoch 55, Training Loss: 81.47, Validation Loss: 86.05
2025-02-24 15:36:46,553 - Epoch 56, Training Loss: 75.27, Validation Loss: 85.52
2025-02-24 15:36:46,768 - Epoch 57, Training Loss: 71.23, Validation Loss: 85.19
2025-02-24 15:36:46,983 - Epoch 58, Training Loss: 87.69, Validation Loss: 84.66
2025-02-24 15:36:47,224 - Epoch 59, Training Loss: 78.98, Validation Loss: 83.92
2025-02-24 15:36:47,440 - Epoch 60, Training Loss: 88.88, Validation Loss: 83.28
2025-02-24 15:36:47,641 - Epoch 61, Training Loss: 76.66, Validation Loss: 82.68
2025-02-24 15:36:47,857 - Epoch 62, Training Loss: 81.03, Validation Loss: 82.23
2025-02-24 15:36:48,078 - Epoch 63, Training Loss: 83.33, Validation Loss: 81.74
2025-02-24 15:36:48,294 - Epoch 64, Training Loss: 80.73, Validation Loss: 81.32
2025-02-24 15:36:48,512 - Epoch 65, Training Loss: 79.33, Validation Loss: 80.88
2025-02-24 15:36:48,724 - Epoch 66, Training Loss: 78.80, Validation Loss: 80.55
2025-02-24 15:36:48,940 - Epoch 67, Training Loss: 74.42, Validation Loss: 80.12
2025-02-24 15:36:49,166 - Epoch 68, Training Loss: 76.98, Validation Loss: 79.66
2025-02-24 15:36:49,383 - Epoch 69, Training Loss: 73.84, Validation Loss: 79.31
2025-02-24 15:36:49,593 - Epoch 70, Training Loss: 70.09, Validation Loss: 78.87
2025-02-24 15:36:49,805 - Epoch 71, Training Loss: 69.80, Validation Loss: 78.70
2025-02-24 15:36:50,027 - Epoch 72, Training Loss: 70.56, Validation Loss: 78.70
2025-02-24 15:36:50,234 - Epoch 73, Training Loss: 70.27, Validation Loss: 78.89
2025-02-24 15:36:50,426 - Epoch 74, Training Loss: 85.98, Validation Loss: 78.59
2025-02-24 15:36:50,631 - Epoch 75, Training Loss: 89.12, Validation Loss: 77.92
2025-02-24 15:36:50,849 - Epoch 76, Training Loss: 70.91, Validation Loss: 77.26
2025-02-24 15:36:51,065 - Epoch 77, Training Loss: 71.77, Validation Loss: 76.82
2025-02-24 15:36:51,298 - Epoch 78, Training Loss: 73.54, Validation Loss: 76.51
2025-02-24 15:36:51,508 - Epoch 79, Training Loss: 70.95, Validation Loss: 76.05
2025-02-24 15:36:51,711 - Epoch 80, Training Loss: 82.41, Validation Loss: 75.49
2025-02-24 15:36:51,931 - Epoch 81, Training Loss: 69.50, Validation Loss: 74.94
2025-02-24 15:36:52,155 - Epoch 82, Training Loss: 76.66, Validation Loss: 74.66
2025-02-24 15:36:52,383 - Epoch 83, Training Loss: 80.90, Validation Loss: 74.46
2025-02-24 15:36:52,591 - Epoch 84, Training Loss: 87.39, Validation Loss: 74.09
2025-02-24 15:36:52,798 - Epoch 85, Training Loss: 79.85, Validation Loss: 73.48
2025-02-24 15:36:53,029 - Epoch 86, Training Loss: 79.91, Validation Loss: 73.04
2025-02-24 15:36:53,276 - Epoch 87, Training Loss: 71.10, Validation Loss: 72.60
2025-02-24 15:36:53,484 - Epoch 88, Training Loss: 73.42, Validation Loss: 72.28
2025-02-24 15:36:53,694 - Epoch 89, Training Loss: 66.89, Validation Loss: 72.16
2025-02-24 15:36:53,910 - Epoch 90, Training Loss: 70.12, Validation Loss: 72.26
2025-02-24 15:36:54,109 - Epoch 91, Training Loss: 70.89, Validation Loss: 72.28
2025-02-24 15:36:54,319 - Epoch 92, Training Loss: 69.20, Validation Loss: 72.07
2025-02-24 15:36:54,524 - Epoch 93, Training Loss: 69.12, Validation Loss: 72.01
2025-02-24 15:36:54,733 - Epoch 94, Training Loss: 79.92, Validation Loss: 71.89
2025-02-24 15:36:54,948 - Epoch 95, Training Loss: 67.56, Validation Loss: 71.78
2025-02-24 15:36:55,178 - Epoch 96, Training Loss: 76.87, Validation Loss: 71.80
2025-02-24 15:36:55,375 - Epoch 97, Training Loss: 71.11, Validation Loss: 71.55
2025-02-24 15:36:55,585 - Epoch 98, Training Loss: 69.35, Validation Loss: 71.27
2025-02-24 15:36:55,793 - Epoch 99, Training Loss: 81.18, Validation Loss: 71.47
2025-02-24 15:36:55,988 - Epoch 100, Training Loss: 70.05, Validation Loss: 71.58
2025-02-24 15:36:56,193 - Epoch 101, Training Loss: 78.74, Validation Loss: 71.87
2025-02-24 15:36:56,392 - Epoch 102, Training Loss: 78.04, Validation Loss: 72.01
2025-02-24 15:36:56,580 - Epoch 103, Training Loss: 77.33, Validation Loss: 71.81
2025-02-24 15:36:56,759 - Epoch 104, Training Loss: 78.64, Validation Loss: 71.42
2025-02-24 15:36:56,961 - Epoch 105, Training Loss: 78.63, Validation Loss: 71.15
2025-02-24 15:36:57,198 - Epoch 106, Training Loss: 78.89, Validation Loss: 70.80
2025-02-24 15:36:57,409 - Epoch 107, Training Loss: 68.53, Validation Loss: 70.59
2025-02-24 15:36:57,612 - Epoch 108, Training Loss: 76.31, Validation Loss: 70.43
2025-02-24 15:36:57,829 - Epoch 109, Training Loss: 67.49, Validation Loss: 70.13
2025-02-24 15:36:58,046 - Epoch 110, Training Loss: 70.86, Validation Loss: 69.82
2025-02-24 15:36:58,281 - Epoch 111, Training Loss: 67.77, Validation Loss: 69.74
2025-02-24 15:36:58,489 - Epoch 112, Training Loss: 75.17, Validation Loss: 69.81
2025-02-24 15:36:58,674 - Epoch 113, Training Loss: 93.02, Validation Loss: 69.75
2025-02-24 15:36:58,866 - Epoch 114, Training Loss: 71.13, Validation Loss: 69.31
2025-02-24 15:36:59,077 - Epoch 115, Training Loss: 69.18, Validation Loss: 69.14
2025-02-24 15:36:59,294 - Epoch 116, Training Loss: 74.32, Validation Loss: 69.01
2025-02-24 15:36:59,510 - Epoch 117, Training Loss: 77.18, Validation Loss: 68.93
2025-02-24 15:36:59,729 - Epoch 118, Training Loss: 78.67, Validation Loss: 68.87
2025-02-24 15:36:59,944 - Epoch 119, Training Loss: 68.54, Validation Loss: 68.93
2025-02-24 15:37:00,154 - Epoch 120, Training Loss: 70.63, Validation Loss: 69.15
2025-02-24 15:37:00,356 - Epoch 121, Training Loss: 69.52, Validation Loss: 69.26
2025-02-24 15:37:00,537 - Epoch 122, Training Loss: 72.60, Validation Loss: 69.27
2025-02-24 15:37:00,723 - Epoch 123, Training Loss: 73.52, Validation Loss: 69.23
2025-02-24 15:37:00,947 - Epoch 124, Training Loss: 71.01, Validation Loss: 68.97
2025-02-24 15:37:01,169 - Epoch 125, Training Loss: 66.25, Validation Loss: 68.80
2025-02-24 15:37:01,386 - Epoch 126, Training Loss: 75.08, Validation Loss: 68.77
2025-02-24 15:37:01,594 - Epoch 127, Training Loss: 68.93, Validation Loss: 68.59
2025-02-24 15:37:01,808 - Epoch 128, Training Loss: 66.24, Validation Loss: 68.39
2025-02-24 15:37:02,021 - Epoch 129, Training Loss: 75.37, Validation Loss: 68.43
2025-02-24 15:37:02,230 - Epoch 130, Training Loss: 64.64, Validation Loss: 68.70
2025-02-24 15:37:02,428 - Epoch 131, Training Loss: 77.19, Validation Loss: 68.95
2025-02-24 15:37:02,617 - Epoch 132, Training Loss: 75.09, Validation Loss: 69.05
2025-02-24 15:37:02,799 - Epoch 133, Training Loss: 72.38, Validation Loss: 69.16
2025-02-24 15:37:02,992 - Epoch 134, Training Loss: 68.58, Validation Loss: 68.98
2025-02-24 15:37:03,196 - Epoch 135, Training Loss: 66.73, Validation Loss: 69.05
2025-02-24 15:37:03,386 - Epoch 136, Training Loss: 70.30, Validation Loss: 69.02
2025-02-24 15:37:03,576 - Epoch 137, Training Loss: 76.88, Validation Loss: 68.98
2025-02-24 15:37:03,763 - Epoch 138, Training Loss: 73.74, Validation Loss: 68.88
2025-02-24 15:37:03,961 - Epoch 139, Training Loss: 73.71, Validation Loss: 68.65
2025-02-24 15:37:04,159 - Epoch 140, Training Loss: 75.42, Validation Loss: 68.32
2025-02-24 15:37:04,374 - Epoch 141, Training Loss: 67.92, Validation Loss: 68.08
2025-02-24 15:37:04,580 - Epoch 142, Training Loss: 68.34, Validation Loss: 68.02
2025-02-24 15:37:04,793 - Epoch 143, Training Loss: 73.02, Validation Loss: 67.98
2025-02-24 15:37:05,014 - Epoch 144, Training Loss: 77.59, Validation Loss: 67.67
2025-02-24 15:37:05,253 - Epoch 145, Training Loss: 75.97, Validation Loss: 67.45
2025-02-24 15:37:05,460 - Epoch 146, Training Loss: 68.03, Validation Loss: 67.37
2025-02-24 15:37:05,670 - Epoch 147, Training Loss: 73.83, Validation Loss: 67.21
2025-02-24 15:37:05,890 - Epoch 148, Training Loss: 67.27, Validation Loss: 67.13
2025-02-24 15:37:06,112 - Epoch 149, Training Loss: 77.43, Validation Loss: 67.27
2025-02-24 15:37:06,317 - Epoch 150, Training Loss: 76.40, Validation Loss: 67.43
2025-02-24 15:37:06,509 - Epoch 151, Training Loss: 72.14, Validation Loss: 67.30
2025-02-24 15:37:06,706 - Epoch 152, Training Loss: 68.52, Validation Loss: 67.04
2025-02-24 15:37:06,933 - Epoch 153, Training Loss: 65.50, Validation Loss: 66.82
2025-02-24 15:37:07,167 - Epoch 154, Training Loss: 64.93, Validation Loss: 66.71
2025-02-24 15:37:07,394 - Epoch 155, Training Loss: 73.00, Validation Loss: 66.82
2025-02-24 15:37:07,595 - Epoch 156, Training Loss: 72.85, Validation Loss: 67.25
2025-02-24 15:37:07,800 - Epoch 157, Training Loss: 71.92, Validation Loss: 67.27
2025-02-24 15:37:07,994 - Epoch 158, Training Loss: 68.42, Validation Loss: 67.04
2025-02-24 15:37:08,209 - Epoch 159, Training Loss: 67.91, Validation Loss: 67.10
2025-02-24 15:37:08,405 - Epoch 160, Training Loss: 86.84, Validation Loss: 67.22
2025-02-24 15:37:08,597 - Epoch 161, Training Loss: 81.17, Validation Loss: 67.09
2025-02-24 15:37:08,791 - Epoch 162, Training Loss: 68.71, Validation Loss: 66.90
2025-02-24 15:37:08,986 - Epoch 163, Training Loss: 65.41, Validation Loss: 66.88
2025-02-24 15:37:09,202 - Epoch 164, Training Loss: 64.40, Validation Loss: 66.84
2025-02-24 15:37:09,396 - Epoch 165, Training Loss: 68.40, Validation Loss: 66.77
2025-02-24 15:37:09,588 - Epoch 166, Training Loss: 67.78, Validation Loss: 66.61
2025-02-24 15:37:09,949 - Epoch 167, Training Loss: 70.77, Validation Loss: 66.47
2025-02-24 15:37:10,180 - Epoch 168, Training Loss: 69.74, Validation Loss: 66.66
2025-02-24 15:37:10,399 - Epoch 169, Training Loss: 67.22, Validation Loss: 66.80
2025-02-24 15:37:10,787 - Epoch 170, Training Loss: 78.17, Validation Loss: 66.96
2025-02-24 15:37:11,295 - Epoch 171, Training Loss: 64.05, Validation Loss: 66.79
2025-02-24 15:37:11,495 - Epoch 172, Training Loss: 68.24, Validation Loss: 66.54
2025-02-24 15:37:11,695 - Epoch 173, Training Loss: 67.65, Validation Loss: 66.59
2025-02-24 15:37:11,895 - Epoch 174, Training Loss: 70.15, Validation Loss: 66.55
2025-02-24 15:37:12,093 - Epoch 175, Training Loss: 67.72, Validation Loss: 66.35
2025-02-24 15:37:12,309 - Epoch 176, Training Loss: 68.47, Validation Loss: 66.28
2025-02-24 15:37:12,525 - Epoch 177, Training Loss: 79.30, Validation Loss: 66.22
2025-02-24 15:37:12,745 - Epoch 178, Training Loss: 64.67, Validation Loss: 66.12
2025-02-24 15:37:12,959 - Epoch 179, Training Loss: 82.30, Validation Loss: 65.92
2025-02-24 15:37:13,192 - Epoch 180, Training Loss: 73.37, Validation Loss: 65.43
2025-02-24 15:37:13,400 - Epoch 181, Training Loss: 66.06, Validation Loss: 64.98
2025-02-24 15:37:13,619 - Epoch 182, Training Loss: 74.81, Validation Loss: 64.77
2025-02-24 15:37:13,847 - Epoch 183, Training Loss: 76.93, Validation Loss: 64.69
2025-02-24 15:37:14,064 - Epoch 184, Training Loss: 69.64, Validation Loss: 64.51
2025-02-24 15:37:14,298 - Epoch 185, Training Loss: 70.14, Validation Loss: 64.38
2025-02-24 15:37:14,512 - Epoch 186, Training Loss: 69.85, Validation Loss: 64.54
2025-02-24 15:37:14,726 - Epoch 187, Training Loss: 68.88, Validation Loss: 64.56
2025-02-24 15:37:14,932 - Epoch 188, Training Loss: 74.96, Validation Loss: 64.63
2025-02-24 15:37:15,156 - Epoch 189, Training Loss: 69.36, Validation Loss: 64.94
2025-02-24 15:37:15,370 - Epoch 190, Training Loss: 75.65, Validation Loss: 65.17
2025-02-24 15:37:15,562 - Epoch 191, Training Loss: 63.86, Validation Loss: 65.27
2025-02-24 15:37:15,768 - Epoch 192, Training Loss: 64.01, Validation Loss: 65.12
2025-02-24 15:37:15,980 - Epoch 193, Training Loss: 66.96, Validation Loss: 64.93
2025-02-24 15:37:16,192 - Epoch 194, Training Loss: 70.25, Validation Loss: 64.89
2025-02-24 15:37:16,384 - Epoch 195, Training Loss: 66.74, Validation Loss: 65.20
2025-02-24 15:37:16,591 - Epoch 196, Training Loss: 72.95, Validation Loss: 65.36
2025-02-24 15:37:16,818 - Epoch 197, Training Loss: 67.26, Validation Loss: 65.39
2025-02-24 15:37:17,026 - Epoch 198, Training Loss: 70.05, Validation Loss: 65.60
2025-02-24 15:37:17,253 - Epoch 199, Training Loss: 71.89, Validation Loss: 65.42
2025-02-24 15:37:17,447 - Epoch 200, Training Loss: 63.97, Validation Loss: 65.23
2025-02-24 15:37:17,656 - Epoch 201, Training Loss: 82.68, Validation Loss: 65.04
2025-02-24 15:37:17,854 - Epoch 202, Training Loss: 74.34, Validation Loss: 64.71
2025-02-24 15:37:18,055 - Epoch 203, Training Loss: 70.93, Validation Loss: 64.49
2025-02-24 15:37:18,269 - Epoch 204, Training Loss: 67.92, Validation Loss: 64.73
2025-02-24 15:37:18,454 - Epoch 205, Training Loss: 78.56, Validation Loss: 65.01
2025-02-24 15:37:18,454 - Early stopping at epoch 205 due to no improvement in validation loss.
2025-02-24 15:37:18,699 - learning rate: 0.005
2025-02-24 15:37:18,699 - Test RMSE: 7.445075511932373, Test MAE: 1.151559054851532
2025-02-24 20:30:27,995 - -----------------------Starting training-------------------------
2025-02-24 20:30:27,995 - learning rate: 0.01
2025-02-24 20:30:28,227 - Epoch 1, Training Loss: 195.68, Validation Loss: 209.62
2025-02-24 20:30:28,450 - Epoch 2, Training Loss: 158.99, Validation Loss: 198.92
2025-02-24 20:30:28,662 - Epoch 3, Training Loss: 149.65, Validation Loss: 189.23
2025-02-24 20:30:28,877 - Epoch 4, Training Loss: 130.08, Validation Loss: 180.71
2025-02-24 20:30:29,088 - Epoch 5, Training Loss: 140.92, Validation Loss: 173.22
2025-02-24 20:30:29,309 - Epoch 6, Training Loss: 132.15, Validation Loss: 166.30
2025-02-24 20:30:29,525 - Epoch 7, Training Loss: 118.76, Validation Loss: 160.05
2025-02-24 20:30:29,740 - Epoch 8, Training Loss: 121.50, Validation Loss: 154.60
2025-02-24 20:30:29,948 - Epoch 9, Training Loss: 132.72, Validation Loss: 149.40
2025-02-24 20:30:30,166 - Epoch 10, Training Loss: 126.95, Validation Loss: 144.37
2025-02-24 20:30:30,393 - Epoch 11, Training Loss: 122.68, Validation Loss: 139.90
2025-02-24 20:30:30,608 - Epoch 12, Training Loss: 110.43, Validation Loss: 135.72
2025-02-24 20:30:30,820 - Epoch 13, Training Loss: 105.86, Validation Loss: 132.02
2025-02-24 20:30:31,041 - Epoch 14, Training Loss: 93.62, Validation Loss: 128.79
2025-02-24 20:30:31,252 - Epoch 15, Training Loss: 117.96, Validation Loss: 125.86
2025-02-24 20:30:31,472 - Epoch 16, Training Loss: 93.54, Validation Loss: 122.76
2025-02-24 20:30:31,691 - Epoch 17, Training Loss: 132.70, Validation Loss: 120.00
2025-02-24 20:30:31,906 - Epoch 18, Training Loss: 105.42, Validation Loss: 116.99
2025-02-24 20:30:32,119 - Epoch 19, Training Loss: 91.95, Validation Loss: 114.35
2025-02-24 20:30:32,340 - Epoch 20, Training Loss: 97.98, Validation Loss: 112.05
2025-02-24 20:30:32,549 - Epoch 21, Training Loss: 95.49, Validation Loss: 109.86
2025-02-24 20:30:32,768 - Epoch 22, Training Loss: 90.82, Validation Loss: 107.70
2025-02-24 20:30:32,988 - Epoch 23, Training Loss: 88.82, Validation Loss: 105.74
2025-02-24 20:30:33,197 - Epoch 24, Training Loss: 89.16, Validation Loss: 103.95
2025-02-24 20:30:33,411 - Epoch 25, Training Loss: 91.00, Validation Loss: 102.35
2025-02-24 20:30:33,623 - Epoch 26, Training Loss: 90.88, Validation Loss: 100.75
2025-02-24 20:30:33,846 - Epoch 27, Training Loss: 80.39, Validation Loss: 99.42
2025-02-24 20:30:34,070 - Epoch 28, Training Loss: 88.09, Validation Loss: 98.17
2025-02-24 20:30:34,286 - Epoch 29, Training Loss: 94.81, Validation Loss: 96.60
2025-02-24 20:30:34,499 - Epoch 30, Training Loss: 83.30, Validation Loss: 94.89
2025-02-24 20:30:34,712 - Epoch 31, Training Loss: 85.45, Validation Loss: 93.43
2025-02-24 20:30:34,923 - Epoch 32, Training Loss: 80.67, Validation Loss: 92.03
2025-02-24 20:30:35,138 - Epoch 33, Training Loss: 81.05, Validation Loss: 90.94
2025-02-24 20:30:35,354 - Epoch 34, Training Loss: 81.55, Validation Loss: 90.03
2025-02-24 20:30:35,567 - Epoch 35, Training Loss: 80.25, Validation Loss: 89.03
2025-02-24 20:30:35,781 - Epoch 36, Training Loss: 83.84, Validation Loss: 88.05
2025-02-24 20:30:36,002 - Epoch 37, Training Loss: 85.19, Validation Loss: 87.00
2025-02-24 20:30:36,217 - Epoch 38, Training Loss: 80.53, Validation Loss: 86.25
2025-02-24 20:30:36,434 - Epoch 39, Training Loss: 70.62, Validation Loss: 85.45
2025-02-24 20:30:36,649 - Epoch 40, Training Loss: 75.48, Validation Loss: 84.82
2025-02-24 20:30:36,865 - Epoch 41, Training Loss: 77.95, Validation Loss: 84.05
2025-02-24 20:30:37,086 - Epoch 42, Training Loss: 78.25, Validation Loss: 82.98
2025-02-24 20:30:37,296 - Epoch 43, Training Loss: 77.44, Validation Loss: 82.05
2025-02-24 20:30:37,513 - Epoch 44, Training Loss: 82.04, Validation Loss: 81.25
2025-02-24 20:30:37,726 - Epoch 45, Training Loss: 71.31, Validation Loss: 80.61
2025-02-24 20:30:37,937 - Epoch 46, Training Loss: 84.86, Validation Loss: 80.14
2025-02-24 20:30:38,152 - Epoch 47, Training Loss: 73.63, Validation Loss: 79.64
2025-02-24 20:30:38,378 - Epoch 48, Training Loss: 75.86, Validation Loss: 79.38
2025-02-24 20:30:38,619 - Epoch 49, Training Loss: 81.87, Validation Loss: 78.89
2025-02-24 20:30:38,834 - Epoch 50, Training Loss: 77.95, Validation Loss: 78.42
2025-02-24 20:30:39,050 - Epoch 51, Training Loss: 72.93, Validation Loss: 77.76
2025-02-24 20:30:39,266 - Epoch 52, Training Loss: 72.55, Validation Loss: 77.62
2025-02-24 20:30:39,488 - Epoch 53, Training Loss: 79.66, Validation Loss: 77.38
2025-02-24 20:30:39,737 - Epoch 54, Training Loss: 73.67, Validation Loss: 76.59
2025-02-24 20:30:39,955 - Epoch 55, Training Loss: 76.30, Validation Loss: 76.15
2025-02-24 20:30:40,182 - Epoch 56, Training Loss: 71.93, Validation Loss: 75.79
2025-02-24 20:30:40,401 - Epoch 57, Training Loss: 66.43, Validation Loss: 75.71
2025-02-24 20:30:40,621 - Epoch 58, Training Loss: 80.98, Validation Loss: 75.32
2025-02-24 20:30:40,836 - Epoch 59, Training Loss: 74.62, Validation Loss: 74.62
2025-02-24 20:30:41,047 - Epoch 60, Training Loss: 83.00, Validation Loss: 74.10
2025-02-24 20:30:41,272 - Epoch 61, Training Loss: 72.82, Validation Loss: 73.62
2025-02-24 20:30:41,484 - Epoch 62, Training Loss: 75.98, Validation Loss: 73.37
2025-02-24 20:30:41,707 - Epoch 63, Training Loss: 79.48, Validation Loss: 73.03
2025-02-24 20:30:41,935 - Epoch 64, Training Loss: 74.59, Validation Loss: 72.77
2025-02-24 20:30:42,155 - Epoch 65, Training Loss: 77.12, Validation Loss: 72.48
2025-02-24 20:30:42,367 - Epoch 66, Training Loss: 73.62, Validation Loss: 72.32
2025-02-24 20:30:42,587 - Epoch 67, Training Loss: 70.13, Validation Loss: 72.02
2025-02-24 20:30:42,807 - Epoch 68, Training Loss: 73.47, Validation Loss: 71.69
2025-02-24 20:30:43,026 - Epoch 69, Training Loss: 69.21, Validation Loss: 71.52
2025-02-24 20:30:43,265 - Epoch 70, Training Loss: 68.30, Validation Loss: 71.18
2025-02-24 20:30:43,486 - Epoch 71, Training Loss: 67.15, Validation Loss: 71.20
2025-02-24 20:30:43,680 - Epoch 72, Training Loss: 69.85, Validation Loss: 71.45
2025-02-24 20:30:43,880 - Epoch 73, Training Loss: 66.65, Validation Loss: 71.94
2025-02-24 20:30:44,069 - Epoch 74, Training Loss: 81.99, Validation Loss: 71.70
2025-02-24 20:30:44,262 - Epoch 75, Training Loss: 83.89, Validation Loss: 70.95
2025-02-24 20:30:44,475 - Epoch 76, Training Loss: 68.12, Validation Loss: 70.27
2025-02-24 20:30:44,689 - Epoch 77, Training Loss: 69.92, Validation Loss: 69.92
2025-02-24 20:30:44,901 - Epoch 78, Training Loss: 69.89, Validation Loss: 69.73
2025-02-24 20:30:45,114 - Epoch 79, Training Loss: 67.72, Validation Loss: 69.32
2025-02-24 20:30:45,329 - Epoch 80, Training Loss: 77.93, Validation Loss: 68.79
2025-02-24 20:30:45,544 - Epoch 81, Training Loss: 67.80, Validation Loss: 68.29
2025-02-24 20:30:45,773 - Epoch 82, Training Loss: 74.61, Validation Loss: 68.18
2025-02-24 20:30:45,982 - Epoch 83, Training Loss: 77.85, Validation Loss: 68.16
2025-02-24 20:30:46,205 - Epoch 84, Training Loss: 83.02, Validation Loss: 67.86
2025-02-24 20:30:46,431 - Epoch 85, Training Loss: 76.99, Validation Loss: 67.22
2025-02-24 20:30:46,645 - Epoch 86, Training Loss: 77.17, Validation Loss: 66.84
2025-02-24 20:30:46,862 - Epoch 87, Training Loss: 68.83, Validation Loss: 66.49
2025-02-24 20:30:47,071 - Epoch 88, Training Loss: 71.07, Validation Loss: 66.28
2025-02-24 20:30:47,302 - Epoch 89, Training Loss: 65.93, Validation Loss: 66.35
2025-02-24 20:30:47,493 - Epoch 90, Training Loss: 68.59, Validation Loss: 66.72
2025-02-24 20:30:47,682 - Epoch 91, Training Loss: 67.84, Validation Loss: 66.92
2025-02-24 20:30:47,875 - Epoch 92, Training Loss: 68.22, Validation Loss: 66.78
2025-02-24 20:30:48,068 - Epoch 93, Training Loss: 67.34, Validation Loss: 66.87
2025-02-24 20:30:48,255 - Epoch 94, Training Loss: 77.50, Validation Loss: 66.83
2025-02-24 20:30:48,451 - Epoch 95, Training Loss: 67.00, Validation Loss: 66.82
2025-02-24 20:30:48,641 - Epoch 96, Training Loss: 74.03, Validation Loss: 66.99
2025-02-24 20:30:48,846 - Epoch 97, Training Loss: 69.22, Validation Loss: 66.76
2025-02-24 20:30:49,037 - Epoch 98, Training Loss: 69.82, Validation Loss: 66.49
2025-02-24 20:30:49,231 - Epoch 99, Training Loss: 80.04, Validation Loss: 66.94
2025-02-24 20:30:49,428 - Epoch 100, Training Loss: 69.84, Validation Loss: 67.20
2025-02-24 20:30:49,620 - Epoch 101, Training Loss: 78.13, Validation Loss: 67.71
2025-02-24 20:30:49,820 - Epoch 102, Training Loss: 76.62, Validation Loss: 67.98
2025-02-24 20:30:50,006 - Epoch 103, Training Loss: 75.58, Validation Loss: 67.74
2025-02-24 20:30:50,201 - Epoch 104, Training Loss: 77.70, Validation Loss: 67.27
2025-02-24 20:30:50,397 - Epoch 105, Training Loss: 77.15, Validation Loss: 67.00
2025-02-24 20:30:50,584 - Epoch 106, Training Loss: 78.12, Validation Loss: 66.63
2025-02-24 20:30:50,784 - Epoch 107, Training Loss: 67.89, Validation Loss: 66.47
2025-02-24 20:30:50,971 - Epoch 108, Training Loss: 74.52, Validation Loss: 66.37
2025-02-24 20:30:51,169 - Epoch 109, Training Loss: 66.01, Validation Loss: 66.08
2025-02-24 20:30:51,385 - Epoch 110, Training Loss: 70.23, Validation Loss: 65.78
2025-02-24 20:30:51,597 - Epoch 111, Training Loss: 67.47, Validation Loss: 65.83
2025-02-24 20:30:51,802 - Epoch 112, Training Loss: 74.73, Validation Loss: 66.08
2025-02-24 20:30:51,990 - Epoch 113, Training Loss: 90.92, Validation Loss: 66.11
2025-02-24 20:30:52,184 - Epoch 114, Training Loss: 71.24, Validation Loss: 65.59
2025-02-24 20:30:52,396 - Epoch 115, Training Loss: 68.14, Validation Loss: 65.50
2025-02-24 20:30:52,620 - Epoch 116, Training Loss: 73.15, Validation Loss: 65.42
2025-02-24 20:30:52,844 - Epoch 117, Training Loss: 76.65, Validation Loss: 65.44
2025-02-24 20:30:53,034 - Epoch 118, Training Loss: 78.03, Validation Loss: 65.45
2025-02-24 20:30:53,230 - Epoch 119, Training Loss: 68.66, Validation Loss: 65.63
2025-02-24 20:30:53,423 - Epoch 120, Training Loss: 70.07, Validation Loss: 66.03
2025-02-24 20:30:53,619 - Epoch 121, Training Loss: 69.26, Validation Loss: 66.25
2025-02-24 20:30:53,814 - Epoch 122, Training Loss: 72.50, Validation Loss: 66.31
2025-02-24 20:30:54,004 - Epoch 123, Training Loss: 72.33, Validation Loss: 66.32
2025-02-24 20:30:54,195 - Epoch 124, Training Loss: 70.57, Validation Loss: 66.01
2025-02-24 20:30:54,391 - Epoch 125, Training Loss: 66.20, Validation Loss: 65.86
2025-02-24 20:30:54,585 - Epoch 126, Training Loss: 74.48, Validation Loss: 65.91
2025-02-24 20:30:54,791 - Epoch 127, Training Loss: 68.15, Validation Loss: 65.72
2025-02-24 20:30:54,975 - Epoch 128, Training Loss: 66.40, Validation Loss: 65.52
2025-02-24 20:30:55,179 - Epoch 129, Training Loss: 75.59, Validation Loss: 65.68
2025-02-24 20:30:55,373 - Epoch 130, Training Loss: 64.43, Validation Loss: 66.15
2025-02-24 20:30:55,570 - Epoch 131, Training Loss: 76.96, Validation Loss: 66.57
2025-02-24 20:30:55,773 - Epoch 132, Training Loss: 75.20, Validation Loss: 66.75
2025-02-24 20:30:56,037 - Epoch 133, Training Loss: 71.68, Validation Loss: 66.94
2025-02-24 20:30:56,237 - Epoch 134, Training Loss: 68.92, Validation Loss: 66.69
2025-02-24 20:30:56,437 - Epoch 135, Training Loss: 66.18, Validation Loss: 66.86
2025-02-24 20:30:56,638 - Epoch 136, Training Loss: 70.33, Validation Loss: 66.85
2025-02-24 20:30:56,837 - Epoch 137, Training Loss: 76.67, Validation Loss: 66.84
2025-02-24 20:30:57,034 - Epoch 138, Training Loss: 73.29, Validation Loss: 66.75
2025-02-24 20:30:57,225 - Epoch 139, Training Loss: 73.23, Validation Loss: 66.47
2025-02-24 20:30:57,419 - Epoch 140, Training Loss: 75.17, Validation Loss: 66.08
2025-02-24 20:30:57,621 - Epoch 141, Training Loss: 67.81, Validation Loss: 65.83
2025-02-24 20:30:57,815 - Epoch 142, Training Loss: 68.15, Validation Loss: 65.85
2025-02-24 20:30:58,009 - Epoch 143, Training Loss: 72.53, Validation Loss: 65.88
2025-02-24 20:30:58,246 - Epoch 144, Training Loss: 77.04, Validation Loss: 65.51
2025-02-24 20:30:58,459 - Epoch 145, Training Loss: 76.02, Validation Loss: 65.28
2025-02-24 20:30:58,674 - Epoch 146, Training Loss: 67.55, Validation Loss: 65.26
2025-02-24 20:30:58,895 - Epoch 147, Training Loss: 73.76, Validation Loss: 65.13
2025-02-24 20:30:59,165 - Epoch 148, Training Loss: 67.46, Validation Loss: 65.09
2025-02-24 20:30:59,413 - Epoch 149, Training Loss: 77.62, Validation Loss: 65.39
2025-02-24 20:30:59,626 - Epoch 150, Training Loss: 76.06, Validation Loss: 65.68
2025-02-24 20:30:59,889 - Epoch 151, Training Loss: 71.54, Validation Loss: 65.53
2025-02-24 20:31:00,111 - Epoch 152, Training Loss: 68.18, Validation Loss: 65.22
2025-02-24 20:31:00,318 - Epoch 153, Training Loss: 65.20, Validation Loss: 64.99
2025-02-24 20:31:00,550 - Epoch 154, Training Loss: 64.86, Validation Loss: 64.91
2025-02-24 20:31:00,789 - Epoch 155, Training Loss: 73.66, Validation Loss: 65.16
2025-02-24 20:31:01,010 - Epoch 156, Training Loss: 72.57, Validation Loss: 65.84
2025-02-24 20:31:01,238 - Epoch 157, Training Loss: 71.59, Validation Loss: 65.86
2025-02-24 20:31:01,429 - Epoch 158, Training Loss: 68.66, Validation Loss: 65.55
2025-02-24 20:31:01,622 - Epoch 159, Training Loss: 68.02, Validation Loss: 65.70
2025-02-24 20:31:01,829 - Epoch 160, Training Loss: 86.73, Validation Loss: 65.91
2025-02-24 20:31:02,019 - Epoch 161, Training Loss: 81.13, Validation Loss: 65.76
2025-02-24 20:31:02,223 - Epoch 162, Training Loss: 68.78, Validation Loss: 65.51
2025-02-24 20:31:02,410 - Epoch 163, Training Loss: 65.50, Validation Loss: 65.54
2025-02-24 20:31:02,604 - Epoch 164, Training Loss: 64.13, Validation Loss: 65.51
2025-02-24 20:31:02,798 - Epoch 165, Training Loss: 68.25, Validation Loss: 65.45
2025-02-24 20:31:02,989 - Epoch 166, Training Loss: 67.62, Validation Loss: 65.26
2025-02-24 20:31:03,182 - Epoch 167, Training Loss: 71.16, Validation Loss: 65.14
2025-02-24 20:31:03,373 - Epoch 168, Training Loss: 69.71, Validation Loss: 65.49
2025-02-24 20:31:03,559 - Epoch 169, Training Loss: 67.40, Validation Loss: 65.73
2025-02-24 20:31:03,759 - Epoch 170, Training Loss: 78.00, Validation Loss: 65.99
2025-02-24 20:31:03,960 - Epoch 171, Training Loss: 63.73, Validation Loss: 65.72
2025-02-24 20:31:04,170 - Epoch 172, Training Loss: 68.43, Validation Loss: 65.38
2025-02-24 20:31:04,382 - Epoch 173, Training Loss: 67.58, Validation Loss: 65.49
2025-02-24 20:31:04,589 - Epoch 174, Training Loss: 69.97, Validation Loss: 65.47
2025-02-24 20:31:04,793 - Epoch 175, Training Loss: 67.77, Validation Loss: 65.20
2025-02-24 20:31:04,992 - Epoch 176, Training Loss: 68.42, Validation Loss: 65.15
2025-02-24 20:31:05,189 - Epoch 177, Training Loss: 79.33, Validation Loss: 65.12
2025-02-24 20:31:05,389 - Epoch 178, Training Loss: 64.45, Validation Loss: 65.03
2025-02-24 20:31:05,601 - Epoch 179, Training Loss: 81.99, Validation Loss: 64.80
2025-02-24 20:31:05,830 - Epoch 180, Training Loss: 73.00, Validation Loss: 64.17
2025-02-24 20:31:06,052 - Epoch 181, Training Loss: 66.02, Validation Loss: 63.64
2025-02-24 20:31:06,264 - Epoch 182, Training Loss: 74.80, Validation Loss: 63.44
2025-02-24 20:31:06,482 - Epoch 183, Training Loss: 76.72, Validation Loss: 63.42
2025-02-24 20:31:06,695 - Epoch 184, Training Loss: 69.27, Validation Loss: 63.24
2025-02-24 20:31:06,920 - Epoch 185, Training Loss: 70.59, Validation Loss: 63.15
2025-02-24 20:31:07,144 - Epoch 186, Training Loss: 69.68, Validation Loss: 63.46
2025-02-24 20:31:07,343 - Epoch 187, Training Loss: 68.82, Validation Loss: 63.53
2025-02-24 20:31:07,544 - Epoch 188, Training Loss: 75.15, Validation Loss: 63.66
2025-02-24 20:31:07,743 - Epoch 189, Training Loss: 69.44, Validation Loss: 64.13
2025-02-24 20:31:07,933 - Epoch 190, Training Loss: 75.74, Validation Loss: 64.43
2025-02-24 20:31:08,130 - Epoch 191, Training Loss: 63.74, Validation Loss: 64.54
2025-02-24 20:31:08,328 - Epoch 192, Training Loss: 63.88, Validation Loss: 64.29
2025-02-24 20:31:08,539 - Epoch 193, Training Loss: 66.89, Validation Loss: 64.02
2025-02-24 20:31:08,743 - Epoch 194, Training Loss: 70.60, Validation Loss: 63.99
2025-02-24 20:31:08,946 - Epoch 195, Training Loss: 66.81, Validation Loss: 64.48
2025-02-24 20:31:09,141 - Epoch 196, Training Loss: 72.90, Validation Loss: 64.73
2025-02-24 20:31:09,340 - Epoch 197, Training Loss: 67.45, Validation Loss: 64.75
2025-02-24 20:31:09,534 - Epoch 198, Training Loss: 69.91, Validation Loss: 65.05
2025-02-24 20:31:09,730 - Epoch 199, Training Loss: 71.90, Validation Loss: 64.76
2025-02-24 20:31:09,922 - Epoch 200, Training Loss: 63.90, Validation Loss: 64.51
2025-02-24 20:31:10,122 - Epoch 201, Training Loss: 82.62, Validation Loss: 64.26
2025-02-24 20:31:10,319 - Epoch 202, Training Loss: 74.18, Validation Loss: 63.82
2025-02-24 20:31:10,518 - Epoch 203, Training Loss: 71.31, Validation Loss: 63.57
2025-02-24 20:31:10,706 - Epoch 204, Training Loss: 68.10, Validation Loss: 63.99
2025-02-24 20:31:10,899 - Epoch 205, Training Loss: 78.37, Validation Loss: 64.42
2025-02-24 20:31:11,095 - Epoch 206, Training Loss: 74.54, Validation Loss: 64.07
2025-02-24 20:31:11,302 - Epoch 207, Training Loss: 77.08, Validation Loss: 63.58
2025-02-24 20:31:11,501 - Epoch 208, Training Loss: 71.76, Validation Loss: 63.25
2025-02-24 20:31:11,700 - Epoch 209, Training Loss: 78.93, Validation Loss: 63.65
2025-02-24 20:31:11,896 - Epoch 210, Training Loss: 66.59, Validation Loss: 63.96
2025-02-24 20:31:12,096 - Epoch 211, Training Loss: 69.99, Validation Loss: 64.09
2025-02-24 20:31:12,290 - Epoch 212, Training Loss: 79.77, Validation Loss: 64.33
2025-02-24 20:31:12,490 - Epoch 213, Training Loss: 65.77, Validation Loss: 64.00
2025-02-24 20:31:12,685 - Epoch 214, Training Loss: 62.94, Validation Loss: 64.07
2025-02-24 20:31:12,882 - Epoch 215, Training Loss: 71.94, Validation Loss: 64.07
2025-02-24 20:31:13,080 - Epoch 216, Training Loss: 67.30, Validation Loss: 64.08
2025-02-24 20:31:13,274 - Epoch 217, Training Loss: 68.96, Validation Loss: 63.95
2025-02-24 20:31:13,465 - Epoch 218, Training Loss: 72.70, Validation Loss: 63.94
2025-02-24 20:31:13,671 - Epoch 219, Training Loss: 64.26, Validation Loss: 64.02
2025-02-24 20:31:13,869 - Epoch 220, Training Loss: 68.27, Validation Loss: 63.92
2025-02-24 20:31:14,071 - Epoch 221, Training Loss: 75.70, Validation Loss: 63.85
2025-02-24 20:31:14,270 - Epoch 222, Training Loss: 72.87, Validation Loss: 63.45
2025-02-24 20:31:14,469 - Epoch 223, Training Loss: 86.70, Validation Loss: 63.30
2025-02-24 20:31:14,666 - Epoch 224, Training Loss: 68.90, Validation Loss: 63.36
2025-02-24 20:31:14,861 - Epoch 225, Training Loss: 73.54, Validation Loss: 63.77
2025-02-24 20:31:15,066 - Epoch 226, Training Loss: 74.43, Validation Loss: 64.29
2025-02-24 20:31:15,265 - Epoch 227, Training Loss: 72.48, Validation Loss: 65.33
2025-02-24 20:31:15,468 - Epoch 228, Training Loss: 77.23, Validation Loss: 66.36
2025-02-24 20:31:15,661 - Epoch 229, Training Loss: 84.02, Validation Loss: 66.29
2025-02-24 20:31:15,867 - Epoch 230, Training Loss: 64.26, Validation Loss: 65.43
2025-02-24 20:31:16,072 - Epoch 231, Training Loss: 67.57, Validation Loss: 64.77
2025-02-24 20:31:16,271 - Epoch 232, Training Loss: 68.99, Validation Loss: 64.15
2025-02-24 20:31:16,489 - Epoch 233, Training Loss: 76.05, Validation Loss: 63.79
2025-02-24 20:31:16,679 - Epoch 234, Training Loss: 75.51, Validation Loss: 63.41
2025-02-24 20:31:16,879 - Epoch 235, Training Loss: 66.45, Validation Loss: 63.02
2025-02-24 20:31:17,108 - Epoch 236, Training Loss: 68.35, Validation Loss: 63.24
2025-02-24 20:31:17,301 - Epoch 237, Training Loss: 70.98, Validation Loss: 63.95
2025-02-24 20:31:17,497 - Epoch 238, Training Loss: 70.50, Validation Loss: 64.77
2025-02-24 20:31:17,709 - Epoch 239, Training Loss: 68.73, Validation Loss: 65.46
2025-02-24 20:31:17,926 - Epoch 240, Training Loss: 67.95, Validation Loss: 65.49
2025-02-24 20:31:18,146 - Epoch 241, Training Loss: 74.40, Validation Loss: 65.10
2025-02-24 20:31:18,361 - Epoch 242, Training Loss: 71.60, Validation Loss: 64.51
2025-02-24 20:31:18,564 - Epoch 243, Training Loss: 67.52, Validation Loss: 64.24
2025-02-24 20:31:18,769 - Epoch 244, Training Loss: 77.33, Validation Loss: 64.54
2025-02-24 20:31:18,965 - Epoch 245, Training Loss: 65.45, Validation Loss: 64.49
2025-02-24 20:31:19,172 - Epoch 246, Training Loss: 74.52, Validation Loss: 64.49
2025-02-24 20:31:19,380 - Epoch 247, Training Loss: 63.88, Validation Loss: 64.29
2025-02-24 20:31:19,580 - Epoch 248, Training Loss: 76.32, Validation Loss: 64.15
2025-02-24 20:31:19,782 - Epoch 249, Training Loss: 74.90, Validation Loss: 63.98
2025-02-24 20:31:19,979 - Epoch 250, Training Loss: 72.59, Validation Loss: 63.58
2025-02-24 20:31:20,174 - Epoch 251, Training Loss: 71.13, Validation Loss: 63.59
2025-02-24 20:31:20,373 - Epoch 252, Training Loss: 68.40, Validation Loss: 64.16
2025-02-24 20:31:20,570 - Epoch 253, Training Loss: 77.34, Validation Loss: 64.68
2025-02-24 20:31:20,765 - Epoch 254, Training Loss: 77.74, Validation Loss: 65.17
2025-02-24 20:31:20,957 - Epoch 255, Training Loss: 75.38, Validation Loss: 65.40
2025-02-24 20:31:21,150 - Epoch 256, Training Loss: 68.73, Validation Loss: 65.59
2025-02-24 20:31:21,343 - Epoch 257, Training Loss: 70.32, Validation Loss: 65.79
2025-02-24 20:31:21,540 - Epoch 258, Training Loss: 64.73, Validation Loss: 65.69
2025-02-24 20:31:21,743 - Epoch 259, Training Loss: 74.19, Validation Loss: 65.34
2025-02-24 20:31:21,927 - Epoch 260, Training Loss: 68.28, Validation Loss: 64.71
2025-02-24 20:31:22,124 - Epoch 261, Training Loss: 70.30, Validation Loss: 64.23
2025-02-24 20:31:22,314 - Epoch 262, Training Loss: 70.01, Validation Loss: 63.72
2025-02-24 20:31:22,507 - Epoch 263, Training Loss: 77.28, Validation Loss: 63.46
2025-02-24 20:31:22,698 - Epoch 264, Training Loss: 65.49, Validation Loss: 63.58
2025-02-24 20:31:22,898 - Epoch 265, Training Loss: 68.21, Validation Loss: 63.88
2025-02-24 20:31:23,086 - Epoch 266, Training Loss: 70.83, Validation Loss: 63.94
2025-02-24 20:31:23,282 - Epoch 267, Training Loss: 78.05, Validation Loss: 63.89
2025-02-24 20:31:23,478 - Epoch 268, Training Loss: 75.20, Validation Loss: 64.02
2025-02-24 20:31:23,674 - Epoch 269, Training Loss: 73.20, Validation Loss: 64.14
2025-02-24 20:31:23,871 - Epoch 270, Training Loss: 70.10, Validation Loss: 64.66
2025-02-24 20:31:24,060 - Epoch 271, Training Loss: 72.61, Validation Loss: 65.55
2025-02-24 20:31:24,255 - Epoch 272, Training Loss: 73.87, Validation Loss: 65.76
2025-02-24 20:31:24,446 - Epoch 273, Training Loss: 67.49, Validation Loss: 65.34
2025-02-24 20:31:24,640 - Epoch 274, Training Loss: 75.51, Validation Loss: 64.76
2025-02-24 20:31:24,833 - Epoch 275, Training Loss: 65.38, Validation Loss: 64.25
2025-02-24 20:31:25,029 - Epoch 276, Training Loss: 71.16, Validation Loss: 63.80
2025-02-24 20:31:25,219 - Epoch 277, Training Loss: 71.53, Validation Loss: 63.77
2025-02-24 20:31:25,414 - Epoch 278, Training Loss: 68.18, Validation Loss: 63.81
2025-02-24 20:31:25,605 - Epoch 279, Training Loss: 68.42, Validation Loss: 63.84
2025-02-24 20:31:25,806 - Epoch 280, Training Loss: 76.34, Validation Loss: 63.70
2025-02-24 20:31:25,997 - Epoch 281, Training Loss: 73.69, Validation Loss: 63.48
2025-02-24 20:31:26,190 - Epoch 282, Training Loss: 76.63, Validation Loss: 63.22
2025-02-24 20:31:26,379 - Epoch 283, Training Loss: 68.51, Validation Loss: 63.10
2025-02-24 20:31:26,574 - Epoch 284, Training Loss: 68.74, Validation Loss: 63.06
2025-02-24 20:31:26,771 - Epoch 285, Training Loss: 70.74, Validation Loss: 62.99
2025-02-24 20:31:26,988 - Epoch 286, Training Loss: 68.28, Validation Loss: 62.81
2025-02-24 20:31:27,201 - Epoch 287, Training Loss: 66.38, Validation Loss: 62.71
2025-02-24 20:31:27,414 - Epoch 288, Training Loss: 74.77, Validation Loss: 62.66
2025-02-24 20:31:27,626 - Epoch 289, Training Loss: 66.25, Validation Loss: 62.61
2025-02-24 20:31:27,851 - Epoch 290, Training Loss: 73.10, Validation Loss: 62.87
2025-02-24 20:31:28,048 - Epoch 291, Training Loss: 70.17, Validation Loss: 63.13
2025-02-24 20:31:28,251 - Epoch 292, Training Loss: 74.57, Validation Loss: 63.51
2025-02-24 20:31:28,448 - Epoch 293, Training Loss: 75.29, Validation Loss: 63.79
2025-02-24 20:31:28,644 - Epoch 294, Training Loss: 73.43, Validation Loss: 63.78
2025-02-24 20:31:28,841 - Epoch 295, Training Loss: 75.27, Validation Loss: 63.61
2025-02-24 20:31:29,036 - Epoch 296, Training Loss: 77.29, Validation Loss: 63.49
2025-02-24 20:31:29,226 - Epoch 297, Training Loss: 72.17, Validation Loss: 63.20
2025-02-24 20:31:29,420 - Epoch 298, Training Loss: 68.87, Validation Loss: 62.73
2025-02-24 20:31:29,610 - Epoch 299, Training Loss: 66.37, Validation Loss: 62.20
2025-02-24 20:31:29,829 - Epoch 300, Training Loss: 72.56, Validation Loss: 62.09
2025-02-24 20:31:30,045 - Epoch 301, Training Loss: 71.28, Validation Loss: 62.28
2025-02-24 20:31:30,242 - Epoch 302, Training Loss: 78.20, Validation Loss: 62.51
2025-02-24 20:31:30,434 - Epoch 303, Training Loss: 67.05, Validation Loss: 62.92
2025-02-24 20:31:30,635 - Epoch 304, Training Loss: 77.11, Validation Loss: 63.19
2025-02-24 20:31:30,829 - Epoch 305, Training Loss: 69.94, Validation Loss: 63.24
2025-02-24 20:31:31,036 - Epoch 306, Training Loss: 69.18, Validation Loss: 63.48
2025-02-24 20:31:31,225 - Epoch 307, Training Loss: 72.76, Validation Loss: 63.68
2025-02-24 20:31:31,418 - Epoch 308, Training Loss: 84.59, Validation Loss: 63.67
2025-02-24 20:31:31,609 - Epoch 309, Training Loss: 64.96, Validation Loss: 63.73
2025-02-24 20:31:31,807 - Epoch 310, Training Loss: 74.98, Validation Loss: 64.03
2025-02-24 20:31:32,003 - Epoch 311, Training Loss: 65.30, Validation Loss: 64.46
2025-02-24 20:31:32,199 - Epoch 312, Training Loss: 72.10, Validation Loss: 64.62
2025-02-24 20:31:32,388 - Epoch 313, Training Loss: 83.15, Validation Loss: 64.18
2025-02-24 20:31:32,581 - Epoch 314, Training Loss: 69.65, Validation Loss: 63.58
2025-02-24 20:31:32,779 - Epoch 315, Training Loss: 74.47, Validation Loss: 63.18
2025-02-24 20:31:32,971 - Epoch 316, Training Loss: 68.18, Validation Loss: 62.95
2025-02-24 20:31:33,160 - Epoch 317, Training Loss: 65.41, Validation Loss: 62.91
2025-02-24 20:31:33,353 - Epoch 318, Training Loss: 72.05, Validation Loss: 63.14
2025-02-24 20:31:33,544 - Epoch 319, Training Loss: 72.56, Validation Loss: 63.54
2025-02-24 20:31:33,742 - Epoch 320, Training Loss: 69.62, Validation Loss: 64.26
2025-02-24 20:31:33,931 - Epoch 321, Training Loss: 67.60, Validation Loss: 64.68
2025-02-24 20:31:34,141 - Epoch 322, Training Loss: 63.38, Validation Loss: 64.63
2025-02-24 20:31:34,332 - Epoch 323, Training Loss: 72.74, Validation Loss: 64.34
2025-02-24 20:31:34,531 - Epoch 324, Training Loss: 74.16, Validation Loss: 63.84
2025-02-24 20:31:34,727 - Epoch 325, Training Loss: 77.49, Validation Loss: 63.54
2025-02-24 20:31:34,924 - Epoch 326, Training Loss: 69.94, Validation Loss: 63.26
2025-02-24 20:31:35,113 - Epoch 327, Training Loss: 71.89, Validation Loss: 62.95
2025-02-24 20:31:35,302 - Epoch 328, Training Loss: 62.74, Validation Loss: 62.52
2025-02-24 20:31:35,493 - Epoch 329, Training Loss: 69.23, Validation Loss: 62.20
2025-02-24 20:31:35,687 - Epoch 330, Training Loss: 62.15, Validation Loss: 62.01
2025-02-24 20:31:35,899 - Epoch 331, Training Loss: 65.27, Validation Loss: 62.07
2025-02-24 20:31:36,093 - Epoch 332, Training Loss: 66.33, Validation Loss: 62.45
2025-02-24 20:31:36,294 - Epoch 333, Training Loss: 76.98, Validation Loss: 62.82
2025-02-24 20:31:36,487 - Epoch 334, Training Loss: 73.09, Validation Loss: 63.07
2025-02-24 20:31:36,679 - Epoch 335, Training Loss: 69.07, Validation Loss: 63.36
2025-02-24 20:31:36,869 - Epoch 336, Training Loss: 71.22, Validation Loss: 63.58
2025-02-24 20:31:37,064 - Epoch 337, Training Loss: 70.44, Validation Loss: 63.31
2025-02-24 20:31:37,258 - Epoch 338, Training Loss: 77.97, Validation Loss: 63.11
2025-02-24 20:31:37,464 - Epoch 339, Training Loss: 66.52, Validation Loss: 63.33
2025-02-24 20:31:37,667 - Epoch 340, Training Loss: 71.81, Validation Loss: 63.66
2025-02-24 20:31:37,866 - Epoch 341, Training Loss: 65.08, Validation Loss: 64.08
2025-02-24 20:31:38,061 - Epoch 342, Training Loss: 68.87, Validation Loss: 64.27
2025-02-24 20:31:38,261 - Epoch 343, Training Loss: 74.13, Validation Loss: 64.50
2025-02-24 20:31:38,457 - Epoch 344, Training Loss: 63.97, Validation Loss: 64.43
2025-02-24 20:31:38,652 - Epoch 345, Training Loss: 71.39, Validation Loss: 64.27
2025-02-24 20:31:38,846 - Epoch 346, Training Loss: 72.67, Validation Loss: 64.14
2025-02-24 20:31:39,041 - Epoch 347, Training Loss: 69.87, Validation Loss: 64.11
2025-02-24 20:31:39,232 - Epoch 348, Training Loss: 81.40, Validation Loss: 64.03
2025-02-24 20:31:39,424 - Epoch 349, Training Loss: 71.24, Validation Loss: 63.83
2025-02-24 20:31:39,618 - Epoch 350, Training Loss: 66.92, Validation Loss: 63.87
2025-02-24 20:31:39,816 - Epoch 351, Training Loss: 67.68, Validation Loss: 64.00
2025-02-24 20:31:40,003 - Epoch 352, Training Loss: 73.40, Validation Loss: 64.19
2025-02-24 20:31:40,198 - Epoch 353, Training Loss: 74.41, Validation Loss: 64.20
2025-02-24 20:31:40,388 - Epoch 354, Training Loss: 79.12, Validation Loss: 64.14
2025-02-24 20:31:40,578 - Epoch 355, Training Loss: 76.20, Validation Loss: 63.57
2025-02-24 20:31:40,774 - Epoch 356, Training Loss: 64.10, Validation Loss: 63.19
2025-02-24 20:31:40,968 - Epoch 357, Training Loss: 77.22, Validation Loss: 62.83
2025-02-24 20:31:41,157 - Epoch 358, Training Loss: 71.63, Validation Loss: 62.73
2025-02-24 20:31:41,358 - Epoch 359, Training Loss: 65.62, Validation Loss: 62.96
2025-02-24 20:31:41,546 - Epoch 360, Training Loss: 74.07, Validation Loss: 63.23
2025-02-24 20:31:41,739 - Epoch 361, Training Loss: 64.66, Validation Loss: 63.30
2025-02-24 20:31:41,928 - Epoch 362, Training Loss: 63.17, Validation Loss: 63.18
2025-02-24 20:31:42,121 - Epoch 363, Training Loss: 68.61, Validation Loss: 63.00
2025-02-24 20:31:42,315 - Epoch 364, Training Loss: 63.10, Validation Loss: 62.82
2025-02-24 20:31:42,510 - Epoch 365, Training Loss: 83.16, Validation Loss: 62.55
2025-02-24 20:31:42,701 - Epoch 366, Training Loss: 69.96, Validation Loss: 62.33
2025-02-24 20:31:42,905 - Epoch 367, Training Loss: 70.29, Validation Loss: 62.58
2025-02-24 20:31:43,093 - Epoch 368, Training Loss: 67.47, Validation Loss: 63.17
2025-02-24 20:31:43,291 - Epoch 369, Training Loss: 69.98, Validation Loss: 63.54
2025-02-24 20:31:43,482 - Epoch 370, Training Loss: 75.86, Validation Loss: 63.96
2025-02-24 20:31:43,678 - Epoch 371, Training Loss: 79.28, Validation Loss: 64.21
2025-02-24 20:31:43,866 - Epoch 372, Training Loss: 65.11, Validation Loss: 64.82
2025-02-24 20:31:44,063 - Epoch 373, Training Loss: 67.22, Validation Loss: 65.22
2025-02-24 20:31:44,264 - Epoch 374, Training Loss: 71.75, Validation Loss: 65.34
2025-02-24 20:31:44,459 - Epoch 375, Training Loss: 69.56, Validation Loss: 65.68
2025-02-24 20:31:44,647 - Epoch 376, Training Loss: 80.83, Validation Loss: 65.76
2025-02-24 20:31:44,846 - Epoch 377, Training Loss: 75.98, Validation Loss: 65.22
2025-02-24 20:31:45,034 - Epoch 378, Training Loss: 67.46, Validation Loss: 64.47
2025-02-24 20:31:45,228 - Epoch 379, Training Loss: 72.40, Validation Loss: 64.06
2025-02-24 20:31:45,423 - Epoch 380, Training Loss: 66.52, Validation Loss: 63.81
2025-02-24 20:31:45,423 - Early stopping at epoch 380 due to no improvement in validation loss.
2025-02-24 20:31:45,690 - learning rate: 0.01
2025-02-24 20:31:45,690 - Test RMSE: 7.468699932098389, Test MAE: 1.189356505870819
2025-02-24 20:32:35,512 - -----------------------Starting training-------------------------
2025-02-24 20:32:35,512 - learning rate: 0.01
2025-02-24 20:32:35,657 - Epoch 1, Training Loss: 195.11, Validation Loss: 208.74
2025-02-24 20:32:35,839 - Epoch 2, Training Loss: 159.46, Validation Loss: 202.32
2025-02-24 20:32:36,032 - Epoch 3, Training Loss: 152.46, Validation Loss: 196.20
2025-02-24 20:32:36,198 - Epoch 4, Training Loss: 134.63, Validation Loss: 190.75
2025-02-24 20:32:36,379 - Epoch 5, Training Loss: 148.29, Validation Loss: 185.84
2025-02-24 20:32:36,543 - Epoch 6, Training Loss: 142.12, Validation Loss: 181.98
2025-02-24 20:32:36,711 - Epoch 7, Training Loss: 128.79, Validation Loss: 179.51
2025-02-24 20:32:36,879 - Epoch 8, Training Loss: 135.91, Validation Loss: 176.91
2025-02-24 20:32:37,052 - Epoch 9, Training Loss: 151.18, Validation Loss: 174.39
2025-02-24 20:32:37,218 - Epoch 10, Training Loss: 144.99, Validation Loss: 172.57
2025-02-24 20:32:37,392 - Epoch 11, Training Loss: 143.19, Validation Loss: 170.80
2025-02-24 20:32:37,558 - Epoch 12, Training Loss: 130.78, Validation Loss: 169.28
2025-02-24 20:32:37,741 - Epoch 13, Training Loss: 127.88, Validation Loss: 167.87
2025-02-24 20:32:37,907 - Epoch 14, Training Loss: 113.77, Validation Loss: 166.78
2025-02-24 20:32:38,078 - Epoch 15, Training Loss: 147.52, Validation Loss: 165.24
2025-02-24 20:32:38,240 - Epoch 16, Training Loss: 116.41, Validation Loss: 164.29
2025-02-24 20:32:38,412 - Epoch 17, Training Loss: 171.08, Validation Loss: 162.69
2025-02-24 20:32:38,576 - Epoch 18, Training Loss: 133.95, Validation Loss: 161.63
2025-02-24 20:32:38,751 - Epoch 19, Training Loss: 120.37, Validation Loss: 160.69
2025-02-24 20:32:38,914 - Epoch 20, Training Loss: 131.48, Validation Loss: 159.62
2025-02-24 20:32:39,086 - Epoch 21, Training Loss: 128.85, Validation Loss: 158.61
2025-02-24 20:32:39,253 - Epoch 22, Training Loss: 121.78, Validation Loss: 157.73
2025-02-24 20:32:39,425 - Epoch 23, Training Loss: 122.53, Validation Loss: 156.85
2025-02-24 20:32:39,590 - Epoch 24, Training Loss: 120.77, Validation Loss: 156.09
2025-02-24 20:32:39,762 - Epoch 25, Training Loss: 127.69, Validation Loss: 155.19
2025-02-24 20:32:39,927 - Epoch 26, Training Loss: 123.41, Validation Loss: 154.51
2025-02-24 20:32:40,106 - Epoch 27, Training Loss: 112.02, Validation Loss: 153.83
2025-02-24 20:32:40,272 - Epoch 28, Training Loss: 127.38, Validation Loss: 153.00
2025-02-24 20:32:40,445 - Epoch 29, Training Loss: 141.12, Validation Loss: 152.07
2025-02-24 20:32:40,610 - Epoch 30, Training Loss: 121.46, Validation Loss: 151.32
2025-02-24 20:32:40,788 - Epoch 31, Training Loss: 129.96, Validation Loss: 150.51
2025-02-24 20:32:40,952 - Epoch 32, Training Loss: 115.53, Validation Loss: 149.95
2025-02-24 20:32:41,129 - Epoch 33, Training Loss: 118.46, Validation Loss: 149.33
2025-02-24 20:32:41,299 - Epoch 34, Training Loss: 120.46, Validation Loss: 148.73
2025-02-24 20:32:41,475 - Epoch 35, Training Loss: 120.73, Validation Loss: 148.11
2025-02-24 20:32:41,644 - Epoch 36, Training Loss: 127.98, Validation Loss: 147.43
2025-02-24 20:32:41,816 - Epoch 37, Training Loss: 123.02, Validation Loss: 146.92
2025-02-24 20:32:41,984 - Epoch 38, Training Loss: 119.32, Validation Loss: 146.37
2025-02-24 20:32:42,154 - Epoch 39, Training Loss: 106.30, Validation Loss: 145.89
2025-02-24 20:32:42,320 - Epoch 40, Training Loss: 114.56, Validation Loss: 145.35
2025-02-24 20:32:42,493 - Epoch 41, Training Loss: 123.41, Validation Loss: 144.69
2025-02-24 20:32:42,664 - Epoch 42, Training Loss: 119.61, Validation Loss: 144.15
2025-02-24 20:32:42,844 - Epoch 43, Training Loss: 117.71, Validation Loss: 143.63
2025-02-24 20:32:43,006 - Epoch 44, Training Loss: 124.14, Validation Loss: 143.11
2025-02-24 20:32:43,180 - Epoch 45, Training Loss: 107.91, Validation Loss: 142.71
2025-02-24 20:32:43,346 - Epoch 46, Training Loss: 130.66, Validation Loss: 142.18
2025-02-24 20:32:43,517 - Epoch 47, Training Loss: 102.92, Validation Loss: 141.90
2025-02-24 20:32:43,687 - Epoch 48, Training Loss: 117.25, Validation Loss: 141.38
2025-02-24 20:32:43,862 - Epoch 49, Training Loss: 120.32, Validation Loss: 140.98
2025-02-24 20:32:44,029 - Epoch 50, Training Loss: 128.19, Validation Loss: 140.38
2025-02-24 20:32:44,201 - Epoch 51, Training Loss: 101.64, Validation Loss: 140.14
2025-02-24 20:32:44,364 - Epoch 52, Training Loss: 106.93, Validation Loss: 139.80
2025-02-24 20:32:44,536 - Epoch 53, Training Loss: 129.83, Validation Loss: 139.20
2025-02-24 20:32:44,703 - Epoch 54, Training Loss: 106.43, Validation Loss: 138.86
2025-02-24 20:32:44,877 - Epoch 55, Training Loss: 116.65, Validation Loss: 138.45
2025-02-24 20:32:45,039 - Epoch 56, Training Loss: 102.01, Validation Loss: 138.18
2025-02-24 20:32:45,213 - Epoch 57, Training Loss: 104.20, Validation Loss: 137.78
2025-02-24 20:32:45,381 - Epoch 58, Training Loss: 129.46, Validation Loss: 137.28
2025-02-24 20:32:45,553 - Epoch 59, Training Loss: 111.75, Validation Loss: 136.93
2025-02-24 20:32:45,722 - Epoch 60, Training Loss: 128.07, Validation Loss: 136.48
2025-02-24 20:32:45,895 - Epoch 61, Training Loss: 108.70, Validation Loss: 136.16
2025-02-24 20:32:46,060 - Epoch 62, Training Loss: 120.14, Validation Loss: 135.76
2025-02-24 20:32:46,233 - Epoch 63, Training Loss: 115.66, Validation Loss: 135.46
2025-02-24 20:32:46,400 - Epoch 64, Training Loss: 123.51, Validation Loss: 135.04
2025-02-24 20:32:46,571 - Epoch 65, Training Loss: 106.51, Validation Loss: 134.80
2025-02-24 20:32:46,735 - Epoch 66, Training Loss: 118.86, Validation Loss: 134.41
2025-02-24 20:32:46,906 - Epoch 67, Training Loss: 110.22, Validation Loss: 134.06
2025-02-24 20:32:47,082 - Epoch 68, Training Loss: 110.95, Validation Loss: 133.78
2025-02-24 20:32:47,257 - Epoch 69, Training Loss: 111.74, Validation Loss: 133.37
2025-02-24 20:32:47,424 - Epoch 70, Training Loss: 96.15, Validation Loss: 133.17
2025-02-24 20:32:47,593 - Epoch 71, Training Loss: 99.34, Validation Loss: 132.92
2025-02-24 20:32:47,758 - Epoch 72, Training Loss: 91.27, Validation Loss: 132.80
2025-02-24 20:32:47,929 - Epoch 73, Training Loss: 106.36, Validation Loss: 132.47
2025-02-24 20:32:48,094 - Epoch 74, Training Loss: 125.77, Validation Loss: 132.05
2025-02-24 20:32:48,271 - Epoch 75, Training Loss: 135.83, Validation Loss: 131.63
2025-02-24 20:32:48,446 - Epoch 76, Training Loss: 104.58, Validation Loss: 131.35
2025-02-24 20:32:48,620 - Epoch 77, Training Loss: 101.56, Validation Loss: 131.11
2025-02-24 20:32:48,787 - Epoch 78, Training Loss: 110.66, Validation Loss: 130.75
2025-02-24 20:32:48,959 - Epoch 79, Training Loss: 107.53, Validation Loss: 130.42
2025-02-24 20:32:49,129 - Epoch 80, Training Loss: 125.58, Validation Loss: 130.01
2025-02-24 20:32:49,311 - Epoch 81, Training Loss: 97.44, Validation Loss: 129.80
2025-02-24 20:32:49,479 - Epoch 82, Training Loss: 108.75, Validation Loss: 129.54
2025-02-24 20:32:49,651 - Epoch 83, Training Loss: 120.01, Validation Loss: 129.22
2025-02-24 20:32:49,813 - Epoch 84, Training Loss: 135.25, Validation Loss: 128.79
2025-02-24 20:32:49,987 - Epoch 85, Training Loss: 119.19, Validation Loss: 128.49
2025-02-24 20:32:50,154 - Epoch 86, Training Loss: 116.73, Validation Loss: 128.19
2025-02-24 20:32:50,331 - Epoch 87, Training Loss: 105.96, Validation Loss: 127.90
2025-02-24 20:32:50,497 - Epoch 88, Training Loss: 107.46, Validation Loss: 127.65
2025-02-24 20:32:50,678 - Epoch 89, Training Loss: 92.73, Validation Loss: 127.50
2025-02-24 20:32:50,845 - Epoch 90, Training Loss: 101.42, Validation Loss: 127.29
2025-02-24 20:32:51,025 - Epoch 91, Training Loss: 111.27, Validation Loss: 126.94
2025-02-24 20:32:51,189 - Epoch 92, Training Loss: 95.51, Validation Loss: 126.78
2025-02-24 20:32:51,360 - Epoch 93, Training Loss: 103.84, Validation Loss: 126.54
2025-02-24 20:32:51,525 - Epoch 94, Training Loss: 118.47, Validation Loss: 126.26
2025-02-24 20:32:51,717 - Epoch 95, Training Loss: 91.28, Validation Loss: 126.14
2025-02-24 20:32:51,884 - Epoch 96, Training Loss: 119.67, Validation Loss: 125.82
2025-02-24 20:32:52,057 - Epoch 97, Training Loss: 106.24, Validation Loss: 125.55
2025-02-24 20:32:52,225 - Epoch 98, Training Loss: 87.45, Validation Loss: 125.48
2025-02-24 20:32:52,401 - Epoch 99, Training Loss: 114.18, Validation Loss: 125.28
2025-02-24 20:32:52,570 - Epoch 100, Training Loss: 93.33, Validation Loss: 125.15
2025-02-24 20:32:52,744 - Epoch 101, Training Loss: 105.88, Validation Loss: 125.01
2025-02-24 20:32:52,907 - Epoch 102, Training Loss: 111.79, Validation Loss: 124.76
2025-02-24 20:32:53,083 - Epoch 103, Training Loss: 114.44, Validation Loss: 124.48
2025-02-24 20:32:53,249 - Epoch 104, Training Loss: 110.27, Validation Loss: 124.28
2025-02-24 20:32:53,423 - Epoch 105, Training Loss: 114.63, Validation Loss: 124.00
2025-02-24 20:32:53,589 - Epoch 106, Training Loss: 107.83, Validation Loss: 123.80
2025-02-24 20:32:53,761 - Epoch 107, Training Loss: 94.23, Validation Loss: 123.63
2025-02-24 20:32:53,932 - Epoch 108, Training Loss: 118.33, Validation Loss: 123.36
2025-02-24 20:32:54,105 - Epoch 109, Training Loss: 103.82, Validation Loss: 123.10
2025-02-24 20:32:54,277 - Epoch 110, Training Loss: 97.08, Validation Loss: 122.94
2025-02-24 20:32:54,446 - Epoch 111, Training Loss: 93.55, Validation Loss: 122.80
2025-02-24 20:32:54,615 - Epoch 112, Training Loss: 102.28, Validation Loss: 122.63
2025-02-24 20:32:54,789 - Epoch 113, Training Loss: 144.97, Validation Loss: 122.25
2025-02-24 20:32:54,958 - Epoch 114, Training Loss: 92.61, Validation Loss: 122.13
2025-02-24 20:32:55,134 - Epoch 115, Training Loss: 99.17, Validation Loss: 121.93
2025-02-24 20:32:55,298 - Epoch 116, Training Loss: 109.25, Validation Loss: 121.74
2025-02-24 20:32:55,472 - Epoch 117, Training Loss: 106.95, Validation Loss: 121.56
2025-02-24 20:32:55,641 - Epoch 118, Training Loss: 108.77, Validation Loss: 121.39
2025-02-24 20:32:55,811 - Epoch 119, Training Loss: 90.35, Validation Loss: 121.30
2025-02-24 20:32:55,977 - Epoch 120, Training Loss: 100.92, Validation Loss: 121.13
2025-02-24 20:32:56,153 - Epoch 121, Training Loss: 95.85, Validation Loss: 120.96
2025-02-24 20:32:56,322 - Epoch 122, Training Loss: 97.78, Validation Loss: 120.82
2025-02-24 20:32:56,498 - Epoch 123, Training Loss: 111.89, Validation Loss: 120.56
2025-02-24 20:32:56,665 - Epoch 124, Training Loss: 98.05, Validation Loss: 120.39
2025-02-24 20:32:56,836 - Epoch 125, Training Loss: 90.28, Validation Loss: 120.25
2025-02-24 20:32:57,014 - Epoch 126, Training Loss: 108.59, Validation Loss: 120.03
2025-02-24 20:32:57,188 - Epoch 127, Training Loss: 100.57, Validation Loss: 119.82
2025-02-24 20:32:57,351 - Epoch 128, Training Loss: 89.27, Validation Loss: 119.71
2025-02-24 20:32:57,527 - Epoch 129, Training Loss: 98.17, Validation Loss: 119.61
2025-02-24 20:32:57,695 - Epoch 130, Training Loss: 89.95, Validation Loss: 119.48
2025-02-24 20:32:57,870 - Epoch 131, Training Loss: 102.81, Validation Loss: 119.32
2025-02-24 20:32:58,037 - Epoch 132, Training Loss: 97.36, Validation Loss: 119.23
2025-02-24 20:32:58,211 - Epoch 133, Training Loss: 108.78, Validation Loss: 118.98
2025-02-24 20:32:58,379 - Epoch 134, Training Loss: 85.21, Validation Loss: 118.93
2025-02-24 20:32:58,561 - Epoch 135, Training Loss: 99.26, Validation Loss: 118.72
2025-02-24 20:32:58,724 - Epoch 136, Training Loss: 93.98, Validation Loss: 118.60
2025-02-24 20:32:58,902 - Epoch 137, Training Loss: 102.58, Validation Loss: 118.45
2025-02-24 20:32:59,068 - Epoch 138, Training Loss: 106.20, Validation Loss: 118.25
2025-02-24 20:32:59,241 - Epoch 139, Training Loss: 107.21, Validation Loss: 118.03
2025-02-24 20:32:59,409 - Epoch 140, Training Loss: 103.28, Validation Loss: 117.88
2025-02-24 20:32:59,585 - Epoch 141, Training Loss: 90.01, Validation Loss: 117.76
2025-02-24 20:32:59,755 - Epoch 142, Training Loss: 94.34, Validation Loss: 117.62
2025-02-24 20:32:59,930 - Epoch 143, Training Loss: 105.20, Validation Loss: 117.40
2025-02-24 20:33:00,097 - Epoch 144, Training Loss: 111.59, Validation Loss: 117.21
2025-02-24 20:33:00,271 - Epoch 145, Training Loss: 101.58, Validation Loss: 117.09
2025-02-24 20:33:00,438 - Epoch 146, Training Loss: 97.48, Validation Loss: 116.90
2025-02-24 20:33:00,613 - Epoch 147, Training Loss: 99.25, Validation Loss: 116.74
2025-02-24 20:33:00,781 - Epoch 148, Training Loss: 91.14, Validation Loss: 116.64
2025-02-24 20:33:00,977 - Epoch 149, Training Loss: 98.84, Validation Loss: 116.54
2025-02-24 20:33:01,146 - Epoch 150, Training Loss: 109.21, Validation Loss: 116.34
2025-02-24 20:33:01,318 - Epoch 151, Training Loss: 109.77, Validation Loss: 116.13
2025-02-24 20:33:01,482 - Epoch 152, Training Loss: 95.92, Validation Loss: 115.97
2025-02-24 20:33:01,657 - Epoch 153, Training Loss: 94.46, Validation Loss: 115.80
2025-02-24 20:33:01,823 - Epoch 154, Training Loss: 90.75, Validation Loss: 115.68
2025-02-24 20:33:02,003 - Epoch 155, Training Loss: 83.73, Validation Loss: 115.67
2025-02-24 20:33:02,171 - Epoch 156, Training Loss: 103.73, Validation Loss: 115.49
2025-02-24 20:33:02,341 - Epoch 157, Training Loss: 107.59, Validation Loss: 115.27
2025-02-24 20:33:02,510 - Epoch 158, Training Loss: 87.97, Validation Loss: 115.19
2025-02-24 20:33:02,688 - Epoch 159, Training Loss: 92.82, Validation Loss: 115.07
2025-02-24 20:33:02,852 - Epoch 160, Training Loss: 119.37, Validation Loss: 114.88
2025-02-24 20:33:03,024 - Epoch 161, Training Loss: 110.86, Validation Loss: 114.73
2025-02-24 20:33:03,190 - Epoch 162, Training Loss: 93.00, Validation Loss: 114.60
2025-02-24 20:33:03,362 - Epoch 163, Training Loss: 87.04, Validation Loss: 114.48
2025-02-24 20:33:03,528 - Epoch 164, Training Loss: 93.64, Validation Loss: 114.32
2025-02-24 20:33:03,709 - Epoch 165, Training Loss: 94.96, Validation Loss: 114.18
2025-02-24 20:33:03,873 - Epoch 166, Training Loss: 94.74, Validation Loss: 114.02
2025-02-24 20:33:04,048 - Epoch 167, Training Loss: 86.95, Validation Loss: 113.97
2025-02-24 20:33:04,214 - Epoch 168, Training Loss: 93.59, Validation Loss: 113.83
2025-02-24 20:33:04,386 - Epoch 169, Training Loss: 86.24, Validation Loss: 113.76
2025-02-24 20:33:04,552 - Epoch 170, Training Loss: 109.72, Validation Loss: 113.56
2025-02-24 20:33:04,727 - Epoch 171, Training Loss: 92.48, Validation Loss: 113.40
2025-02-24 20:33:04,889 - Epoch 172, Training Loss: 87.61, Validation Loss: 113.33
2025-02-24 20:33:05,070 - Epoch 173, Training Loss: 90.98, Validation Loss: 113.22
2025-02-24 20:33:05,237 - Epoch 174, Training Loss: 104.16, Validation Loss: 113.01
2025-02-24 20:33:05,411 - Epoch 175, Training Loss: 86.70, Validation Loss: 112.92
2025-02-24 20:33:05,575 - Epoch 176, Training Loss: 90.62, Validation Loss: 112.80
2025-02-24 20:33:05,754 - Epoch 177, Training Loss: 103.47, Validation Loss: 112.67
2025-02-24 20:33:05,919 - Epoch 178, Training Loss: 91.28, Validation Loss: 112.51
2025-02-24 20:33:06,097 - Epoch 179, Training Loss: 120.71, Validation Loss: 112.27
2025-02-24 20:33:06,262 - Epoch 180, Training Loss: 110.00, Validation Loss: 112.05
2025-02-24 20:33:06,440 - Epoch 181, Training Loss: 88.19, Validation Loss: 111.94
2025-02-24 20:33:06,611 - Epoch 182, Training Loss: 103.10, Validation Loss: 111.81
2025-02-24 20:33:06,794 - Epoch 183, Training Loss: 108.59, Validation Loss: 111.63
2025-02-24 20:33:06,954 - Epoch 184, Training Loss: 103.42, Validation Loss: 111.45
2025-02-24 20:33:07,127 - Epoch 185, Training Loss: 83.57, Validation Loss: 111.42
2025-02-24 20:33:07,297 - Epoch 186, Training Loss: 99.46, Validation Loss: 111.25
2025-02-24 20:33:07,469 - Epoch 187, Training Loss: 94.46, Validation Loss: 111.12
2025-02-24 20:33:07,636 - Epoch 188, Training Loss: 94.02, Validation Loss: 111.06
2025-02-24 20:33:07,811 - Epoch 189, Training Loss: 90.26, Validation Loss: 110.97
2025-02-24 20:33:07,980 - Epoch 190, Training Loss: 99.07, Validation Loss: 110.86
2025-02-24 20:33:08,158 - Epoch 191, Training Loss: 91.30, Validation Loss: 110.72
2025-02-24 20:33:08,324 - Epoch 192, Training Loss: 91.69, Validation Loss: 110.57
2025-02-24 20:33:08,499 - Epoch 193, Training Loss: 96.62, Validation Loss: 110.43
2025-02-24 20:33:08,667 - Epoch 194, Training Loss: 82.17, Validation Loss: 110.42
2025-02-24 20:33:08,840 - Epoch 195, Training Loss: 89.28, Validation Loss: 110.31
2025-02-24 20:33:09,006 - Epoch 196, Training Loss: 101.04, Validation Loss: 110.17
2025-02-24 20:33:09,182 - Epoch 197, Training Loss: 80.22, Validation Loss: 110.15
2025-02-24 20:33:09,345 - Epoch 198, Training Loss: 101.04, Validation Loss: 109.95
2025-02-24 20:33:09,516 - Epoch 199, Training Loss: 93.92, Validation Loss: 109.85
2025-02-24 20:33:09,683 - Epoch 200, Training Loss: 89.07, Validation Loss: 109.72
2025-02-24 20:33:09,856 - Epoch 201, Training Loss: 115.93, Validation Loss: 109.57
2025-02-24 20:33:10,020 - Epoch 202, Training Loss: 107.53, Validation Loss: 109.40
2025-02-24 20:33:10,195 - Epoch 203, Training Loss: 81.97, Validation Loss: 109.39
2025-02-24 20:33:10,360 - Epoch 204, Training Loss: 83.22, Validation Loss: 109.34
2025-02-24 20:33:10,531 - Epoch 205, Training Loss: 115.47, Validation Loss: 109.15
2025-02-24 20:33:10,697 - Epoch 206, Training Loss: 107.14, Validation Loss: 108.97
2025-02-24 20:33:10,869 - Epoch 207, Training Loss: 109.49, Validation Loss: 108.79
2025-02-24 20:33:11,038 - Epoch 208, Training Loss: 79.93, Validation Loss: 108.79
2025-02-24 20:33:11,211 - Epoch 209, Training Loss: 100.15, Validation Loss: 108.69
2025-02-24 20:33:11,377 - Epoch 210, Training Loss: 93.60, Validation Loss: 108.56
2025-02-24 20:33:11,553 - Epoch 211, Training Loss: 81.79, Validation Loss: 108.53
2025-02-24 20:33:11,719 - Epoch 212, Training Loss: 116.89, Validation Loss: 108.33
2025-02-24 20:33:11,891 - Epoch 213, Training Loss: 86.33, Validation Loss: 108.25
2025-02-24 20:33:12,062 - Epoch 214, Training Loss: 85.30, Validation Loss: 108.14
2025-02-24 20:33:12,241 - Epoch 215, Training Loss: 98.66, Validation Loss: 108.03
2025-02-24 20:33:12,407 - Epoch 216, Training Loss: 91.03, Validation Loss: 107.92
2025-02-24 20:33:12,580 - Epoch 217, Training Loss: 92.20, Validation Loss: 107.82
2025-02-24 20:33:12,753 - Epoch 218, Training Loss: 97.54, Validation Loss: 107.72
2025-02-24 20:33:12,929 - Epoch 219, Training Loss: 89.76, Validation Loss: 107.60
2025-02-24 20:33:13,095 - Epoch 220, Training Loss: 84.89, Validation Loss: 107.53
2025-02-24 20:33:13,268 - Epoch 221, Training Loss: 109.23, Validation Loss: 107.34
2025-02-24 20:33:13,443 - Epoch 222, Training Loss: 95.80, Validation Loss: 107.23
2025-02-24 20:33:13,616 - Epoch 223, Training Loss: 110.71, Validation Loss: 107.14
2025-02-24 20:33:13,783 - Epoch 224, Training Loss: 83.34, Validation Loss: 107.09
2025-02-24 20:33:13,957 - Epoch 225, Training Loss: 96.74, Validation Loss: 107.00
2025-02-24 20:33:14,132 - Epoch 226, Training Loss: 80.60, Validation Loss: 107.02
2025-02-24 20:33:14,296 - Epoch 227, Training Loss: 79.80, Validation Loss: 107.04
2025-02-24 20:33:14,445 - Epoch 228, Training Loss: 103.33, Validation Loss: 106.92
2025-02-24 20:33:14,617 - Epoch 229, Training Loss: 120.85, Validation Loss: 106.72
2025-02-24 20:33:14,790 - Epoch 230, Training Loss: 86.92, Validation Loss: 106.61
2025-02-24 20:33:14,963 - Epoch 231, Training Loss: 96.22, Validation Loss: 106.45
2025-02-24 20:33:15,131 - Epoch 232, Training Loss: 89.37, Validation Loss: 106.35
2025-02-24 20:33:15,310 - Epoch 233, Training Loss: 104.26, Validation Loss: 106.21
2025-02-24 20:33:15,477 - Epoch 234, Training Loss: 105.61, Validation Loss: 106.03
2025-02-24 20:33:15,647 - Epoch 235, Training Loss: 80.19, Validation Loss: 105.98
2025-02-24 20:33:15,809 - Epoch 236, Training Loss: 81.13, Validation Loss: 105.96
2025-02-24 20:33:15,984 - Epoch 237, Training Loss: 86.71, Validation Loss: 105.91
2025-02-24 20:33:16,154 - Epoch 238, Training Loss: 83.49, Validation Loss: 105.89
2025-02-24 20:33:16,327 - Epoch 239, Training Loss: 88.95, Validation Loss: 105.79
2025-02-24 20:33:16,498 - Epoch 240, Training Loss: 94.11, Validation Loss: 105.66
2025-02-24 20:33:16,671 - Epoch 241, Training Loss: 103.60, Validation Loss: 105.51
2025-02-24 20:33:16,835 - Epoch 242, Training Loss: 100.05, Validation Loss: 105.39
2025-02-24 20:33:17,010 - Epoch 243, Training Loss: 77.87, Validation Loss: 105.38
2025-02-24 20:33:17,178 - Epoch 244, Training Loss: 101.26, Validation Loss: 105.27
2025-02-24 20:33:17,352 - Epoch 245, Training Loss: 85.85, Validation Loss: 105.20
2025-02-24 20:33:17,525 - Epoch 246, Training Loss: 97.84, Validation Loss: 105.09
2025-02-24 20:33:17,697 - Epoch 247, Training Loss: 89.70, Validation Loss: 104.98
2025-02-24 20:33:17,870 - Epoch 248, Training Loss: 96.31, Validation Loss: 104.90
2025-02-24 20:33:18,042 - Epoch 249, Training Loss: 104.27, Validation Loss: 104.74
2025-02-24 20:33:18,206 - Epoch 250, Training Loss: 90.20, Validation Loss: 104.67
2025-02-24 20:33:18,382 - Epoch 251, Training Loss: 82.78, Validation Loss: 104.65
2025-02-24 20:33:18,546 - Epoch 252, Training Loss: 82.96, Validation Loss: 104.62
2025-02-24 20:33:18,732 - Epoch 253, Training Loss: 91.25, Validation Loss: 104.58
2025-02-24 20:33:18,901 - Epoch 254, Training Loss: 96.00, Validation Loss: 104.50
2025-02-24 20:33:19,072 - Epoch 255, Training Loss: 96.02, Validation Loss: 104.42
2025-02-24 20:33:19,243 - Epoch 256, Training Loss: 82.02, Validation Loss: 104.40
2025-02-24 20:33:19,415 - Epoch 257, Training Loss: 88.86, Validation Loss: 104.31
2025-02-24 20:33:19,583 - Epoch 258, Training Loss: 84.56, Validation Loss: 104.22
2025-02-24 20:33:19,770 - Epoch 259, Training Loss: 100.40, Validation Loss: 104.06
2025-02-24 20:33:19,935 - Epoch 260, Training Loss: 87.80, Validation Loss: 103.96
2025-02-24 20:33:20,108 - Epoch 261, Training Loss: 95.55, Validation Loss: 103.83
2025-02-24 20:33:20,273 - Epoch 262, Training Loss: 92.25, Validation Loss: 103.72
2025-02-24 20:33:20,447 - Epoch 263, Training Loss: 95.64, Validation Loss: 103.66
2025-02-24 20:33:20,615 - Epoch 264, Training Loss: 83.59, Validation Loss: 103.61
2025-02-24 20:33:20,796 - Epoch 265, Training Loss: 87.99, Validation Loss: 103.52
2025-02-24 20:33:20,962 - Epoch 266, Training Loss: 92.72, Validation Loss: 103.41
2025-02-24 20:33:21,135 - Epoch 267, Training Loss: 92.90, Validation Loss: 103.37
2025-02-24 20:33:21,308 - Epoch 268, Training Loss: 96.74, Validation Loss: 103.27
2025-02-24 20:33:21,485 - Epoch 269, Training Loss: 84.48, Validation Loss: 103.25
2025-02-24 20:33:21,654 - Epoch 270, Training Loss: 77.70, Validation Loss: 103.27
2025-02-24 20:33:21,802 - Epoch 271, Training Loss: 88.46, Validation Loss: 103.21
2025-02-24 20:33:21,971 - Epoch 272, Training Loss: 100.25, Validation Loss: 103.07
2025-02-24 20:33:22,148 - Epoch 273, Training Loss: 91.30, Validation Loss: 102.95
2025-02-24 20:33:22,325 - Epoch 274, Training Loss: 98.30, Validation Loss: 102.83
2025-02-24 20:33:22,500 - Epoch 275, Training Loss: 88.54, Validation Loss: 102.72
2025-02-24 20:33:22,667 - Epoch 276, Training Loss: 86.59, Validation Loss: 102.67
2025-02-24 20:33:22,838 - Epoch 277, Training Loss: 94.74, Validation Loss: 102.58
2025-02-24 20:33:23,004 - Epoch 278, Training Loss: 84.57, Validation Loss: 102.51
2025-02-24 20:33:23,184 - Epoch 279, Training Loss: 87.83, Validation Loss: 102.42
2025-02-24 20:33:23,350 - Epoch 280, Training Loss: 100.97, Validation Loss: 102.31
2025-02-24 20:33:23,521 - Epoch 281, Training Loss: 97.05, Validation Loss: 102.20
2025-02-24 20:33:23,684 - Epoch 282, Training Loss: 96.20, Validation Loss: 102.12
2025-02-24 20:33:23,854 - Epoch 283, Training Loss: 88.18, Validation Loss: 102.02
2025-02-24 20:33:24,019 - Epoch 284, Training Loss: 89.65, Validation Loss: 101.94
2025-02-24 20:33:24,190 - Epoch 285, Training Loss: 91.86, Validation Loss: 101.84
2025-02-24 20:33:24,357 - Epoch 286, Training Loss: 92.66, Validation Loss: 101.74
2025-02-24 20:33:24,528 - Epoch 287, Training Loss: 85.59, Validation Loss: 101.66
2025-02-24 20:33:24,691 - Epoch 288, Training Loss: 99.29, Validation Loss: 101.56
2025-02-24 20:33:24,864 - Epoch 289, Training Loss: 79.87, Validation Loss: 101.51
2025-02-24 20:33:25,031 - Epoch 290, Training Loss: 93.02, Validation Loss: 101.45
2025-02-24 20:33:25,207 - Epoch 291, Training Loss: 84.79, Validation Loss: 101.40
2025-02-24 20:33:25,370 - Epoch 292, Training Loss: 89.77, Validation Loss: 101.35
2025-02-24 20:33:25,547 - Epoch 293, Training Loss: 95.20, Validation Loss: 101.26
2025-02-24 20:33:25,726 - Epoch 294, Training Loss: 96.41, Validation Loss: 101.17
2025-02-24 20:33:25,899 - Epoch 295, Training Loss: 98.75, Validation Loss: 101.07
2025-02-24 20:33:26,083 - Epoch 296, Training Loss: 98.27, Validation Loss: 100.98
2025-02-24 20:33:26,254 - Epoch 297, Training Loss: 97.50, Validation Loss: 100.85
2025-02-24 20:33:26,427 - Epoch 298, Training Loss: 94.81, Validation Loss: 100.71
2025-02-24 20:33:26,591 - Epoch 299, Training Loss: 83.62, Validation Loss: 100.64
2025-02-24 20:33:26,765 - Epoch 300, Training Loss: 87.02, Validation Loss: 100.60
2025-02-24 20:33:26,933 - Epoch 301, Training Loss: 90.90, Validation Loss: 100.52
2025-02-24 20:33:27,107 - Epoch 302, Training Loss: 91.33, Validation Loss: 100.48
2025-02-24 20:33:27,276 - Epoch 303, Training Loss: 82.47, Validation Loss: 100.42
2025-02-24 20:33:27,447 - Epoch 304, Training Loss: 100.23, Validation Loss: 100.32
2025-02-24 20:33:27,612 - Epoch 305, Training Loss: 80.10, Validation Loss: 100.30
2025-02-24 20:33:27,792 - Epoch 306, Training Loss: 83.94, Validation Loss: 100.24
2025-02-24 20:33:27,961 - Epoch 307, Training Loss: 93.32, Validation Loss: 100.16
2025-02-24 20:33:28,135 - Epoch 308, Training Loss: 103.52, Validation Loss: 100.09
2025-02-24 20:33:28,307 - Epoch 309, Training Loss: 78.67, Validation Loss: 100.05
2025-02-24 20:33:28,500 - Epoch 310, Training Loss: 85.10, Validation Loss: 100.03
2025-02-24 20:33:28,668 - Epoch 311, Training Loss: 81.06, Validation Loss: 99.97
2025-02-24 20:33:28,843 - Epoch 312, Training Loss: 94.99, Validation Loss: 99.87
2025-02-24 20:33:29,008 - Epoch 313, Training Loss: 112.62, Validation Loss: 99.73
2025-02-24 20:33:29,184 - Epoch 314, Training Loss: 87.87, Validation Loss: 99.66
2025-02-24 20:33:29,353 - Epoch 315, Training Loss: 97.15, Validation Loss: 99.56
2025-02-24 20:33:29,525 - Epoch 316, Training Loss: 85.43, Validation Loss: 99.49
2025-02-24 20:33:29,693 - Epoch 317, Training Loss: 80.32, Validation Loss: 99.45
2025-02-24 20:33:29,865 - Epoch 318, Training Loss: 84.92, Validation Loss: 99.41
2025-02-24 20:33:30,033 - Epoch 319, Training Loss: 80.71, Validation Loss: 99.40
2025-02-24 20:33:30,205 - Epoch 320, Training Loss: 82.73, Validation Loss: 99.36
2025-02-24 20:33:30,373 - Epoch 321, Training Loss: 84.90, Validation Loss: 99.28
2025-02-24 20:33:30,556 - Epoch 322, Training Loss: 82.35, Validation Loss: 99.21
2025-02-24 20:33:30,721 - Epoch 323, Training Loss: 97.98, Validation Loss: 99.08
2025-02-24 20:33:30,901 - Epoch 324, Training Loss: 92.67, Validation Loss: 99.02
2025-02-24 20:33:31,065 - Epoch 325, Training Loss: 97.42, Validation Loss: 98.94
2025-02-24 20:33:31,239 - Epoch 326, Training Loss: 87.59, Validation Loss: 98.86
2025-02-24 20:33:31,430 - Epoch 327, Training Loss: 95.27, Validation Loss: 98.73
2025-02-24 20:33:31,600 - Epoch 328, Training Loss: 82.27, Validation Loss: 98.66
2025-02-24 20:33:31,776 - Epoch 329, Training Loss: 89.86, Validation Loss: 98.57
2025-02-24 20:33:31,948 - Epoch 330, Training Loss: 80.90, Validation Loss: 98.50
2025-02-24 20:33:32,122 - Epoch 331, Training Loss: 77.86, Validation Loss: 98.48
2025-02-24 20:33:32,289 - Epoch 332, Training Loss: 81.68, Validation Loss: 98.43
2025-02-24 20:33:32,467 - Epoch 333, Training Loss: 93.09, Validation Loss: 98.37
2025-02-24 20:33:32,634 - Epoch 334, Training Loss: 87.35, Validation Loss: 98.32
2025-02-24 20:33:32,807 - Epoch 335, Training Loss: 81.23, Validation Loss: 98.29
2025-02-24 20:33:32,973 - Epoch 336, Training Loss: 95.60, Validation Loss: 98.19
2025-02-24 20:33:33,145 - Epoch 337, Training Loss: 90.25, Validation Loss: 98.11
2025-02-24 20:33:33,313 - Epoch 338, Training Loss: 86.95, Validation Loss: 98.10
2025-02-24 20:33:33,493 - Epoch 339, Training Loss: 82.83, Validation Loss: 98.05
2025-02-24 20:33:33,657 - Epoch 340, Training Loss: 81.22, Validation Loss: 98.04
2025-02-24 20:33:33,831 - Epoch 341, Training Loss: 82.02, Validation Loss: 97.98
2025-02-24 20:33:33,998 - Epoch 342, Training Loss: 81.41, Validation Loss: 97.94
2025-02-24 20:33:34,172 - Epoch 343, Training Loss: 88.39, Validation Loss: 97.89
2025-02-24 20:33:34,344 - Epoch 344, Training Loss: 81.61, Validation Loss: 97.81
2025-02-24 20:33:34,512 - Epoch 345, Training Loss: 87.61, Validation Loss: 97.76
2025-02-24 20:33:34,682 - Epoch 346, Training Loss: 87.83, Validation Loss: 97.70
2025-02-24 20:33:34,855 - Epoch 347, Training Loss: 83.24, Validation Loss: 97.65
2025-02-24 20:33:35,022 - Epoch 348, Training Loss: 100.78, Validation Loss: 97.56
2025-02-24 20:33:35,197 - Epoch 349, Training Loss: 83.01, Validation Loss: 97.53
2025-02-24 20:33:35,363 - Epoch 350, Training Loss: 81.53, Validation Loss: 97.48
2025-02-24 20:33:35,535 - Epoch 351, Training Loss: 83.61, Validation Loss: 97.43
2025-02-24 20:33:35,705 - Epoch 352, Training Loss: 91.17, Validation Loss: 97.38
2025-02-24 20:33:35,879 - Epoch 353, Training Loss: 90.68, Validation Loss: 97.33
2025-02-24 20:33:36,044 - Epoch 354, Training Loss: 104.87, Validation Loss: 97.20
2025-02-24 20:33:36,219 - Epoch 355, Training Loss: 96.16, Validation Loss: 97.12
2025-02-24 20:33:36,388 - Epoch 356, Training Loss: 82.57, Validation Loss: 97.04
2025-02-24 20:33:36,555 - Epoch 357, Training Loss: 96.37, Validation Loss: 96.96
2025-02-24 20:33:36,731 - Epoch 358, Training Loss: 86.66, Validation Loss: 96.93
2025-02-24 20:33:36,901 - Epoch 359, Training Loss: 79.81, Validation Loss: 96.89
2025-02-24 20:33:37,065 - Epoch 360, Training Loss: 91.92, Validation Loss: 96.82
2025-02-24 20:33:37,237 - Epoch 361, Training Loss: 82.06, Validation Loss: 96.74
2025-02-24 20:33:37,405 - Epoch 362, Training Loss: 82.49, Validation Loss: 96.66
2025-02-24 20:33:37,578 - Epoch 363, Training Loss: 85.44, Validation Loss: 96.60
2025-02-24 20:33:37,745 - Epoch 364, Training Loss: 82.46, Validation Loss: 96.52
2025-02-24 20:33:37,918 - Epoch 365, Training Loss: 104.24, Validation Loss: 96.43
2025-02-24 20:33:38,084 - Epoch 366, Training Loss: 83.68, Validation Loss: 96.38
2025-02-24 20:33:38,259 - Epoch 367, Training Loss: 81.54, Validation Loss: 96.36
2025-02-24 20:33:38,421 - Epoch 368, Training Loss: 82.34, Validation Loss: 96.32
2025-02-24 20:33:38,598 - Epoch 369, Training Loss: 79.57, Validation Loss: 96.30
2025-02-24 20:33:38,767 - Epoch 370, Training Loss: 90.23, Validation Loss: 96.25
2025-02-24 20:33:38,950 - Epoch 371, Training Loss: 89.90, Validation Loss: 96.25
2025-02-24 20:33:39,114 - Epoch 372, Training Loss: 77.25, Validation Loss: 96.23
2025-02-24 20:33:39,293 - Epoch 373, Training Loss: 80.40, Validation Loss: 96.18
2025-02-24 20:33:39,459 - Epoch 374, Training Loss: 81.12, Validation Loss: 96.17
2025-02-24 20:33:39,631 - Epoch 375, Training Loss: 81.56, Validation Loss: 96.14
2025-02-24 20:33:39,802 - Epoch 376, Training Loss: 97.93, Validation Loss: 96.05
2025-02-24 20:33:39,976 - Epoch 377, Training Loss: 98.20, Validation Loss: 95.94
2025-02-24 20:33:40,144 - Epoch 378, Training Loss: 82.95, Validation Loss: 95.88
2025-02-24 20:33:40,322 - Epoch 379, Training Loss: 90.41, Validation Loss: 95.82
2025-02-24 20:33:40,509 - Epoch 380, Training Loss: 86.34, Validation Loss: 95.74
2025-02-24 20:33:40,679 - Epoch 381, Training Loss: 91.17, Validation Loss: 95.70
2025-02-24 20:33:40,852 - Epoch 382, Training Loss: 80.33, Validation Loss: 95.68
2025-02-24 20:33:41,018 - Epoch 383, Training Loss: 79.26, Validation Loss: 95.67
2025-02-24 20:33:41,201 - Epoch 384, Training Loss: 93.71, Validation Loss: 95.60
2025-02-24 20:33:41,364 - Epoch 385, Training Loss: 83.64, Validation Loss: 95.56
2025-02-24 20:33:41,537 - Epoch 386, Training Loss: 93.71, Validation Loss: 95.51
2025-02-24 20:33:41,706 - Epoch 387, Training Loss: 90.47, Validation Loss: 95.41
2025-02-24 20:33:41,876 - Epoch 388, Training Loss: 85.64, Validation Loss: 95.36
2025-02-24 20:33:42,040 - Epoch 389, Training Loss: 103.83, Validation Loss: 95.25
2025-02-24 20:33:42,212 - Epoch 390, Training Loss: 93.05, Validation Loss: 95.17
2025-02-24 20:33:42,378 - Epoch 391, Training Loss: 91.77, Validation Loss: 95.14
2025-02-24 20:33:42,554 - Epoch 392, Training Loss: 88.73, Validation Loss: 95.09
2025-02-24 20:33:42,725 - Epoch 393, Training Loss: 79.05, Validation Loss: 95.05
2025-02-24 20:33:42,898 - Epoch 394, Training Loss: 84.08, Validation Loss: 94.97
2025-02-24 20:33:43,061 - Epoch 395, Training Loss: 76.29, Validation Loss: 94.94
2025-02-24 20:33:43,235 - Epoch 396, Training Loss: 95.59, Validation Loss: 94.85
2025-02-24 20:33:43,402 - Epoch 397, Training Loss: 92.26, Validation Loss: 94.81
2025-02-24 20:33:43,575 - Epoch 398, Training Loss: 82.73, Validation Loss: 94.75
2025-02-24 20:33:43,742 - Epoch 399, Training Loss: 91.81, Validation Loss: 94.70
2025-02-24 20:33:43,912 - Epoch 400, Training Loss: 80.01, Validation Loss: 94.66
2025-02-24 20:33:44,078 - Epoch 401, Training Loss: 80.90, Validation Loss: 94.65
2025-02-24 20:33:44,252 - Epoch 402, Training Loss: 81.49, Validation Loss: 94.59
2025-02-24 20:33:44,420 - Epoch 403, Training Loss: 90.48, Validation Loss: 94.54
2025-02-24 20:33:44,593 - Epoch 404, Training Loss: 89.97, Validation Loss: 94.49
2025-02-24 20:33:44,759 - Epoch 405, Training Loss: 81.71, Validation Loss: 94.44
2025-02-24 20:33:44,933 - Epoch 406, Training Loss: 88.04, Validation Loss: 94.40
2025-02-24 20:33:45,099 - Epoch 407, Training Loss: 89.93, Validation Loss: 94.35
2025-02-24 20:33:45,271 - Epoch 408, Training Loss: 80.72, Validation Loss: 94.30
2025-02-24 20:33:45,437 - Epoch 409, Training Loss: 82.12, Validation Loss: 94.24
2025-02-24 20:33:45,606 - Epoch 410, Training Loss: 85.24, Validation Loss: 94.24
2025-02-24 20:33:45,772 - Epoch 411, Training Loss: 96.97, Validation Loss: 94.20
2025-02-24 20:33:45,944 - Epoch 412, Training Loss: 78.14, Validation Loss: 94.18
2025-02-24 20:33:46,109 - Epoch 413, Training Loss: 98.45, Validation Loss: 94.09
2025-02-24 20:33:46,293 - Epoch 414, Training Loss: 84.03, Validation Loss: 94.02
2025-02-24 20:33:46,458 - Epoch 415, Training Loss: 89.70, Validation Loss: 93.96
2025-02-24 20:33:46,628 - Epoch 416, Training Loss: 91.30, Validation Loss: 93.90
2025-02-24 20:33:46,794 - Epoch 417, Training Loss: 84.47, Validation Loss: 93.86
2025-02-24 20:33:46,968 - Epoch 418, Training Loss: 75.21, Validation Loss: 93.84
2025-02-24 20:33:47,132 - Epoch 419, Training Loss: 83.06, Validation Loss: 93.77
2025-02-24 20:33:47,305 - Epoch 420, Training Loss: 79.33, Validation Loss: 93.74
2025-02-24 20:33:47,473 - Epoch 421, Training Loss: 76.63, Validation Loss: 93.76
2025-02-24 20:33:47,627 - Epoch 422, Training Loss: 79.12, Validation Loss: 93.72
2025-02-24 20:33:47,809 - Epoch 423, Training Loss: 90.35, Validation Loss: 93.66
2025-02-24 20:33:47,984 - Epoch 424, Training Loss: 85.62, Validation Loss: 93.59
2025-02-24 20:33:48,162 - Epoch 425, Training Loss: 78.62, Validation Loss: 93.54
2025-02-24 20:33:48,331 - Epoch 426, Training Loss: 91.86, Validation Loss: 93.45
2025-02-24 20:33:48,505 - Epoch 427, Training Loss: 79.64, Validation Loss: 93.44
2025-02-24 20:33:48,673 - Epoch 428, Training Loss: 84.23, Validation Loss: 93.44
2025-02-24 20:33:48,838 - Epoch 429, Training Loss: 78.65, Validation Loss: 93.44
2025-02-24 20:33:49,003 - Epoch 430, Training Loss: 86.35, Validation Loss: 93.35
2025-02-24 20:33:49,189 - Epoch 431, Training Loss: 102.83, Validation Loss: 93.25
2025-02-24 20:33:49,361 - Epoch 432, Training Loss: 84.81, Validation Loss: 93.20
2025-02-24 20:33:49,537 - Epoch 433, Training Loss: 93.13, Validation Loss: 93.14
2025-02-24 20:33:49,703 - Epoch 434, Training Loss: 80.05, Validation Loss: 93.08
2025-02-24 20:33:49,879 - Epoch 435, Training Loss: 90.38, Validation Loss: 92.99
2025-02-24 20:33:50,058 - Epoch 436, Training Loss: 83.25, Validation Loss: 92.94
2025-02-24 20:33:50,230 - Epoch 437, Training Loss: 90.90, Validation Loss: 92.85
2025-02-24 20:33:50,397 - Epoch 438, Training Loss: 87.15, Validation Loss: 92.82
2025-02-24 20:33:50,567 - Epoch 439, Training Loss: 74.84, Validation Loss: 92.81
2025-02-24 20:33:50,736 - Epoch 440, Training Loss: 97.27, Validation Loss: 92.74
2025-02-24 20:33:50,920 - Epoch 441, Training Loss: 86.68, Validation Loss: 92.74
2025-02-24 20:33:51,087 - Epoch 442, Training Loss: 76.27, Validation Loss: 92.74
2025-02-24 20:33:51,260 - Epoch 443, Training Loss: 101.47, Validation Loss: 92.62
2025-02-24 20:33:51,430 - Epoch 444, Training Loss: 84.61, Validation Loss: 92.56
2025-02-24 20:33:51,604 - Epoch 445, Training Loss: 100.54, Validation Loss: 92.45
2025-02-24 20:33:51,771 - Epoch 446, Training Loss: 94.92, Validation Loss: 92.36
2025-02-24 20:33:51,949 - Epoch 447, Training Loss: 77.42, Validation Loss: 92.33
2025-02-24 20:33:52,120 - Epoch 448, Training Loss: 80.84, Validation Loss: 92.28
2025-02-24 20:33:52,292 - Epoch 449, Training Loss: 80.19, Validation Loss: 92.26
2025-02-24 20:33:52,465 - Epoch 450, Training Loss: 92.88, Validation Loss: 92.20
2025-02-24 20:33:52,636 - Epoch 451, Training Loss: 98.34, Validation Loss: 92.14
2025-02-24 20:33:52,808 - Epoch 452, Training Loss: 74.37, Validation Loss: 92.13
2025-02-24 20:33:52,983 - Epoch 453, Training Loss: 87.21, Validation Loss: 92.12
2025-02-24 20:33:53,149 - Epoch 454, Training Loss: 86.07, Validation Loss: 92.12
2025-02-24 20:33:53,297 - Epoch 455, Training Loss: 78.38, Validation Loss: 92.09
2025-02-24 20:33:53,467 - Epoch 456, Training Loss: 90.05, Validation Loss: 92.02
2025-02-24 20:33:53,640 - Epoch 457, Training Loss: 78.29, Validation Loss: 91.99
2025-02-24 20:33:53,805 - Epoch 458, Training Loss: 80.89, Validation Loss: 91.95
2025-02-24 20:33:53,991 - Epoch 459, Training Loss: 83.49, Validation Loss: 91.87
2025-02-24 20:33:54,154 - Epoch 460, Training Loss: 98.09, Validation Loss: 91.81
2025-02-24 20:33:54,329 - Epoch 461, Training Loss: 82.43, Validation Loss: 91.81
2025-02-24 20:33:54,498 - Epoch 462, Training Loss: 75.60, Validation Loss: 91.78
2025-02-24 20:33:54,669 - Epoch 463, Training Loss: 82.07, Validation Loss: 91.72
2025-02-24 20:33:54,837 - Epoch 464, Training Loss: 86.76, Validation Loss: 91.69
2025-02-24 20:33:55,009 - Epoch 465, Training Loss: 87.34, Validation Loss: 91.63
2025-02-24 20:33:55,173 - Epoch 466, Training Loss: 95.72, Validation Loss: 91.56
2025-02-24 20:33:55,346 - Epoch 467, Training Loss: 82.42, Validation Loss: 91.50
2025-02-24 20:33:55,517 - Epoch 468, Training Loss: 86.09, Validation Loss: 91.45
2025-02-24 20:33:55,690 - Epoch 469, Training Loss: 80.28, Validation Loss: 91.42
2025-02-24 20:33:55,861 - Epoch 470, Training Loss: 81.40, Validation Loss: 91.39
2025-02-24 20:33:56,042 - Epoch 471, Training Loss: 97.00, Validation Loss: 91.30
2025-02-24 20:33:56,211 - Epoch 472, Training Loss: 79.49, Validation Loss: 91.28
2025-02-24 20:33:56,389 - Epoch 473, Training Loss: 80.22, Validation Loss: 91.24
2025-02-24 20:33:56,566 - Epoch 474, Training Loss: 77.42, Validation Loss: 91.24
2025-02-24 20:33:56,740 - Epoch 475, Training Loss: 97.20, Validation Loss: 91.17
2025-02-24 20:33:56,928 - Epoch 476, Training Loss: 104.80, Validation Loss: 91.07
2025-02-24 20:33:57,097 - Epoch 477, Training Loss: 87.10, Validation Loss: 91.03
2025-02-24 20:33:57,273 - Epoch 478, Training Loss: 73.98, Validation Loss: 91.04
2025-02-24 20:33:57,417 - Epoch 479, Training Loss: 82.65, Validation Loss: 91.02
2025-02-24 20:33:57,592 - Epoch 480, Training Loss: 79.83, Validation Loss: 90.98
2025-02-24 20:33:57,760 - Epoch 481, Training Loss: 94.84, Validation Loss: 90.92
2025-02-24 20:33:57,936 - Epoch 482, Training Loss: 81.32, Validation Loss: 90.86
2025-02-24 20:33:58,100 - Epoch 483, Training Loss: 74.61, Validation Loss: 90.82
2025-02-24 20:33:58,274 - Epoch 484, Training Loss: 87.04, Validation Loss: 90.80
2025-02-24 20:33:58,442 - Epoch 485, Training Loss: 81.25, Validation Loss: 90.76
2025-02-24 20:33:58,613 - Epoch 486, Training Loss: 78.05, Validation Loss: 90.76
2025-02-24 20:33:58,765 - Epoch 487, Training Loss: 81.81, Validation Loss: 90.73
2025-02-24 20:33:58,942 - Epoch 488, Training Loss: 79.94, Validation Loss: 90.69
2025-02-24 20:33:59,115 - Epoch 489, Training Loss: 81.57, Validation Loss: 90.63
2025-02-24 20:33:59,289 - Epoch 490, Training Loss: 84.73, Validation Loss: 90.59
2025-02-24 20:33:59,460 - Epoch 491, Training Loss: 82.76, Validation Loss: 90.55
2025-02-24 20:33:59,632 - Epoch 492, Training Loss: 77.92, Validation Loss: 90.53
2025-02-24 20:33:59,800 - Epoch 493, Training Loss: 85.66, Validation Loss: 90.51
2025-02-24 20:33:59,971 - Epoch 494, Training Loss: 88.17, Validation Loss: 90.45
2025-02-24 20:34:00,142 - Epoch 495, Training Loss: 80.86, Validation Loss: 90.43
2025-02-24 20:34:00,317 - Epoch 496, Training Loss: 88.65, Validation Loss: 90.40
2025-02-24 20:34:00,491 - Epoch 497, Training Loss: 78.76, Validation Loss: 90.39
2025-02-24 20:34:00,665 - Epoch 498, Training Loss: 86.41, Validation Loss: 90.30
2025-02-24 20:34:00,829 - Epoch 499, Training Loss: 77.96, Validation Loss: 90.25
2025-02-24 20:34:01,016 - Epoch 500, Training Loss: 92.87, Validation Loss: 90.20
2025-02-24 20:34:01,184 - Epoch 501, Training Loss: 81.66, Validation Loss: 90.17
2025-02-24 20:34:01,357 - Epoch 502, Training Loss: 83.74, Validation Loss: 90.14
2025-02-24 20:34:01,534 - Epoch 503, Training Loss: 82.33, Validation Loss: 90.09
2025-02-24 20:34:01,713 - Epoch 504, Training Loss: 73.34, Validation Loss: 90.13
2025-02-24 20:34:01,857 - Epoch 505, Training Loss: 78.26, Validation Loss: 90.12
2025-02-24 20:34:02,008 - Epoch 506, Training Loss: 99.22, Validation Loss: 90.06
2025-02-24 20:34:02,175 - Epoch 507, Training Loss: 100.70, Validation Loss: 89.97
2025-02-24 20:34:02,343 - Epoch 508, Training Loss: 91.22, Validation Loss: 89.90
2025-02-24 20:34:02,514 - Epoch 509, Training Loss: 85.55, Validation Loss: 89.88
2025-02-24 20:34:02,688 - Epoch 510, Training Loss: 80.42, Validation Loss: 89.84
2025-02-24 20:34:02,856 - Epoch 511, Training Loss: 77.91, Validation Loss: 89.81
2025-02-24 20:34:03,047 - Epoch 512, Training Loss: 86.18, Validation Loss: 89.77
2025-02-24 20:34:03,211 - Epoch 513, Training Loss: 72.41, Validation Loss: 89.81
2025-02-24 20:34:03,363 - Epoch 514, Training Loss: 82.49, Validation Loss: 89.73
2025-02-24 20:34:03,528 - Epoch 515, Training Loss: 93.86, Validation Loss: 89.66
2025-02-24 20:34:03,701 - Epoch 516, Training Loss: 88.81, Validation Loss: 89.63
2025-02-24 20:34:03,869 - Epoch 517, Training Loss: 93.63, Validation Loss: 89.54
2025-02-24 20:34:04,044 - Epoch 518, Training Loss: 75.47, Validation Loss: 89.56
2025-02-24 20:34:04,192 - Epoch 519, Training Loss: 79.74, Validation Loss: 89.50
2025-02-24 20:34:04,367 - Epoch 520, Training Loss: 77.71, Validation Loss: 89.48
2025-02-24 20:34:04,548 - Epoch 521, Training Loss: 74.48, Validation Loss: 89.50
2025-02-24 20:34:04,698 - Epoch 522, Training Loss: 92.25, Validation Loss: 89.43
2025-02-24 20:34:04,862 - Epoch 523, Training Loss: 76.68, Validation Loss: 89.40
2025-02-24 20:34:05,045 - Epoch 524, Training Loss: 79.91, Validation Loss: 89.36
2025-02-24 20:34:05,211 - Epoch 525, Training Loss: 96.15, Validation Loss: 89.29
2025-02-24 20:34:05,386 - Epoch 526, Training Loss: 86.91, Validation Loss: 89.27
2025-02-24 20:34:05,556 - Epoch 527, Training Loss: 74.71, Validation Loss: 89.27
2025-02-24 20:34:05,711 - Epoch 528, Training Loss: 83.57, Validation Loss: 89.26
2025-02-24 20:34:05,882 - Epoch 529, Training Loss: 82.15, Validation Loss: 89.21
2025-02-24 20:34:06,062 - Epoch 530, Training Loss: 102.57, Validation Loss: 89.11
2025-02-24 20:34:06,226 - Epoch 531, Training Loss: 83.09, Validation Loss: 89.07
2025-02-24 20:34:06,402 - Epoch 532, Training Loss: 89.69, Validation Loss: 89.02
2025-02-24 20:34:06,570 - Epoch 533, Training Loss: 80.75, Validation Loss: 88.97
2025-02-24 20:34:06,745 - Epoch 534, Training Loss: 91.10, Validation Loss: 88.94
2025-02-24 20:34:06,918 - Epoch 535, Training Loss: 84.73, Validation Loss: 88.89
2025-02-24 20:34:07,111 - Epoch 536, Training Loss: 76.29, Validation Loss: 88.88
2025-02-24 20:34:07,289 - Epoch 537, Training Loss: 88.62, Validation Loss: 88.81
2025-02-24 20:34:07,469 - Epoch 538, Training Loss: 93.86, Validation Loss: 88.75
2025-02-24 20:34:07,634 - Epoch 539, Training Loss: 80.15, Validation Loss: 88.72
2025-02-24 20:34:07,810 - Epoch 540, Training Loss: 74.38, Validation Loss: 88.74
2025-02-24 20:34:07,957 - Epoch 541, Training Loss: 73.77, Validation Loss: 88.76
2025-02-24 20:34:08,108 - Epoch 542, Training Loss: 88.75, Validation Loss: 88.72
2025-02-24 20:34:08,273 - Epoch 543, Training Loss: 83.38, Validation Loss: 88.68
2025-02-24 20:34:08,448 - Epoch 544, Training Loss: 93.71, Validation Loss: 88.63
2025-02-24 20:34:08,614 - Epoch 545, Training Loss: 78.39, Validation Loss: 88.62
2025-02-24 20:34:08,786 - Epoch 546, Training Loss: 77.42, Validation Loss: 88.59
2025-02-24 20:34:08,954 - Epoch 547, Training Loss: 91.88, Validation Loss: 88.53
2025-02-24 20:34:09,129 - Epoch 548, Training Loss: 86.42, Validation Loss: 88.52
2025-02-24 20:34:09,295 - Epoch 549, Training Loss: 85.74, Validation Loss: 88.49
2025-02-24 20:34:09,467 - Epoch 550, Training Loss: 85.94, Validation Loss: 88.45
2025-02-24 20:34:09,636 - Epoch 551, Training Loss: 79.32, Validation Loss: 88.41
2025-02-24 20:34:09,807 - Epoch 552, Training Loss: 86.53, Validation Loss: 88.35
2025-02-24 20:34:09,975 - Epoch 553, Training Loss: 80.32, Validation Loss: 88.32
2025-02-24 20:34:10,145 - Epoch 554, Training Loss: 90.84, Validation Loss: 88.26
2025-02-24 20:34:10,312 - Epoch 555, Training Loss: 82.81, Validation Loss: 88.20
2025-02-24 20:34:10,484 - Epoch 556, Training Loss: 78.87, Validation Loss: 88.18
2025-02-24 20:34:10,650 - Epoch 557, Training Loss: 74.59, Validation Loss: 88.18
2025-02-24 20:34:10,824 - Epoch 558, Training Loss: 82.50, Validation Loss: 88.13
2025-02-24 20:34:10,988 - Epoch 559, Training Loss: 71.61, Validation Loss: 88.14
2025-02-24 20:34:11,144 - Epoch 560, Training Loss: 85.65, Validation Loss: 88.13
2025-02-24 20:34:11,290 - Epoch 561, Training Loss: 79.66, Validation Loss: 88.09
2025-02-24 20:34:11,460 - Epoch 562, Training Loss: 75.89, Validation Loss: 88.09
2025-02-24 20:34:11,628 - Epoch 563, Training Loss: 78.29, Validation Loss: 88.05
2025-02-24 20:34:11,801 - Epoch 564, Training Loss: 87.29, Validation Loss: 87.99
2025-02-24 20:34:11,993 - Epoch 565, Training Loss: 100.14, Validation Loss: 87.92
2025-02-24 20:34:12,161 - Epoch 566, Training Loss: 86.11, Validation Loss: 87.87
2025-02-24 20:34:12,333 - Epoch 567, Training Loss: 93.27, Validation Loss: 87.79
2025-02-24 20:34:12,506 - Epoch 568, Training Loss: 83.03, Validation Loss: 87.74
2025-02-24 20:34:12,681 - Epoch 569, Training Loss: 85.06, Validation Loss: 87.68
2025-02-24 20:34:12,865 - Epoch 570, Training Loss: 86.37, Validation Loss: 87.66
2025-02-24 20:34:13,043 - Epoch 571, Training Loss: 78.09, Validation Loss: 87.61
2025-02-24 20:34:13,229 - Epoch 572, Training Loss: 70.77, Validation Loss: 87.61
2025-02-24 20:34:13,373 - Epoch 573, Training Loss: 73.96, Validation Loss: 87.60
2025-02-24 20:34:13,547 - Epoch 574, Training Loss: 81.40, Validation Loss: 87.56
2025-02-24 20:34:13,740 - Epoch 575, Training Loss: 81.96, Validation Loss: 87.56
2025-02-24 20:34:13,935 - Epoch 576, Training Loss: 102.56, Validation Loss: 87.51
2025-02-24 20:34:14,111 - Epoch 577, Training Loss: 74.03, Validation Loss: 87.47
2025-02-24 20:34:14,296 - Epoch 578, Training Loss: 79.26, Validation Loss: 87.43
2025-02-24 20:34:14,466 - Epoch 579, Training Loss: 77.01, Validation Loss: 87.40
2025-02-24 20:34:14,656 - Epoch 580, Training Loss: 75.52, Validation Loss: 87.42
2025-02-24 20:34:14,805 - Epoch 581, Training Loss: 71.95, Validation Loss: 87.41
2025-02-24 20:34:14,972 - Epoch 582, Training Loss: 76.63, Validation Loss: 87.38
2025-02-24 20:34:15,148 - Epoch 583, Training Loss: 80.59, Validation Loss: 87.34
2025-02-24 20:34:15,324 - Epoch 584, Training Loss: 92.02, Validation Loss: 87.27
2025-02-24 20:34:15,493 - Epoch 585, Training Loss: 78.93, Validation Loss: 87.25
2025-02-24 20:34:15,662 - Epoch 586, Training Loss: 86.72, Validation Loss: 87.19
2025-02-24 20:34:15,835 - Epoch 587, Training Loss: 81.64, Validation Loss: 87.14
2025-02-24 20:34:16,001 - Epoch 588, Training Loss: 79.70, Validation Loss: 87.11
2025-02-24 20:34:16,176 - Epoch 589, Training Loss: 70.41, Validation Loss: 87.10
2025-02-24 20:34:16,341 - Epoch 590, Training Loss: 82.80, Validation Loss: 87.11
2025-02-24 20:34:16,500 - Epoch 591, Training Loss: 77.42, Validation Loss: 87.06
2025-02-24 20:34:16,668 - Epoch 592, Training Loss: 82.72, Validation Loss: 87.01
2025-02-24 20:34:16,841 - Epoch 593, Training Loss: 80.07, Validation Loss: 86.97
2025-02-24 20:34:17,009 - Epoch 594, Training Loss: 86.16, Validation Loss: 86.93
2025-02-24 20:34:17,180 - Epoch 595, Training Loss: 71.54, Validation Loss: 86.95
2025-02-24 20:34:17,329 - Epoch 596, Training Loss: 78.17, Validation Loss: 86.93
2025-02-24 20:34:17,489 - Epoch 597, Training Loss: 72.08, Validation Loss: 86.94
2025-02-24 20:34:17,633 - Epoch 598, Training Loss: 72.76, Validation Loss: 86.95
2025-02-24 20:34:17,784 - Epoch 599, Training Loss: 78.68, Validation Loss: 86.91
2025-02-24 20:34:17,959 - Epoch 600, Training Loss: 74.38, Validation Loss: 86.89
2025-02-24 20:34:18,126 - Epoch 601, Training Loss: 78.44, Validation Loss: 86.86
2025-02-24 20:34:18,291 - Epoch 602, Training Loss: 90.66, Validation Loss: 86.81
2025-02-24 20:34:18,460 - Epoch 603, Training Loss: 84.24, Validation Loss: 86.77
2025-02-24 20:34:18,629 - Epoch 604, Training Loss: 74.65, Validation Loss: 86.77
2025-02-24 20:34:18,796 - Epoch 605, Training Loss: 71.71, Validation Loss: 86.79
2025-02-24 20:34:18,941 - Epoch 606, Training Loss: 74.59, Validation Loss: 86.81
2025-02-24 20:34:19,094 - Epoch 607, Training Loss: 87.99, Validation Loss: 86.78
2025-02-24 20:34:19,239 - Epoch 608, Training Loss: 85.37, Validation Loss: 86.74
2025-02-24 20:34:19,407 - Epoch 609, Training Loss: 75.38, Validation Loss: 86.71
2025-02-24 20:34:19,573 - Epoch 610, Training Loss: 83.53, Validation Loss: 86.65
2025-02-24 20:34:19,749 - Epoch 611, Training Loss: 77.35, Validation Loss: 86.63
2025-02-24 20:34:19,925 - Epoch 612, Training Loss: 86.07, Validation Loss: 86.56
2025-02-24 20:34:20,098 - Epoch 613, Training Loss: 78.81, Validation Loss: 86.53
2025-02-24 20:34:20,263 - Epoch 614, Training Loss: 82.45, Validation Loss: 86.49
2025-02-24 20:34:20,437 - Epoch 615, Training Loss: 76.11, Validation Loss: 86.48
2025-02-24 20:34:20,601 - Epoch 616, Training Loss: 86.42, Validation Loss: 86.44
2025-02-24 20:34:20,775 - Epoch 617, Training Loss: 93.50, Validation Loss: 86.38
2025-02-24 20:34:20,943 - Epoch 618, Training Loss: 95.49, Validation Loss: 86.32
2025-02-24 20:34:21,116 - Epoch 619, Training Loss: 71.07, Validation Loss: 86.34
2025-02-24 20:34:21,259 - Epoch 620, Training Loss: 93.88, Validation Loss: 86.31
2025-02-24 20:34:21,431 - Epoch 621, Training Loss: 81.00, Validation Loss: 86.31
2025-02-24 20:34:21,577 - Epoch 622, Training Loss: 72.37, Validation Loss: 86.35
2025-02-24 20:34:21,727 - Epoch 623, Training Loss: 72.29, Validation Loss: 86.36
2025-02-24 20:34:21,874 - Epoch 624, Training Loss: 83.85, Validation Loss: 86.32
2025-02-24 20:34:22,024 - Epoch 625, Training Loss: 82.59, Validation Loss: 86.30
2025-02-24 20:34:22,191 - Epoch 626, Training Loss: 73.96, Validation Loss: 86.28
2025-02-24 20:34:22,365 - Epoch 627, Training Loss: 75.21, Validation Loss: 86.26
2025-02-24 20:34:22,548 - Epoch 628, Training Loss: 84.16, Validation Loss: 86.24
2025-02-24 20:34:22,716 - Epoch 629, Training Loss: 72.64, Validation Loss: 86.23
2025-02-24 20:34:22,886 - Epoch 630, Training Loss: 88.48, Validation Loss: 86.15
2025-02-24 20:34:23,052 - Epoch 631, Training Loss: 80.87, Validation Loss: 86.15
2025-02-24 20:34:23,230 - Epoch 632, Training Loss: 82.53, Validation Loss: 86.09
2025-02-24 20:34:23,397 - Epoch 633, Training Loss: 71.90, Validation Loss: 86.13
2025-02-24 20:34:23,547 - Epoch 634, Training Loss: 82.90, Validation Loss: 86.13
2025-02-24 20:34:23,691 - Epoch 635, Training Loss: 77.00, Validation Loss: 86.09
2025-02-24 20:34:23,838 - Epoch 636, Training Loss: 79.75, Validation Loss: 86.05
2025-02-24 20:34:24,004 - Epoch 637, Training Loss: 74.88, Validation Loss: 86.00
2025-02-24 20:34:24,176 - Epoch 638, Training Loss: 87.91, Validation Loss: 85.94
2025-02-24 20:34:24,341 - Epoch 639, Training Loss: 77.54, Validation Loss: 85.93
2025-02-24 20:34:24,513 - Epoch 640, Training Loss: 89.96, Validation Loss: 85.91
2025-02-24 20:34:24,686 - Epoch 641, Training Loss: 85.30, Validation Loss: 85.90
2025-02-24 20:34:24,859 - Epoch 642, Training Loss: 105.72, Validation Loss: 85.84
2025-02-24 20:34:25,024 - Epoch 643, Training Loss: 87.67, Validation Loss: 85.82
2025-02-24 20:34:25,195 - Epoch 644, Training Loss: 71.56, Validation Loss: 85.85
2025-02-24 20:34:25,342 - Epoch 645, Training Loss: 93.96, Validation Loss: 85.80
2025-02-24 20:34:25,514 - Epoch 646, Training Loss: 90.92, Validation Loss: 85.73
2025-02-24 20:34:25,678 - Epoch 647, Training Loss: 85.00, Validation Loss: 85.70
2025-02-24 20:34:25,850 - Epoch 648, Training Loss: 88.22, Validation Loss: 85.65
2025-02-24 20:34:26,014 - Epoch 649, Training Loss: 73.35, Validation Loss: 85.66
2025-02-24 20:34:26,162 - Epoch 650, Training Loss: 76.02, Validation Loss: 85.61
2025-02-24 20:34:26,331 - Epoch 651, Training Loss: 72.91, Validation Loss: 85.62
2025-02-24 20:34:26,478 - Epoch 652, Training Loss: 72.96, Validation Loss: 85.62
2025-02-24 20:34:26,619 - Epoch 653, Training Loss: 81.82, Validation Loss: 85.58
2025-02-24 20:34:26,791 - Epoch 654, Training Loss: 72.28, Validation Loss: 85.56
2025-02-24 20:34:26,958 - Epoch 655, Training Loss: 83.97, Validation Loss: 85.53
2025-02-24 20:34:27,130 - Epoch 656, Training Loss: 85.75, Validation Loss: 85.48
2025-02-24 20:34:27,298 - Epoch 657, Training Loss: 74.51, Validation Loss: 85.45
2025-02-24 20:34:27,475 - Epoch 658, Training Loss: 74.33, Validation Loss: 85.46
2025-02-24 20:34:27,617 - Epoch 659, Training Loss: 90.79, Validation Loss: 85.41
2025-02-24 20:34:27,791 - Epoch 660, Training Loss: 73.30, Validation Loss: 85.43
2025-02-24 20:34:27,940 - Epoch 661, Training Loss: 81.42, Validation Loss: 85.39
2025-02-24 20:34:28,116 - Epoch 662, Training Loss: 70.35, Validation Loss: 85.40
2025-02-24 20:34:28,261 - Epoch 663, Training Loss: 88.35, Validation Loss: 85.31
2025-02-24 20:34:28,434 - Epoch 664, Training Loss: 89.45, Validation Loss: 85.27
2025-02-24 20:34:28,599 - Epoch 665, Training Loss: 97.44, Validation Loss: 85.21
2025-02-24 20:34:28,770 - Epoch 666, Training Loss: 87.49, Validation Loss: 85.16
2025-02-24 20:34:28,937 - Epoch 667, Training Loss: 90.28, Validation Loss: 85.11
2025-02-24 20:34:29,119 - Epoch 668, Training Loss: 95.38, Validation Loss: 85.04
2025-02-24 20:34:29,283 - Epoch 669, Training Loss: 79.15, Validation Loss: 85.00
2025-02-24 20:34:29,458 - Epoch 670, Training Loss: 70.51, Validation Loss: 84.99
2025-02-24 20:34:29,634 - Epoch 671, Training Loss: 81.97, Validation Loss: 84.98
2025-02-24 20:34:29,806 - Epoch 672, Training Loss: 76.39, Validation Loss: 84.93
2025-02-24 20:34:29,979 - Epoch 673, Training Loss: 88.71, Validation Loss: 84.85
2025-02-24 20:34:30,145 - Epoch 674, Training Loss: 74.91, Validation Loss: 84.85
2025-02-24 20:34:30,319 - Epoch 675, Training Loss: 89.22, Validation Loss: 84.83
2025-02-24 20:34:30,484 - Epoch 676, Training Loss: 82.32, Validation Loss: 84.83
2025-02-24 20:34:30,664 - Epoch 677, Training Loss: 75.11, Validation Loss: 84.84
2025-02-24 20:34:30,809 - Epoch 678, Training Loss: 73.62, Validation Loss: 84.82
2025-02-24 20:34:30,981 - Epoch 679, Training Loss: 73.25, Validation Loss: 84.82
2025-02-24 20:34:31,148 - Epoch 680, Training Loss: 71.45, Validation Loss: 84.83
2025-02-24 20:34:31,304 - Epoch 681, Training Loss: 77.63, Validation Loss: 84.78
2025-02-24 20:34:31,475 - Epoch 682, Training Loss: 82.53, Validation Loss: 84.73
2025-02-24 20:34:31,648 - Epoch 683, Training Loss: 74.65, Validation Loss: 84.70
2025-02-24 20:34:31,811 - Epoch 684, Training Loss: 73.58, Validation Loss: 84.70
2025-02-24 20:34:31,985 - Epoch 685, Training Loss: 81.48, Validation Loss: 84.68
2025-02-24 20:34:32,150 - Epoch 686, Training Loss: 83.43, Validation Loss: 84.63
2025-02-24 20:34:32,324 - Epoch 687, Training Loss: 85.02, Validation Loss: 84.62
2025-02-24 20:34:32,495 - Epoch 688, Training Loss: 75.88, Validation Loss: 84.60
2025-02-24 20:34:32,672 - Epoch 689, Training Loss: 74.64, Validation Loss: 84.57
2025-02-24 20:34:32,840 - Epoch 690, Training Loss: 72.32, Validation Loss: 84.59
2025-02-24 20:34:32,990 - Epoch 691, Training Loss: 76.98, Validation Loss: 84.55
2025-02-24 20:34:33,158 - Epoch 692, Training Loss: 87.34, Validation Loss: 84.51
2025-02-24 20:34:33,336 - Epoch 693, Training Loss: 84.65, Validation Loss: 84.48
2025-02-24 20:34:33,517 - Epoch 694, Training Loss: 72.01, Validation Loss: 84.50
2025-02-24 20:34:33,745 - Epoch 695, Training Loss: 68.94, Validation Loss: 84.50
2025-02-24 20:34:33,903 - Epoch 696, Training Loss: 74.66, Validation Loss: 84.50
2025-02-24 20:34:34,052 - Epoch 697, Training Loss: 74.01, Validation Loss: 84.51
2025-02-24 20:34:34,213 - Epoch 698, Training Loss: 74.68, Validation Loss: 84.48
2025-02-24 20:34:34,372 - Epoch 699, Training Loss: 75.44, Validation Loss: 84.45
2025-02-24 20:34:34,560 - Epoch 700, Training Loss: 72.83, Validation Loss: 84.45
2025-02-24 20:34:34,728 - Epoch 701, Training Loss: 83.82, Validation Loss: 84.44
2025-02-24 20:34:34,898 - Epoch 702, Training Loss: 79.45, Validation Loss: 84.42
2025-02-24 20:34:35,082 - Epoch 703, Training Loss: 89.33, Validation Loss: 84.34
2025-02-24 20:34:35,264 - Epoch 704, Training Loss: 82.46, Validation Loss: 84.32
2025-02-24 20:34:35,450 - Epoch 705, Training Loss: 82.68, Validation Loss: 84.29
2025-02-24 20:34:35,636 - Epoch 706, Training Loss: 71.74, Validation Loss: 84.30
2025-02-24 20:34:35,791 - Epoch 707, Training Loss: 74.19, Validation Loss: 84.29
2025-02-24 20:34:35,977 - Epoch 708, Training Loss: 78.45, Validation Loss: 84.25
2025-02-24 20:34:36,182 - Epoch 709, Training Loss: 70.65, Validation Loss: 84.22
2025-02-24 20:34:36,396 - Epoch 710, Training Loss: 83.35, Validation Loss: 84.17
2025-02-24 20:34:36,602 - Epoch 711, Training Loss: 85.60, Validation Loss: 84.13
2025-02-24 20:34:36,809 - Epoch 712, Training Loss: 93.72, Validation Loss: 84.06
2025-02-24 20:34:37,056 - Epoch 713, Training Loss: 81.79, Validation Loss: 84.05
2025-02-24 20:34:37,235 - Epoch 714, Training Loss: 81.45, Validation Loss: 83.99
2025-02-24 20:34:37,416 - Epoch 715, Training Loss: 98.28, Validation Loss: 83.92
2025-02-24 20:34:37,593 - Epoch 716, Training Loss: 90.76, Validation Loss: 83.86
2025-02-24 20:34:37,812 - Epoch 717, Training Loss: 77.92, Validation Loss: 83.84
2025-02-24 20:34:37,987 - Epoch 718, Training Loss: 74.01, Validation Loss: 83.82
2025-02-24 20:34:38,175 - Epoch 719, Training Loss: 84.80, Validation Loss: 83.78
2025-02-24 20:34:38,360 - Epoch 720, Training Loss: 74.16, Validation Loss: 83.76
2025-02-24 20:34:38,552 - Epoch 721, Training Loss: 74.30, Validation Loss: 83.74
2025-02-24 20:34:38,728 - Epoch 722, Training Loss: 73.70, Validation Loss: 83.76
2025-02-24 20:34:38,890 - Epoch 723, Training Loss: 78.69, Validation Loss: 83.76
2025-02-24 20:34:39,046 - Epoch 724, Training Loss: 84.71, Validation Loss: 83.71
2025-02-24 20:34:39,217 - Epoch 725, Training Loss: 79.72, Validation Loss: 83.69
2025-02-24 20:34:39,389 - Epoch 726, Training Loss: 70.55, Validation Loss: 83.68
2025-02-24 20:34:39,555 - Epoch 727, Training Loss: 80.83, Validation Loss: 83.66
2025-02-24 20:34:39,738 - Epoch 728, Training Loss: 82.02, Validation Loss: 83.66
2025-02-24 20:34:39,901 - Epoch 729, Training Loss: 74.73, Validation Loss: 83.66
2025-02-24 20:34:40,071 - Epoch 730, Training Loss: 78.44, Validation Loss: 83.62
2025-02-24 20:34:40,238 - Epoch 731, Training Loss: 77.95, Validation Loss: 83.63
2025-02-24 20:34:40,388 - Epoch 732, Training Loss: 78.94, Validation Loss: 83.58
2025-02-24 20:34:40,560 - Epoch 733, Training Loss: 71.29, Validation Loss: 83.55
2025-02-24 20:34:40,736 - Epoch 734, Training Loss: 94.30, Validation Loss: 83.48
2025-02-24 20:34:40,904 - Epoch 735, Training Loss: 85.00, Validation Loss: 83.43
2025-02-24 20:34:41,079 - Epoch 736, Training Loss: 83.98, Validation Loss: 83.39
2025-02-24 20:34:41,264 - Epoch 737, Training Loss: 89.68, Validation Loss: 83.35
2025-02-24 20:34:41,442 - Epoch 738, Training Loss: 74.64, Validation Loss: 83.33
2025-02-24 20:34:41,620 - Epoch 739, Training Loss: 72.48, Validation Loss: 83.33
2025-02-24 20:34:41,789 - Epoch 740, Training Loss: 75.46, Validation Loss: 83.34
2025-02-24 20:34:41,947 - Epoch 741, Training Loss: 71.34, Validation Loss: 83.35
2025-02-24 20:34:42,109 - Epoch 742, Training Loss: 72.95, Validation Loss: 83.34
2025-02-24 20:34:42,289 - Epoch 743, Training Loss: 74.58, Validation Loss: 83.32
2025-02-24 20:34:42,504 - Epoch 744, Training Loss: 73.99, Validation Loss: 83.28
2025-02-24 20:34:42,672 - Epoch 745, Training Loss: 89.12, Validation Loss: 83.21
2025-02-24 20:34:42,853 - Epoch 746, Training Loss: 77.18, Validation Loss: 83.21
2025-02-24 20:34:43,029 - Epoch 747, Training Loss: 82.21, Validation Loss: 83.18
2025-02-24 20:34:43,201 - Epoch 748, Training Loss: 73.48, Validation Loss: 83.18
2025-02-24 20:34:43,374 - Epoch 749, Training Loss: 81.64, Validation Loss: 83.16
2025-02-24 20:34:43,572 - Epoch 750, Training Loss: 75.21, Validation Loss: 83.12
2025-02-24 20:34:43,741 - Epoch 751, Training Loss: 70.22, Validation Loss: 83.13
2025-02-24 20:34:43,894 - Epoch 752, Training Loss: 80.53, Validation Loss: 83.12
2025-02-24 20:34:44,065 - Epoch 753, Training Loss: 72.78, Validation Loss: 83.15
2025-02-24 20:34:44,228 - Epoch 754, Training Loss: 72.12, Validation Loss: 83.15
2025-02-24 20:34:44,378 - Epoch 755, Training Loss: 82.75, Validation Loss: 83.13
2025-02-24 20:34:44,546 - Epoch 756, Training Loss: 78.02, Validation Loss: 83.13
2025-02-24 20:34:44,697 - Epoch 757, Training Loss: 87.71, Validation Loss: 83.08
2025-02-24 20:34:44,870 - Epoch 758, Training Loss: 72.92, Validation Loss: 83.09
2025-02-24 20:34:45,018 - Epoch 759, Training Loss: 82.50, Validation Loss: 83.06
2025-02-24 20:34:45,195 - Epoch 760, Training Loss: 74.82, Validation Loss: 83.09
2025-02-24 20:34:45,345 - Epoch 761, Training Loss: 75.27, Validation Loss: 83.07
2025-02-24 20:34:45,498 - Epoch 762, Training Loss: 83.32, Validation Loss: 83.00
2025-02-24 20:34:45,672 - Epoch 763, Training Loss: 81.92, Validation Loss: 82.96
2025-02-24 20:34:45,848 - Epoch 764, Training Loss: 74.56, Validation Loss: 82.94
2025-02-24 20:34:46,024 - Epoch 765, Training Loss: 69.93, Validation Loss: 82.95
2025-02-24 20:34:46,178 - Epoch 766, Training Loss: 83.24, Validation Loss: 82.93
2025-02-24 20:34:46,352 - Epoch 767, Training Loss: 75.77, Validation Loss: 82.89
2025-02-24 20:34:46,547 - Epoch 768, Training Loss: 93.04, Validation Loss: 82.83
2025-02-24 20:34:46,735 - Epoch 769, Training Loss: 71.85, Validation Loss: 82.86
2025-02-24 20:34:46,904 - Epoch 770, Training Loss: 72.43, Validation Loss: 82.86
2025-02-24 20:34:47,068 - Epoch 771, Training Loss: 87.09, Validation Loss: 82.82
2025-02-24 20:34:47,258 - Epoch 772, Training Loss: 73.05, Validation Loss: 82.80
2025-02-24 20:34:47,448 - Epoch 773, Training Loss: 73.64, Validation Loss: 82.80
2025-02-24 20:34:47,613 - Epoch 774, Training Loss: 78.37, Validation Loss: 82.80
2025-02-24 20:34:47,777 - Epoch 775, Training Loss: 73.86, Validation Loss: 82.78
2025-02-24 20:34:47,968 - Epoch 776, Training Loss: 84.31, Validation Loss: 82.73
2025-02-24 20:34:48,147 - Epoch 777, Training Loss: 73.15, Validation Loss: 82.77
2025-02-24 20:34:48,304 - Epoch 778, Training Loss: 90.65, Validation Loss: 82.73
2025-02-24 20:34:48,466 - Epoch 779, Training Loss: 75.03, Validation Loss: 82.72
2025-02-24 20:34:48,668 - Epoch 780, Training Loss: 70.84, Validation Loss: 82.72
2025-02-24 20:34:48,858 - Epoch 781, Training Loss: 68.33, Validation Loss: 82.72
2025-02-24 20:34:49,048 - Epoch 782, Training Loss: 73.69, Validation Loss: 82.72
2025-02-24 20:34:49,211 - Epoch 783, Training Loss: 72.73, Validation Loss: 82.74
2025-02-24 20:34:49,375 - Epoch 784, Training Loss: 82.16, Validation Loss: 82.69
2025-02-24 20:34:49,563 - Epoch 785, Training Loss: 82.77, Validation Loss: 82.70
2025-02-24 20:34:49,732 - Epoch 786, Training Loss: 72.22, Validation Loss: 82.70
2025-02-24 20:34:49,895 - Epoch 787, Training Loss: 70.29, Validation Loss: 82.70
2025-02-24 20:34:50,049 - Epoch 788, Training Loss: 81.87, Validation Loss: 82.67
2025-02-24 20:34:50,245 - Epoch 789, Training Loss: 71.75, Validation Loss: 82.67
2025-02-24 20:34:50,444 - Epoch 790, Training Loss: 76.99, Validation Loss: 82.63
2025-02-24 20:34:50,633 - Epoch 791, Training Loss: 82.08, Validation Loss: 82.63
2025-02-24 20:34:50,785 - Epoch 792, Training Loss: 77.46, Validation Loss: 82.60
2025-02-24 20:34:50,974 - Epoch 793, Training Loss: 70.22, Validation Loss: 82.61
2025-02-24 20:34:51,140 - Epoch 794, Training Loss: 89.15, Validation Loss: 82.56
2025-02-24 20:34:51,324 - Epoch 795, Training Loss: 74.23, Validation Loss: 82.52
2025-02-24 20:34:51,508 - Epoch 796, Training Loss: 82.69, Validation Loss: 82.49
2025-02-24 20:34:51,690 - Epoch 797, Training Loss: 74.35, Validation Loss: 82.49
2025-02-24 20:34:51,867 - Epoch 798, Training Loss: 75.22, Validation Loss: 82.48
2025-02-24 20:34:52,053 - Epoch 799, Training Loss: 70.18, Validation Loss: 82.48
2025-02-24 20:34:52,222 - Epoch 800, Training Loss: 82.87, Validation Loss: 82.45
2025-02-24 20:34:52,399 - Epoch 801, Training Loss: 82.78, Validation Loss: 82.41
2025-02-24 20:34:52,580 - Epoch 802, Training Loss: 71.51, Validation Loss: 82.40
2025-02-24 20:34:52,769 - Epoch 803, Training Loss: 69.34, Validation Loss: 82.37
2025-02-24 20:34:52,956 - Epoch 804, Training Loss: 76.67, Validation Loss: 82.34
2025-02-24 20:34:53,136 - Epoch 805, Training Loss: 89.65, Validation Loss: 82.30
2025-02-24 20:34:53,321 - Epoch 806, Training Loss: 69.87, Validation Loss: 82.30
2025-02-24 20:34:53,501 - Epoch 807, Training Loss: 71.17, Validation Loss: 82.30
2025-02-24 20:34:53,668 - Epoch 808, Training Loss: 75.98, Validation Loss: 82.27
2025-02-24 20:34:53,841 - Epoch 809, Training Loss: 72.36, Validation Loss: 82.26
2025-02-24 20:34:54,058 - Epoch 810, Training Loss: 69.77, Validation Loss: 82.28
2025-02-24 20:34:54,212 - Epoch 811, Training Loss: 74.22, Validation Loss: 82.24
2025-02-24 20:34:54,398 - Epoch 812, Training Loss: 81.44, Validation Loss: 82.20
2025-02-24 20:34:54,585 - Epoch 813, Training Loss: 88.88, Validation Loss: 82.16
2025-02-24 20:34:54,800 - Epoch 814, Training Loss: 79.55, Validation Loss: 82.12
2025-02-24 20:34:54,972 - Epoch 815, Training Loss: 81.76, Validation Loss: 82.14
2025-02-24 20:34:55,133 - Epoch 816, Training Loss: 74.95, Validation Loss: 82.14
2025-02-24 20:34:55,281 - Epoch 817, Training Loss: 75.16, Validation Loss: 82.13
2025-02-24 20:34:55,445 - Epoch 818, Training Loss: 82.48, Validation Loss: 82.11
2025-02-24 20:34:55,627 - Epoch 819, Training Loss: 83.84, Validation Loss: 82.05
2025-02-24 20:34:55,826 - Epoch 820, Training Loss: 89.01, Validation Loss: 82.00
2025-02-24 20:34:56,009 - Epoch 821, Training Loss: 76.67, Validation Loss: 81.94
2025-02-24 20:34:56,193 - Epoch 822, Training Loss: 73.50, Validation Loss: 81.92
2025-02-24 20:34:56,378 - Epoch 823, Training Loss: 78.41, Validation Loss: 81.89
2025-02-24 20:34:56,567 - Epoch 824, Training Loss: 70.68, Validation Loss: 81.91
2025-02-24 20:34:56,728 - Epoch 825, Training Loss: 78.00, Validation Loss: 81.89
2025-02-24 20:34:56,890 - Epoch 826, Training Loss: 72.25, Validation Loss: 81.90
2025-02-24 20:34:57,045 - Epoch 827, Training Loss: 84.17, Validation Loss: 81.84
2025-02-24 20:34:57,231 - Epoch 828, Training Loss: 84.43, Validation Loss: 81.83
2025-02-24 20:34:57,417 - Epoch 829, Training Loss: 77.64, Validation Loss: 81.80
2025-02-24 20:34:57,602 - Epoch 830, Training Loss: 76.90, Validation Loss: 81.81
2025-02-24 20:34:57,757 - Epoch 831, Training Loss: 71.96, Validation Loss: 81.81
2025-02-24 20:34:57,925 - Epoch 832, Training Loss: 75.82, Validation Loss: 81.79
2025-02-24 20:34:58,098 - Epoch 833, Training Loss: 69.94, Validation Loss: 81.79
2025-02-24 20:34:58,270 - Epoch 834, Training Loss: 69.79, Validation Loss: 81.78
2025-02-24 20:34:58,457 - Epoch 835, Training Loss: 86.69, Validation Loss: 81.74
2025-02-24 20:34:58,643 - Epoch 836, Training Loss: 74.12, Validation Loss: 81.76
2025-02-24 20:34:58,805 - Epoch 837, Training Loss: 82.93, Validation Loss: 81.72
2025-02-24 20:34:58,987 - Epoch 838, Training Loss: 73.49, Validation Loss: 81.70
2025-02-24 20:34:59,175 - Epoch 839, Training Loss: 77.44, Validation Loss: 81.69
2025-02-24 20:34:59,362 - Epoch 840, Training Loss: 75.84, Validation Loss: 81.64
2025-02-24 20:34:59,554 - Epoch 841, Training Loss: 69.03, Validation Loss: 81.66
2025-02-24 20:34:59,717 - Epoch 842, Training Loss: 75.15, Validation Loss: 81.64
2025-02-24 20:34:59,891 - Epoch 843, Training Loss: 81.71, Validation Loss: 81.58
2025-02-24 20:35:00,067 - Epoch 844, Training Loss: 77.22, Validation Loss: 81.57
2025-02-24 20:35:00,233 - Epoch 845, Training Loss: 82.73, Validation Loss: 81.51
2025-02-24 20:35:00,417 - Epoch 846, Training Loss: 73.84, Validation Loss: 81.53
2025-02-24 20:35:00,577 - Epoch 847, Training Loss: 84.11, Validation Loss: 81.49
2025-02-24 20:35:00,778 - Epoch 848, Training Loss: 84.24, Validation Loss: 81.44
2025-02-24 20:35:01,041 - Epoch 849, Training Loss: 70.80, Validation Loss: 81.48
2025-02-24 20:35:01,208 - Epoch 850, Training Loss: 74.21, Validation Loss: 81.49
2025-02-24 20:35:01,365 - Epoch 851, Training Loss: 82.97, Validation Loss: 81.48
2025-02-24 20:35:01,521 - Epoch 852, Training Loss: 93.18, Validation Loss: 81.43
2025-02-24 20:35:01,721 - Epoch 853, Training Loss: 79.75, Validation Loss: 81.39
2025-02-24 20:35:01,906 - Epoch 854, Training Loss: 81.86, Validation Loss: 81.37
2025-02-24 20:35:02,092 - Epoch 855, Training Loss: 74.25, Validation Loss: 81.34
2025-02-24 20:35:02,282 - Epoch 856, Training Loss: 79.36, Validation Loss: 81.32
2025-02-24 20:35:02,454 - Epoch 857, Training Loss: 79.21, Validation Loss: 81.33
2025-02-24 20:35:02,613 - Epoch 858, Training Loss: 75.05, Validation Loss: 81.30
2025-02-24 20:35:02,781 - Epoch 859, Training Loss: 82.60, Validation Loss: 81.27
2025-02-24 20:35:02,974 - Epoch 860, Training Loss: 75.56, Validation Loss: 81.26
2025-02-24 20:35:03,152 - Epoch 861, Training Loss: 74.48, Validation Loss: 81.22
2025-02-24 20:35:03,334 - Epoch 862, Training Loss: 84.63, Validation Loss: 81.17
2025-02-24 20:35:03,517 - Epoch 863, Training Loss: 75.65, Validation Loss: 81.16
2025-02-24 20:35:03,699 - Epoch 864, Training Loss: 72.50, Validation Loss: 81.16
2025-02-24 20:35:03,886 - Epoch 865, Training Loss: 99.48, Validation Loss: 81.10
2025-02-24 20:35:04,065 - Epoch 866, Training Loss: 78.03, Validation Loss: 81.05
2025-02-24 20:35:04,236 - Epoch 867, Training Loss: 77.82, Validation Loss: 81.05
2025-02-24 20:35:04,415 - Epoch 868, Training Loss: 74.90, Validation Loss: 81.04
2025-02-24 20:35:04,586 - Epoch 869, Training Loss: 71.27, Validation Loss: 81.07
2025-02-24 20:35:04,744 - Epoch 870, Training Loss: 72.39, Validation Loss: 81.07
2025-02-24 20:35:04,893 - Epoch 871, Training Loss: 91.65, Validation Loss: 81.04
2025-02-24 20:35:05,069 - Epoch 872, Training Loss: 75.06, Validation Loss: 81.04
2025-02-24 20:35:05,219 - Epoch 873, Training Loss: 72.70, Validation Loss: 81.04
2025-02-24 20:35:05,374 - Epoch 874, Training Loss: 87.08, Validation Loss: 81.01
2025-02-24 20:35:05,548 - Epoch 875, Training Loss: 71.54, Validation Loss: 81.00
2025-02-24 20:35:05,726 - Epoch 876, Training Loss: 84.59, Validation Loss: 80.97
2025-02-24 20:35:05,906 - Epoch 877, Training Loss: 67.61, Validation Loss: 80.98
2025-02-24 20:35:06,063 - Epoch 878, Training Loss: 77.99, Validation Loss: 80.97
2025-02-24 20:35:06,240 - Epoch 879, Training Loss: 73.05, Validation Loss: 80.98
2025-02-24 20:35:06,389 - Epoch 880, Training Loss: 81.71, Validation Loss: 80.97
2025-02-24 20:35:06,535 - Epoch 881, Training Loss: 81.46, Validation Loss: 80.95
2025-02-24 20:35:06,708 - Epoch 882, Training Loss: 91.36, Validation Loss: 80.89
2025-02-24 20:35:06,876 - Epoch 883, Training Loss: 85.11, Validation Loss: 80.87
2025-02-24 20:35:07,049 - Epoch 884, Training Loss: 84.89, Validation Loss: 80.85
2025-02-24 20:35:07,225 - Epoch 885, Training Loss: 72.74, Validation Loss: 80.83
2025-02-24 20:35:07,399 - Epoch 886, Training Loss: 70.85, Validation Loss: 80.84
2025-02-24 20:35:07,547 - Epoch 887, Training Loss: 81.16, Validation Loss: 80.81
2025-02-24 20:35:07,734 - Epoch 888, Training Loss: 80.82, Validation Loss: 80.80
2025-02-24 20:35:07,949 - Epoch 889, Training Loss: 74.74, Validation Loss: 80.77
2025-02-24 20:35:08,132 - Epoch 890, Training Loss: 75.29, Validation Loss: 80.73
2025-02-24 20:35:08,311 - Epoch 891, Training Loss: 79.63, Validation Loss: 80.72
2025-02-24 20:35:08,492 - Epoch 892, Training Loss: 84.67, Validation Loss: 80.67
2025-02-24 20:35:08,666 - Epoch 893, Training Loss: 82.11, Validation Loss: 80.66
2025-02-24 20:35:08,839 - Epoch 894, Training Loss: 74.70, Validation Loss: 80.66
2025-02-24 20:35:08,987 - Epoch 895, Training Loss: 84.10, Validation Loss: 80.61
2025-02-24 20:35:09,174 - Epoch 896, Training Loss: 91.23, Validation Loss: 80.59
2025-02-24 20:35:09,359 - Epoch 897, Training Loss: 94.01, Validation Loss: 80.54
2025-02-24 20:35:09,538 - Epoch 898, Training Loss: 71.51, Validation Loss: 80.52
2025-02-24 20:35:09,714 - Epoch 899, Training Loss: 72.96, Validation Loss: 80.50
2025-02-24 20:35:09,895 - Epoch 900, Training Loss: 75.34, Validation Loss: 80.52
2025-02-24 20:35:10,063 - Epoch 901, Training Loss: 75.92, Validation Loss: 80.49
2025-02-24 20:35:10,239 - Epoch 902, Training Loss: 79.74, Validation Loss: 80.46
2025-02-24 20:35:10,428 - Epoch 903, Training Loss: 81.97, Validation Loss: 80.47
2025-02-24 20:35:10,584 - Epoch 904, Training Loss: 80.83, Validation Loss: 80.46
2025-02-24 20:35:10,767 - Epoch 905, Training Loss: 74.88, Validation Loss: 80.42
2025-02-24 20:35:10,936 - Epoch 906, Training Loss: 69.99, Validation Loss: 80.43
2025-02-24 20:35:11,083 - Epoch 907, Training Loss: 72.57, Validation Loss: 80.40
2025-02-24 20:35:11,258 - Epoch 908, Training Loss: 72.23, Validation Loss: 80.40
2025-02-24 20:35:11,417 - Epoch 909, Training Loss: 72.32, Validation Loss: 80.39
2025-02-24 20:35:11,586 - Epoch 910, Training Loss: 79.34, Validation Loss: 80.38
2025-02-24 20:35:11,760 - Epoch 911, Training Loss: 84.61, Validation Loss: 80.35
2025-02-24 20:35:11,926 - Epoch 912, Training Loss: 82.85, Validation Loss: 80.30
2025-02-24 20:35:12,106 - Epoch 913, Training Loss: 73.37, Validation Loss: 80.28
2025-02-24 20:35:12,280 - Epoch 914, Training Loss: 77.01, Validation Loss: 80.24
2025-02-24 20:35:12,461 - Epoch 915, Training Loss: 79.90, Validation Loss: 80.23
2025-02-24 20:35:12,633 - Epoch 916, Training Loss: 101.20, Validation Loss: 80.17
2025-02-24 20:35:12,808 - Epoch 917, Training Loss: 72.71, Validation Loss: 80.19
2025-02-24 20:35:12,956 - Epoch 918, Training Loss: 80.39, Validation Loss: 80.19
2025-02-24 20:35:13,106 - Epoch 919, Training Loss: 68.69, Validation Loss: 80.20
2025-02-24 20:35:13,252 - Epoch 920, Training Loss: 71.81, Validation Loss: 80.18
2025-02-24 20:35:13,399 - Epoch 921, Training Loss: 81.57, Validation Loss: 80.15
2025-02-24 20:35:13,575 - Epoch 922, Training Loss: 72.14, Validation Loss: 80.17
2025-02-24 20:35:13,735 - Epoch 923, Training Loss: 67.25, Validation Loss: 80.18
2025-02-24 20:35:13,878 - Epoch 924, Training Loss: 73.25, Validation Loss: 80.19
2025-02-24 20:35:14,027 - Epoch 925, Training Loss: 85.11, Validation Loss: 80.16
2025-02-24 20:35:14,178 - Epoch 926, Training Loss: 82.28, Validation Loss: 80.12
2025-02-24 20:35:14,348 - Epoch 927, Training Loss: 79.90, Validation Loss: 80.10
2025-02-24 20:35:14,518 - Epoch 928, Training Loss: 78.78, Validation Loss: 80.06
2025-02-24 20:35:14,694 - Epoch 929, Training Loss: 78.85, Validation Loss: 80.03
2025-02-24 20:35:14,861 - Epoch 930, Training Loss: 76.00, Validation Loss: 80.01
2025-02-24 20:35:15,034 - Epoch 931, Training Loss: 70.62, Validation Loss: 80.00
2025-02-24 20:35:15,204 - Epoch 932, Training Loss: 73.53, Validation Loss: 79.99
2025-02-24 20:35:15,378 - Epoch 933, Training Loss: 75.17, Validation Loss: 79.97
2025-02-24 20:35:15,544 - Epoch 934, Training Loss: 73.13, Validation Loss: 79.97
2025-02-24 20:35:15,720 - Epoch 935, Training Loss: 91.59, Validation Loss: 79.91
2025-02-24 20:35:15,887 - Epoch 936, Training Loss: 74.06, Validation Loss: 79.89
2025-02-24 20:35:16,061 - Epoch 937, Training Loss: 72.81, Validation Loss: 79.85
2025-02-24 20:35:16,230 - Epoch 938, Training Loss: 80.43, Validation Loss: 79.80
2025-02-24 20:35:16,406 - Epoch 939, Training Loss: 70.90, Validation Loss: 79.81
2025-02-24 20:35:16,550 - Epoch 940, Training Loss: 72.12, Validation Loss: 79.82
2025-02-24 20:35:16,699 - Epoch 941, Training Loss: 72.35, Validation Loss: 79.82
2025-02-24 20:35:16,845 - Epoch 942, Training Loss: 78.22, Validation Loss: 79.81
2025-02-24 20:35:16,995 - Epoch 943, Training Loss: 86.45, Validation Loss: 79.77
2025-02-24 20:35:17,166 - Epoch 944, Training Loss: 77.40, Validation Loss: 79.76
2025-02-24 20:35:17,341 - Epoch 945, Training Loss: 82.46, Validation Loss: 79.72
2025-02-24 20:35:17,504 - Epoch 946, Training Loss: 79.50, Validation Loss: 79.69
2025-02-24 20:35:17,681 - Epoch 947, Training Loss: 77.03, Validation Loss: 79.66
2025-02-24 20:35:17,854 - Epoch 948, Training Loss: 71.83, Validation Loss: 79.68
2025-02-24 20:35:18,008 - Epoch 949, Training Loss: 74.23, Validation Loss: 79.66
2025-02-24 20:35:18,176 - Epoch 950, Training Loss: 80.02, Validation Loss: 79.61
2025-02-24 20:35:18,359 - Epoch 951, Training Loss: 82.21, Validation Loss: 79.60
2025-02-24 20:35:18,535 - Epoch 952, Training Loss: 80.41, Validation Loss: 79.58
2025-02-24 20:35:18,724 - Epoch 953, Training Loss: 71.46, Validation Loss: 79.57
2025-02-24 20:35:18,893 - Epoch 954, Training Loss: 89.12, Validation Loss: 79.52
2025-02-24 20:35:19,067 - Epoch 955, Training Loss: 77.28, Validation Loss: 79.51
2025-02-24 20:35:19,235 - Epoch 956, Training Loss: 85.62, Validation Loss: 79.48
2025-02-24 20:35:19,406 - Epoch 957, Training Loss: 78.84, Validation Loss: 79.45
2025-02-24 20:35:19,571 - Epoch 958, Training Loss: 78.46, Validation Loss: 79.45
2025-02-24 20:35:19,723 - Epoch 959, Training Loss: 72.56, Validation Loss: 79.43
2025-02-24 20:35:19,892 - Epoch 960, Training Loss: 75.84, Validation Loss: 79.43
2025-02-24 20:35:20,065 - Epoch 961, Training Loss: 77.50, Validation Loss: 79.41
2025-02-24 20:35:20,229 - Epoch 962, Training Loss: 72.27, Validation Loss: 79.40
2025-02-24 20:35:20,407 - Epoch 963, Training Loss: 80.88, Validation Loss: 79.38
2025-02-24 20:35:20,581 - Epoch 964, Training Loss: 67.22, Validation Loss: 79.39
2025-02-24 20:35:20,737 - Epoch 965, Training Loss: 73.84, Validation Loss: 79.38
2025-02-24 20:35:20,891 - Epoch 966, Training Loss: 68.49, Validation Loss: 79.36
2025-02-24 20:35:21,068 - Epoch 967, Training Loss: 71.99, Validation Loss: 79.35
2025-02-24 20:35:21,336 - Epoch 968, Training Loss: 70.87, Validation Loss: 79.38
2025-02-24 20:35:21,494 - Epoch 969, Training Loss: 92.08, Validation Loss: 79.34
2025-02-24 20:35:21,682 - Epoch 970, Training Loss: 79.13, Validation Loss: 79.32
2025-02-24 20:35:21,860 - Epoch 971, Training Loss: 74.49, Validation Loss: 79.28
2025-02-24 20:35:22,052 - Epoch 972, Training Loss: 89.19, Validation Loss: 79.23
2025-02-24 20:35:22,238 - Epoch 973, Training Loss: 72.53, Validation Loss: 79.27
2025-02-24 20:35:22,395 - Epoch 974, Training Loss: 82.17, Validation Loss: 79.22
2025-02-24 20:35:22,570 - Epoch 975, Training Loss: 82.19, Validation Loss: 79.22
2025-02-24 20:35:22,763 - Epoch 976, Training Loss: 75.66, Validation Loss: 79.19
2025-02-24 20:35:22,948 - Epoch 977, Training Loss: 78.76, Validation Loss: 79.18
2025-02-24 20:35:23,130 - Epoch 978, Training Loss: 71.83, Validation Loss: 79.18
2025-02-24 20:35:23,286 - Epoch 979, Training Loss: 87.03, Validation Loss: 79.14
2025-02-24 20:35:23,460 - Epoch 980, Training Loss: 72.31, Validation Loss: 79.11
2025-02-24 20:35:23,637 - Epoch 981, Training Loss: 81.69, Validation Loss: 79.08
2025-02-24 20:35:23,803 - Epoch 982, Training Loss: 70.75, Validation Loss: 79.07
2025-02-24 20:35:23,984 - Epoch 983, Training Loss: 72.34, Validation Loss: 79.05
2025-02-24 20:35:24,149 - Epoch 984, Training Loss: 78.76, Validation Loss: 79.03
2025-02-24 20:35:24,328 - Epoch 985, Training Loss: 72.33, Validation Loss: 79.06
2025-02-24 20:35:24,472 - Epoch 986, Training Loss: 67.11, Validation Loss: 79.09
2025-02-24 20:35:24,618 - Epoch 987, Training Loss: 72.25, Validation Loss: 79.10
2025-02-24 20:35:24,764 - Epoch 988, Training Loss: 83.36, Validation Loss: 79.11
2025-02-24 20:35:24,910 - Epoch 989, Training Loss: 72.61, Validation Loss: 79.16
2025-02-24 20:35:25,063 - Epoch 990, Training Loss: 76.37, Validation Loss: 79.11
2025-02-24 20:35:25,216 - Epoch 991, Training Loss: 83.11, Validation Loss: 79.07
2025-02-24 20:35:25,360 - Epoch 992, Training Loss: 72.78, Validation Loss: 79.06
2025-02-24 20:35:25,512 - Epoch 993, Training Loss: 73.63, Validation Loss: 79.04
2025-02-24 20:35:25,659 - Epoch 994, Training Loss: 73.64, Validation Loss: 79.04
2025-02-24 20:35:25,807 - Epoch 995, Training Loss: 86.64, Validation Loss: 79.00
2025-02-24 20:35:25,974 - Epoch 996, Training Loss: 72.47, Validation Loss: 79.00
2025-02-24 20:35:26,124 - Epoch 997, Training Loss: 75.53, Validation Loss: 78.99
2025-02-24 20:35:26,305 - Epoch 998, Training Loss: 93.84, Validation Loss: 78.94
2025-02-24 20:35:26,478 - Epoch 999, Training Loss: 77.82, Validation Loss: 78.93
2025-02-24 20:35:26,645 - Epoch 1000, Training Loss: 70.01, Validation Loss: 78.95
2025-02-24 20:35:26,789 - Epoch 1001, Training Loss: 73.20, Validation Loss: 78.94
2025-02-24 20:35:26,938 - Epoch 1002, Training Loss: 91.04, Validation Loss: 78.90
2025-02-24 20:35:27,104 - Epoch 1003, Training Loss: 69.38, Validation Loss: 78.88
2025-02-24 20:35:27,281 - Epoch 1004, Training Loss: 80.09, Validation Loss: 78.85
2025-02-24 20:35:27,448 - Epoch 1005, Training Loss: 90.40, Validation Loss: 78.80
2025-02-24 20:35:27,624 - Epoch 1006, Training Loss: 69.70, Validation Loss: 78.82
2025-02-24 20:35:27,772 - Epoch 1007, Training Loss: 83.90, Validation Loss: 78.78
2025-02-24 20:35:27,948 - Epoch 1008, Training Loss: 73.57, Validation Loss: 78.78
2025-02-24 20:35:28,116 - Epoch 1009, Training Loss: 89.45, Validation Loss: 78.75
2025-02-24 20:35:28,294 - Epoch 1010, Training Loss: 70.41, Validation Loss: 78.76
2025-02-24 20:35:28,444 - Epoch 1011, Training Loss: 69.97, Validation Loss: 78.76
2025-02-24 20:35:28,590 - Epoch 1012, Training Loss: 81.62, Validation Loss: 78.74
2025-02-24 20:35:28,756 - Epoch 1013, Training Loss: 82.23, Validation Loss: 78.73
2025-02-24 20:35:28,934 - Epoch 1014, Training Loss: 89.75, Validation Loss: 78.70
2025-02-24 20:35:29,100 - Epoch 1015, Training Loss: 71.05, Validation Loss: 78.69
2025-02-24 20:35:29,278 - Epoch 1016, Training Loss: 78.62, Validation Loss: 78.68
2025-02-24 20:35:29,445 - Epoch 1017, Training Loss: 83.61, Validation Loss: 78.66
2025-02-24 20:35:29,623 - Epoch 1018, Training Loss: 73.45, Validation Loss: 78.67
2025-02-24 20:35:29,776 - Epoch 1019, Training Loss: 79.32, Validation Loss: 78.65
2025-02-24 20:35:29,949 - Epoch 1020, Training Loss: 86.57, Validation Loss: 78.61
2025-02-24 20:35:30,116 - Epoch 1021, Training Loss: 70.09, Validation Loss: 78.63
2025-02-24 20:35:30,269 - Epoch 1022, Training Loss: 71.57, Validation Loss: 78.62
2025-02-24 20:35:30,415 - Epoch 1023, Training Loss: 68.33, Validation Loss: 78.62
2025-02-24 20:35:30,563 - Epoch 1024, Training Loss: 83.20, Validation Loss: 78.59
2025-02-24 20:35:30,732 - Epoch 1025, Training Loss: 65.61, Validation Loss: 78.59
2025-02-24 20:35:30,908 - Epoch 1026, Training Loss: 75.66, Validation Loss: 78.59
2025-02-24 20:35:31,068 - Epoch 1027, Training Loss: 82.98, Validation Loss: 78.57
2025-02-24 20:35:31,240 - Epoch 1028, Training Loss: 69.82, Validation Loss: 78.59
2025-02-24 20:35:31,400 - Epoch 1029, Training Loss: 70.26, Validation Loss: 78.60
2025-02-24 20:35:31,549 - Epoch 1030, Training Loss: 72.23, Validation Loss: 78.62
2025-02-24 20:35:31,694 - Epoch 1031, Training Loss: 95.62, Validation Loss: 78.56
2025-02-24 20:35:31,883 - Epoch 1032, Training Loss: 76.31, Validation Loss: 78.52
2025-02-24 20:35:32,062 - Epoch 1033, Training Loss: 86.44, Validation Loss: 78.47
2025-02-24 20:35:32,250 - Epoch 1034, Training Loss: 79.83, Validation Loss: 78.45
2025-02-24 20:35:32,436 - Epoch 1035, Training Loss: 76.28, Validation Loss: 78.43
2025-02-24 20:35:32,616 - Epoch 1036, Training Loss: 65.91, Validation Loss: 78.44
2025-02-24 20:35:32,779 - Epoch 1037, Training Loss: 72.15, Validation Loss: 78.46
2025-02-24 20:35:32,936 - Epoch 1038, Training Loss: 67.48, Validation Loss: 78.44
2025-02-24 20:35:33,152 - Epoch 1039, Training Loss: 68.74, Validation Loss: 78.44
2025-02-24 20:35:33,319 - Epoch 1040, Training Loss: 71.98, Validation Loss: 78.44
2025-02-24 20:35:33,488 - Epoch 1041, Training Loss: 72.66, Validation Loss: 78.44
2025-02-24 20:35:33,663 - Epoch 1042, Training Loss: 82.54, Validation Loss: 78.41
2025-02-24 20:35:33,856 - Epoch 1043, Training Loss: 85.53, Validation Loss: 78.36
2025-02-24 20:35:34,030 - Epoch 1044, Training Loss: 72.74, Validation Loss: 78.35
2025-02-24 20:35:34,212 - Epoch 1045, Training Loss: 75.42, Validation Loss: 78.33
2025-02-24 20:35:34,388 - Epoch 1046, Training Loss: 79.95, Validation Loss: 78.34
2025-02-24 20:35:34,548 - Epoch 1047, Training Loss: 75.13, Validation Loss: 78.35
2025-02-24 20:35:34,705 - Epoch 1048, Training Loss: 76.12, Validation Loss: 78.37
2025-02-24 20:35:34,891 - Epoch 1049, Training Loss: 69.07, Validation Loss: 78.37
2025-02-24 20:35:35,072 - Epoch 1050, Training Loss: 84.73, Validation Loss: 78.35
2025-02-24 20:35:35,244 - Epoch 1051, Training Loss: 71.99, Validation Loss: 78.33
2025-02-24 20:35:35,429 - Epoch 1052, Training Loss: 77.69, Validation Loss: 78.30
2025-02-24 20:35:35,625 - Epoch 1053, Training Loss: 69.97, Validation Loss: 78.29
2025-02-24 20:35:35,823 - Epoch 1054, Training Loss: 72.73, Validation Loss: 78.26
2025-02-24 20:35:36,009 - Epoch 1055, Training Loss: 81.95, Validation Loss: 78.23
2025-02-24 20:35:36,183 - Epoch 1056, Training Loss: 86.17, Validation Loss: 78.19
2025-02-24 20:35:36,361 - Epoch 1057, Training Loss: 70.43, Validation Loss: 78.19
2025-02-24 20:35:36,535 - Epoch 1058, Training Loss: 71.83, Validation Loss: 78.19
2025-02-24 20:35:36,694 - Epoch 1059, Training Loss: 75.63, Validation Loss: 78.18
2025-02-24 20:35:36,862 - Epoch 1060, Training Loss: 75.00, Validation Loss: 78.15
2025-02-24 20:35:37,044 - Epoch 1061, Training Loss: 79.68, Validation Loss: 78.11
2025-02-24 20:35:37,211 - Epoch 1062, Training Loss: 71.37, Validation Loss: 78.12
2025-02-24 20:35:37,362 - Epoch 1063, Training Loss: 74.47, Validation Loss: 78.09
2025-02-24 20:35:37,536 - Epoch 1064, Training Loss: 72.11, Validation Loss: 78.09
2025-02-24 20:35:37,692 - Epoch 1065, Training Loss: 80.51, Validation Loss: 78.08
2025-02-24 20:35:37,868 - Epoch 1066, Training Loss: 73.20, Validation Loss: 78.12
2025-02-24 20:35:38,021 - Epoch 1067, Training Loss: 81.75, Validation Loss: 78.07
2025-02-24 20:35:38,197 - Epoch 1068, Training Loss: 71.16, Validation Loss: 78.04
2025-02-24 20:35:38,381 - Epoch 1069, Training Loss: 71.21, Validation Loss: 78.03
2025-02-24 20:35:38,552 - Epoch 1070, Training Loss: 75.90, Validation Loss: 78.01
2025-02-24 20:35:38,729 - Epoch 1071, Training Loss: 90.93, Validation Loss: 77.97
2025-02-24 20:35:38,911 - Epoch 1072, Training Loss: 76.77, Validation Loss: 77.96
2025-02-24 20:35:39,091 - Epoch 1073, Training Loss: 73.52, Validation Loss: 77.96
2025-02-24 20:35:39,272 - Epoch 1074, Training Loss: 83.95, Validation Loss: 77.93
2025-02-24 20:35:39,452 - Epoch 1075, Training Loss: 73.50, Validation Loss: 77.93
2025-02-24 20:35:39,633 - Epoch 1076, Training Loss: 69.50, Validation Loss: 77.93
2025-02-24 20:35:39,785 - Epoch 1077, Training Loss: 73.72, Validation Loss: 77.89
2025-02-24 20:35:39,955 - Epoch 1078, Training Loss: 79.20, Validation Loss: 77.86
2025-02-24 20:35:40,136 - Epoch 1079, Training Loss: 76.77, Validation Loss: 77.86
2025-02-24 20:35:40,317 - Epoch 1080, Training Loss: 87.52, Validation Loss: 77.81
2025-02-24 20:35:40,493 - Epoch 1081, Training Loss: 89.13, Validation Loss: 77.77
2025-02-24 20:35:40,660 - Epoch 1082, Training Loss: 71.53, Validation Loss: 77.73
2025-02-24 20:35:40,836 - Epoch 1083, Training Loss: 68.51, Validation Loss: 77.74
2025-02-24 20:35:40,985 - Epoch 1084, Training Loss: 79.62, Validation Loss: 77.74
2025-02-24 20:35:41,142 - Epoch 1085, Training Loss: 82.02, Validation Loss: 77.73
2025-02-24 20:35:41,324 - Epoch 1086, Training Loss: 74.22, Validation Loss: 77.72
2025-02-24 20:35:41,506 - Epoch 1087, Training Loss: 72.10, Validation Loss: 77.72
2025-02-24 20:35:41,672 - Epoch 1088, Training Loss: 70.36, Validation Loss: 77.71
2025-02-24 20:35:41,847 - Epoch 1089, Training Loss: 79.10, Validation Loss: 77.69
2025-02-24 20:35:42,030 - Epoch 1090, Training Loss: 70.62, Validation Loss: 77.69
2025-02-24 20:35:42,219 - Epoch 1091, Training Loss: 78.01, Validation Loss: 77.69
2025-02-24 20:35:42,416 - Epoch 1092, Training Loss: 72.70, Validation Loss: 77.69
2025-02-24 20:35:42,579 - Epoch 1093, Training Loss: 74.05, Validation Loss: 77.71
2025-02-24 20:35:42,762 - Epoch 1094, Training Loss: 74.47, Validation Loss: 77.69
2025-02-24 20:35:42,916 - Epoch 1095, Training Loss: 72.60, Validation Loss: 77.67
2025-02-24 20:35:43,087 - Epoch 1096, Training Loss: 87.81, Validation Loss: 77.62
2025-02-24 20:35:43,287 - Epoch 1097, Training Loss: 87.73, Validation Loss: 77.62
2025-02-24 20:35:43,457 - Epoch 1098, Training Loss: 70.90, Validation Loss: 77.62
2025-02-24 20:35:43,608 - Epoch 1099, Training Loss: 78.65, Validation Loss: 77.59
2025-02-24 20:35:43,797 - Epoch 1100, Training Loss: 70.97, Validation Loss: 77.62
2025-02-24 20:35:43,962 - Epoch 1101, Training Loss: 77.39, Validation Loss: 77.61
2025-02-24 20:35:44,111 - Epoch 1102, Training Loss: 74.32, Validation Loss: 77.60
2025-02-24 20:35:44,263 - Epoch 1103, Training Loss: 79.10, Validation Loss: 77.60
2025-02-24 20:35:44,416 - Epoch 1104, Training Loss: 80.92, Validation Loss: 77.59
2025-02-24 20:35:44,575 - Epoch 1105, Training Loss: 72.40, Validation Loss: 77.59
2025-02-24 20:35:44,737 - Epoch 1106, Training Loss: 76.35, Validation Loss: 77.57
2025-02-24 20:35:44,925 - Epoch 1107, Training Loss: 74.46, Validation Loss: 77.58
2025-02-24 20:35:45,133 - Epoch 1108, Training Loss: 72.20, Validation Loss: 77.60
2025-02-24 20:35:45,288 - Epoch 1109, Training Loss: 72.90, Validation Loss: 77.58
2025-02-24 20:35:45,439 - Epoch 1110, Training Loss: 76.10, Validation Loss: 77.58
2025-02-24 20:35:45,593 - Epoch 1111, Training Loss: 71.91, Validation Loss: 77.57
2025-02-24 20:35:45,789 - Epoch 1112, Training Loss: 69.47, Validation Loss: 77.60
2025-02-24 20:35:45,951 - Epoch 1113, Training Loss: 75.25, Validation Loss: 77.58
2025-02-24 20:35:46,105 - Epoch 1114, Training Loss: 80.70, Validation Loss: 77.53
2025-02-24 20:35:46,280 - Epoch 1115, Training Loss: 72.92, Validation Loss: 77.55
2025-02-24 20:35:46,701 - Epoch 1116, Training Loss: 70.32, Validation Loss: 77.53
2025-02-24 20:35:47,451 - Epoch 1117, Training Loss: 78.52, Validation Loss: 77.52
2025-02-24 20:35:47,651 - Epoch 1118, Training Loss: 72.94, Validation Loss: 77.52
2025-02-24 20:35:47,850 - Epoch 1119, Training Loss: 71.60, Validation Loss: 77.52
2025-02-24 20:35:48,070 - Epoch 1120, Training Loss: 71.21, Validation Loss: 77.48
2025-02-24 20:35:48,285 - Epoch 1121, Training Loss: 88.89, Validation Loss: 77.45
2025-02-24 20:35:48,479 - Epoch 1122, Training Loss: 77.17, Validation Loss: 77.47
2025-02-24 20:35:48,661 - Epoch 1123, Training Loss: 77.62, Validation Loss: 77.45
2025-02-24 20:35:48,822 - Epoch 1124, Training Loss: 73.75, Validation Loss: 77.45
2025-02-24 20:35:48,996 - Epoch 1125, Training Loss: 79.26, Validation Loss: 77.42
2025-02-24 20:35:49,163 - Epoch 1126, Training Loss: 80.57, Validation Loss: 77.38
2025-02-24 20:35:49,340 - Epoch 1127, Training Loss: 77.01, Validation Loss: 77.36
2025-02-24 20:35:49,505 - Epoch 1128, Training Loss: 77.58, Validation Loss: 77.37
2025-02-24 20:35:49,653 - Epoch 1129, Training Loss: 71.01, Validation Loss: 77.37
2025-02-24 20:35:49,799 - Epoch 1130, Training Loss: 85.48, Validation Loss: 77.34
2025-02-24 20:35:49,980 - Epoch 1131, Training Loss: 68.92, Validation Loss: 77.34
2025-02-24 20:35:50,125 - Epoch 1132, Training Loss: 71.33, Validation Loss: 77.34
2025-02-24 20:35:50,274 - Epoch 1133, Training Loss: 75.70, Validation Loss: 77.32
2025-02-24 20:35:50,443 - Epoch 1134, Training Loss: 73.53, Validation Loss: 77.33
2025-02-24 20:35:50,596 - Epoch 1135, Training Loss: 81.96, Validation Loss: 77.32
2025-02-24 20:35:50,744 - Epoch 1136, Training Loss: 77.73, Validation Loss: 77.32
2025-02-24 20:35:50,920 - Epoch 1137, Training Loss: 72.11, Validation Loss: 77.36
2025-02-24 20:35:51,068 - Epoch 1138, Training Loss: 80.34, Validation Loss: 77.34
2025-02-24 20:35:51,224 - Epoch 1139, Training Loss: 76.16, Validation Loss: 77.31
2025-02-24 20:35:51,397 - Epoch 1140, Training Loss: 81.84, Validation Loss: 77.28
2025-02-24 20:35:51,580 - Epoch 1141, Training Loss: 89.12, Validation Loss: 77.21
2025-02-24 20:35:51,770 - Epoch 1142, Training Loss: 72.64, Validation Loss: 77.19
2025-02-24 20:35:51,943 - Epoch 1143, Training Loss: 72.85, Validation Loss: 77.21
2025-02-24 20:35:52,093 - Epoch 1144, Training Loss: 71.11, Validation Loss: 77.21
2025-02-24 20:35:52,244 - Epoch 1145, Training Loss: 69.93, Validation Loss: 77.19
2025-02-24 20:35:52,405 - Epoch 1146, Training Loss: 74.02, Validation Loss: 77.19
2025-02-24 20:35:52,585 - Epoch 1147, Training Loss: 67.94, Validation Loss: 77.16
2025-02-24 20:35:52,774 - Epoch 1148, Training Loss: 70.10, Validation Loss: 77.15
2025-02-24 20:35:52,943 - Epoch 1149, Training Loss: 83.79, Validation Loss: 77.12
2025-02-24 20:35:53,177 - Epoch 1150, Training Loss: 73.27, Validation Loss: 77.10
2025-02-24 20:35:53,351 - Epoch 1151, Training Loss: 82.92, Validation Loss: 77.05
2025-02-24 20:35:53,528 - Epoch 1152, Training Loss: 66.76, Validation Loss: 77.04
2025-02-24 20:35:53,700 - Epoch 1153, Training Loss: 68.94, Validation Loss: 77.06
2025-02-24 20:35:53,860 - Epoch 1154, Training Loss: 70.70, Validation Loss: 77.07
2025-02-24 20:35:54,010 - Epoch 1155, Training Loss: 70.26, Validation Loss: 77.08
2025-02-24 20:35:54,161 - Epoch 1156, Training Loss: 73.78, Validation Loss: 77.08
2025-02-24 20:35:54,315 - Epoch 1157, Training Loss: 69.28, Validation Loss: 77.09
2025-02-24 20:35:54,480 - Epoch 1158, Training Loss: 77.79, Validation Loss: 77.07
2025-02-24 20:35:54,632 - Epoch 1159, Training Loss: 76.57, Validation Loss: 77.06
2025-02-24 20:35:54,789 - Epoch 1160, Training Loss: 73.13, Validation Loss: 77.05
2025-02-24 20:35:54,946 - Epoch 1161, Training Loss: 72.67, Validation Loss: 77.07
2025-02-24 20:35:55,102 - Epoch 1162, Training Loss: 71.68, Validation Loss: 77.09
2025-02-24 20:35:55,256 - Epoch 1163, Training Loss: 70.14, Validation Loss: 77.08
2025-02-24 20:35:55,409 - Epoch 1164, Training Loss: 74.32, Validation Loss: 77.05
2025-02-24 20:35:55,560 - Epoch 1165, Training Loss: 70.68, Validation Loss: 77.08
2025-02-24 20:35:55,714 - Epoch 1166, Training Loss: 90.21, Validation Loss: 77.04
2025-02-24 20:35:55,856 - Epoch 1167, Training Loss: 72.42, Validation Loss: 77.02
2025-02-24 20:35:56,072 - Epoch 1168, Training Loss: 81.14, Validation Loss: 77.01
2025-02-24 20:35:56,241 - Epoch 1169, Training Loss: 91.35, Validation Loss: 76.94
2025-02-24 20:35:56,425 - Epoch 1170, Training Loss: 68.18, Validation Loss: 76.93
2025-02-24 20:35:56,590 - Epoch 1171, Training Loss: 74.92, Validation Loss: 76.93
2025-02-24 20:35:56,746 - Epoch 1172, Training Loss: 74.96, Validation Loss: 76.93
2025-02-24 20:35:56,889 - Epoch 1173, Training Loss: 69.09, Validation Loss: 76.93
2025-02-24 20:35:57,040 - Epoch 1174, Training Loss: 77.74, Validation Loss: 76.91
2025-02-24 20:35:57,206 - Epoch 1175, Training Loss: 75.52, Validation Loss: 76.88
2025-02-24 20:35:57,381 - Epoch 1176, Training Loss: 81.71, Validation Loss: 76.88
2025-02-24 20:35:57,550 - Epoch 1177, Training Loss: 81.50, Validation Loss: 76.85
2025-02-24 20:35:57,734 - Epoch 1178, Training Loss: 82.44, Validation Loss: 76.83
2025-02-24 20:35:57,905 - Epoch 1179, Training Loss: 77.54, Validation Loss: 76.80
2025-02-24 20:35:58,086 - Epoch 1180, Training Loss: 68.85, Validation Loss: 76.81
2025-02-24 20:35:58,236 - Epoch 1181, Training Loss: 82.15, Validation Loss: 76.78
2025-02-24 20:35:58,411 - Epoch 1182, Training Loss: 76.28, Validation Loss: 76.76
2025-02-24 20:35:58,580 - Epoch 1183, Training Loss: 80.09, Validation Loss: 76.74
2025-02-24 20:35:58,767 - Epoch 1184, Training Loss: 75.43, Validation Loss: 76.71
2025-02-24 20:35:58,945 - Epoch 1185, Training Loss: 72.88, Validation Loss: 76.68
2025-02-24 20:35:59,140 - Epoch 1186, Training Loss: 74.75, Validation Loss: 76.64
2025-02-24 20:35:59,322 - Epoch 1187, Training Loss: 66.49, Validation Loss: 76.63
2025-02-24 20:35:59,511 - Epoch 1188, Training Loss: 78.68, Validation Loss: 76.62
2025-02-24 20:35:59,705 - Epoch 1189, Training Loss: 69.02, Validation Loss: 76.63
2025-02-24 20:35:59,865 - Epoch 1190, Training Loss: 79.66, Validation Loss: 76.62
2025-02-24 20:36:00,048 - Epoch 1191, Training Loss: 74.28, Validation Loss: 76.58
2025-02-24 20:36:00,236 - Epoch 1192, Training Loss: 79.98, Validation Loss: 76.58
2025-02-24 20:36:00,412 - Epoch 1193, Training Loss: 79.44, Validation Loss: 76.56
2025-02-24 20:36:00,588 - Epoch 1194, Training Loss: 73.41, Validation Loss: 76.56
2025-02-24 20:36:00,766 - Epoch 1195, Training Loss: 78.89, Validation Loss: 76.55
2025-02-24 20:36:00,974 - Epoch 1196, Training Loss: 73.89, Validation Loss: 76.52
2025-02-24 20:36:01,160 - Epoch 1197, Training Loss: 69.11, Validation Loss: 76.52
2025-02-24 20:36:01,322 - Epoch 1198, Training Loss: 73.78, Validation Loss: 76.54
2025-02-24 20:36:01,482 - Epoch 1199, Training Loss: 69.56, Validation Loss: 76.55
2025-02-24 20:36:01,639 - Epoch 1200, Training Loss: 78.34, Validation Loss: 76.53
2025-02-24 20:36:01,802 - Epoch 1201, Training Loss: 70.47, Validation Loss: 76.53
2025-02-24 20:36:01,964 - Epoch 1202, Training Loss: 74.86, Validation Loss: 76.51
2025-02-24 20:36:02,131 - Epoch 1203, Training Loss: 73.90, Validation Loss: 76.54
2025-02-24 20:36:02,279 - Epoch 1204, Training Loss: 79.24, Validation Loss: 76.52
2025-02-24 20:36:02,440 - Epoch 1205, Training Loss: 79.53, Validation Loss: 76.48
2025-02-24 20:36:02,625 - Epoch 1206, Training Loss: 79.59, Validation Loss: 76.46
2025-02-24 20:36:02,793 - Epoch 1207, Training Loss: 73.00, Validation Loss: 76.47
2025-02-24 20:36:02,965 - Epoch 1208, Training Loss: 88.42, Validation Loss: 76.42
2025-02-24 20:36:03,144 - Epoch 1209, Training Loss: 76.97, Validation Loss: 76.42
2025-02-24 20:36:03,329 - Epoch 1210, Training Loss: 75.61, Validation Loss: 76.38
2025-02-24 20:36:03,515 - Epoch 1211, Training Loss: 87.48, Validation Loss: 76.36
2025-02-24 20:36:03,689 - Epoch 1212, Training Loss: 72.53, Validation Loss: 76.37
2025-02-24 20:36:03,845 - Epoch 1213, Training Loss: 70.39, Validation Loss: 76.34
2025-02-24 20:36:04,030 - Epoch 1214, Training Loss: 75.35, Validation Loss: 76.32
2025-02-24 20:36:04,211 - Epoch 1215, Training Loss: 71.78, Validation Loss: 76.32
2025-02-24 20:36:04,363 - Epoch 1216, Training Loss: 74.07, Validation Loss: 76.33
2025-02-24 20:36:04,509 - Epoch 1217, Training Loss: 78.60, Validation Loss: 76.29
2025-02-24 20:36:04,692 - Epoch 1218, Training Loss: 69.66, Validation Loss: 76.27
2025-02-24 20:36:04,862 - Epoch 1219, Training Loss: 71.98, Validation Loss: 76.28
2025-02-24 20:36:05,014 - Epoch 1220, Training Loss: 70.33, Validation Loss: 76.29
2025-02-24 20:36:05,170 - Epoch 1221, Training Loss: 74.30, Validation Loss: 76.28
2025-02-24 20:36:05,327 - Epoch 1222, Training Loss: 68.06, Validation Loss: 76.26
2025-02-24 20:36:05,495 - Epoch 1223, Training Loss: 71.49, Validation Loss: 76.27
2025-02-24 20:36:05,650 - Epoch 1224, Training Loss: 79.38, Validation Loss: 76.25
2025-02-24 20:36:05,823 - Epoch 1225, Training Loss: 81.25, Validation Loss: 76.23
2025-02-24 20:36:06,005 - Epoch 1226, Training Loss: 76.63, Validation Loss: 76.22
2025-02-24 20:36:06,176 - Epoch 1227, Training Loss: 78.16, Validation Loss: 76.20
2025-02-24 20:36:06,356 - Epoch 1228, Training Loss: 68.50, Validation Loss: 76.23
2025-02-24 20:36:06,507 - Epoch 1229, Training Loss: 73.97, Validation Loss: 76.20
2025-02-24 20:36:06,663 - Epoch 1230, Training Loss: 71.13, Validation Loss: 76.21
2025-02-24 20:36:06,808 - Epoch 1231, Training Loss: 72.09, Validation Loss: 76.20
2025-02-24 20:36:06,989 - Epoch 1232, Training Loss: 68.38, Validation Loss: 76.23
2025-02-24 20:36:07,141 - Epoch 1233, Training Loss: 74.23, Validation Loss: 76.23
2025-02-24 20:36:07,305 - Epoch 1234, Training Loss: 72.17, Validation Loss: 76.23
2025-02-24 20:36:07,456 - Epoch 1235, Training Loss: 71.28, Validation Loss: 76.21
2025-02-24 20:36:07,619 - Epoch 1236, Training Loss: 74.04, Validation Loss: 76.20
2025-02-24 20:36:07,790 - Epoch 1237, Training Loss: 82.37, Validation Loss: 76.20
2025-02-24 20:36:07,943 - Epoch 1238, Training Loss: 76.70, Validation Loss: 76.17
2025-02-24 20:36:08,125 - Epoch 1239, Training Loss: 74.12, Validation Loss: 76.14
2025-02-24 20:36:08,312 - Epoch 1240, Training Loss: 70.75, Validation Loss: 76.13
2025-02-24 20:36:08,495 - Epoch 1241, Training Loss: 85.13, Validation Loss: 76.10
2025-02-24 20:36:08,682 - Epoch 1242, Training Loss: 79.07, Validation Loss: 76.07
2025-02-24 20:36:08,895 - Epoch 1243, Training Loss: 70.85, Validation Loss: 76.10
2025-02-24 20:36:09,115 - Epoch 1244, Training Loss: 72.36, Validation Loss: 76.11
2025-02-24 20:36:09,336 - Epoch 1245, Training Loss: 77.86, Validation Loss: 76.09
2025-02-24 20:36:09,518 - Epoch 1246, Training Loss: 78.74, Validation Loss: 76.05
2025-02-24 20:36:09,747 - Epoch 1247, Training Loss: 81.08, Validation Loss: 76.02
2025-02-24 20:36:09,985 - Epoch 1248, Training Loss: 68.88, Validation Loss: 76.00
2025-02-24 20:36:10,259 - Epoch 1249, Training Loss: 83.60, Validation Loss: 75.97
2025-02-24 20:36:10,499 - Epoch 1250, Training Loss: 71.77, Validation Loss: 75.98
2025-02-24 20:36:10,704 - Epoch 1251, Training Loss: 86.00, Validation Loss: 75.97
2025-02-24 20:36:10,930 - Epoch 1252, Training Loss: 69.46, Validation Loss: 75.99
2025-02-24 20:36:11,117 - Epoch 1253, Training Loss: 72.44, Validation Loss: 75.99
2025-02-24 20:36:11,306 - Epoch 1254, Training Loss: 72.41, Validation Loss: 75.98
2025-02-24 20:36:11,530 - Epoch 1255, Training Loss: 68.77, Validation Loss: 75.97
2025-02-24 20:36:11,762 - Epoch 1256, Training Loss: 73.63, Validation Loss: 75.97
2025-02-24 20:36:12,006 - Epoch 1257, Training Loss: 75.35, Validation Loss: 75.96
2025-02-24 20:36:12,345 - Epoch 1258, Training Loss: 74.29, Validation Loss: 75.96
2025-02-24 20:36:12,689 - Epoch 1259, Training Loss: 82.33, Validation Loss: 75.92
2025-02-24 20:36:13,058 - Epoch 1260, Training Loss: 66.79, Validation Loss: 75.93
2025-02-24 20:36:13,311 - Epoch 1261, Training Loss: 82.20, Validation Loss: 75.91
2025-02-24 20:36:13,583 - Epoch 1262, Training Loss: 69.31, Validation Loss: 75.92
2025-02-24 20:36:13,781 - Epoch 1263, Training Loss: 86.62, Validation Loss: 75.89
2025-02-24 20:36:14,006 - Epoch 1264, Training Loss: 70.36, Validation Loss: 75.87
2025-02-24 20:36:14,231 - Epoch 1265, Training Loss: 77.72, Validation Loss: 75.86
2025-02-24 20:36:14,511 - Epoch 1266, Training Loss: 77.07, Validation Loss: 75.84
2025-02-24 20:36:14,747 - Epoch 1267, Training Loss: 79.63, Validation Loss: 75.84
2025-02-24 20:36:14,952 - Epoch 1268, Training Loss: 82.08, Validation Loss: 75.83
2025-02-24 20:36:15,147 - Epoch 1269, Training Loss: 71.22, Validation Loss: 75.81
2025-02-24 20:36:15,357 - Epoch 1270, Training Loss: 75.79, Validation Loss: 75.81
2025-02-24 20:36:15,540 - Epoch 1271, Training Loss: 72.34, Validation Loss: 75.84
2025-02-24 20:36:15,705 - Epoch 1272, Training Loss: 72.26, Validation Loss: 75.84
2025-02-24 20:36:15,857 - Epoch 1273, Training Loss: 79.59, Validation Loss: 75.82
2025-02-24 20:36:16,013 - Epoch 1274, Training Loss: 81.60, Validation Loss: 75.78
2025-02-24 20:36:16,185 - Epoch 1275, Training Loss: 69.35, Validation Loss: 75.82
2025-02-24 20:36:16,351 - Epoch 1276, Training Loss: 80.90, Validation Loss: 75.79
2025-02-24 20:36:16,518 - Epoch 1277, Training Loss: 71.76, Validation Loss: 75.80
2025-02-24 20:36:16,678 - Epoch 1278, Training Loss: 69.27, Validation Loss: 75.81
2025-02-24 20:36:16,842 - Epoch 1279, Training Loss: 76.50, Validation Loss: 75.79
2025-02-24 20:36:17,001 - Epoch 1280, Training Loss: 77.11, Validation Loss: 75.80
2025-02-24 20:36:17,163 - Epoch 1281, Training Loss: 76.42, Validation Loss: 75.77
2025-02-24 20:36:17,341 - Epoch 1282, Training Loss: 68.11, Validation Loss: 75.77
2025-02-24 20:36:17,518 - Epoch 1283, Training Loss: 71.75, Validation Loss: 75.76
2025-02-24 20:36:17,706 - Epoch 1284, Training Loss: 70.85, Validation Loss: 75.74
2025-02-24 20:36:17,881 - Epoch 1285, Training Loss: 80.94, Validation Loss: 75.74
2025-02-24 20:36:18,062 - Epoch 1286, Training Loss: 69.17, Validation Loss: 75.73
2025-02-24 20:36:18,239 - Epoch 1287, Training Loss: 68.45, Validation Loss: 75.73
2025-02-24 20:36:18,410 - Epoch 1288, Training Loss: 75.57, Validation Loss: 75.73
2025-02-24 20:36:18,575 - Epoch 1289, Training Loss: 70.64, Validation Loss: 75.71
2025-02-24 20:36:18,777 - Epoch 1290, Training Loss: 78.29, Validation Loss: 75.69
2025-02-24 20:36:18,942 - Epoch 1291, Training Loss: 80.95, Validation Loss: 75.66
2025-02-24 20:36:19,123 - Epoch 1292, Training Loss: 72.61, Validation Loss: 75.66
2025-02-24 20:36:19,295 - Epoch 1293, Training Loss: 67.01, Validation Loss: 75.65
2025-02-24 20:36:19,481 - Epoch 1294, Training Loss: 77.72, Validation Loss: 75.64
2025-02-24 20:36:19,668 - Epoch 1295, Training Loss: 69.79, Validation Loss: 75.64
2025-02-24 20:36:19,846 - Epoch 1296, Training Loss: 73.23, Validation Loss: 75.61
2025-02-24 20:36:20,024 - Epoch 1297, Training Loss: 77.31, Validation Loss: 75.58
2025-02-24 20:36:20,196 - Epoch 1298, Training Loss: 78.99, Validation Loss: 75.56
2025-02-24 20:36:20,377 - Epoch 1299, Training Loss: 68.07, Validation Loss: 75.58
2025-02-24 20:36:20,528 - Epoch 1300, Training Loss: 71.20, Validation Loss: 75.56
2025-02-24 20:36:20,690 - Epoch 1301, Training Loss: 76.53, Validation Loss: 75.54
2025-02-24 20:36:20,871 - Epoch 1302, Training Loss: 70.57, Validation Loss: 75.50
2025-02-24 20:36:21,046 - Epoch 1303, Training Loss: 79.95, Validation Loss: 75.50
2025-02-24 20:36:21,219 - Epoch 1304, Training Loss: 75.28, Validation Loss: 75.51
2025-02-24 20:36:21,376 - Epoch 1305, Training Loss: 70.57, Validation Loss: 75.50
2025-02-24 20:36:21,534 - Epoch 1306, Training Loss: 70.34, Validation Loss: 75.52
2025-02-24 20:36:21,698 - Epoch 1307, Training Loss: 76.73, Validation Loss: 75.49
2025-02-24 20:36:21,883 - Epoch 1308, Training Loss: 69.40, Validation Loss: 75.50
2025-02-24 20:36:22,049 - Epoch 1309, Training Loss: 70.47, Validation Loss: 75.50
2025-02-24 20:36:22,211 - Epoch 1310, Training Loss: 74.89, Validation Loss: 75.47
2025-02-24 20:36:22,393 - Epoch 1311, Training Loss: 72.36, Validation Loss: 75.47
2025-02-24 20:36:22,554 - Epoch 1312, Training Loss: 73.10, Validation Loss: 75.46
2025-02-24 20:36:22,793 - Epoch 1313, Training Loss: 69.46, Validation Loss: 75.47
2025-02-24 20:36:22,957 - Epoch 1314, Training Loss: 80.70, Validation Loss: 75.49
2025-02-24 20:36:23,122 - Epoch 1315, Training Loss: 81.20, Validation Loss: 75.47
2025-02-24 20:36:23,280 - Epoch 1316, Training Loss: 83.57, Validation Loss: 75.42
2025-02-24 20:36:23,458 - Epoch 1317, Training Loss: 79.69, Validation Loss: 75.41
2025-02-24 20:36:23,698 - Epoch 1318, Training Loss: 76.79, Validation Loss: 75.42
2025-02-24 20:36:23,864 - Epoch 1319, Training Loss: 70.39, Validation Loss: 75.44
2025-02-24 20:36:24,017 - Epoch 1320, Training Loss: 91.06, Validation Loss: 75.41
2025-02-24 20:36:24,168 - Epoch 1321, Training Loss: 70.26, Validation Loss: 75.41
2025-02-24 20:36:24,326 - Epoch 1322, Training Loss: 71.06, Validation Loss: 75.45
2025-02-24 20:36:24,477 - Epoch 1323, Training Loss: 71.66, Validation Loss: 75.43
2025-02-24 20:36:24,628 - Epoch 1324, Training Loss: 71.95, Validation Loss: 75.44
2025-02-24 20:36:24,785 - Epoch 1325, Training Loss: 78.64, Validation Loss: 75.42
2025-02-24 20:36:24,939 - Epoch 1326, Training Loss: 78.87, Validation Loss: 75.39
2025-02-24 20:36:25,111 - Epoch 1327, Training Loss: 73.64, Validation Loss: 75.38
2025-02-24 20:36:25,310 - Epoch 1328, Training Loss: 80.73, Validation Loss: 75.36
2025-02-24 20:36:25,509 - Epoch 1329, Training Loss: 69.43, Validation Loss: 75.37
2025-02-24 20:36:25,666 - Epoch 1330, Training Loss: 69.76, Validation Loss: 75.38
2025-02-24 20:36:25,826 - Epoch 1331, Training Loss: 70.87, Validation Loss: 75.36
2025-02-24 20:36:26,010 - Epoch 1332, Training Loss: 72.65, Validation Loss: 75.34
2025-02-24 20:36:26,183 - Epoch 1333, Training Loss: 82.91, Validation Loss: 75.31
2025-02-24 20:36:26,361 - Epoch 1334, Training Loss: 69.11, Validation Loss: 75.32
2025-02-24 20:36:26,513 - Epoch 1335, Training Loss: 69.10, Validation Loss: 75.35
2025-02-24 20:36:26,678 - Epoch 1336, Training Loss: 72.70, Validation Loss: 75.33
2025-02-24 20:36:26,832 - Epoch 1337, Training Loss: 69.05, Validation Loss: 75.30
2025-02-24 20:36:27,009 - Epoch 1338, Training Loss: 84.90, Validation Loss: 75.25
2025-02-24 20:36:27,185 - Epoch 1339, Training Loss: 77.98, Validation Loss: 75.23
2025-02-24 20:36:27,370 - Epoch 1340, Training Loss: 80.62, Validation Loss: 75.22
2025-02-24 20:36:27,544 - Epoch 1341, Training Loss: 79.79, Validation Loss: 75.20
2025-02-24 20:36:27,730 - Epoch 1342, Training Loss: 71.52, Validation Loss: 75.20
2025-02-24 20:36:27,907 - Epoch 1343, Training Loss: 69.48, Validation Loss: 75.20
2025-02-24 20:36:28,076 - Epoch 1344, Training Loss: 69.66, Validation Loss: 75.23
2025-02-24 20:36:28,231 - Epoch 1345, Training Loss: 73.73, Validation Loss: 75.21
2025-02-24 20:36:28,386 - Epoch 1346, Training Loss: 83.94, Validation Loss: 75.19
2025-02-24 20:36:28,561 - Epoch 1347, Training Loss: 71.55, Validation Loss: 75.20
2025-02-24 20:36:28,729 - Epoch 1348, Training Loss: 67.64, Validation Loss: 75.23
2025-02-24 20:36:28,879 - Epoch 1349, Training Loss: 72.85, Validation Loss: 75.21
2025-02-24 20:36:29,049 - Epoch 1350, Training Loss: 67.13, Validation Loss: 75.20
2025-02-24 20:36:29,202 - Epoch 1351, Training Loss: 78.07, Validation Loss: 75.20
2025-02-24 20:36:29,367 - Epoch 1352, Training Loss: 78.65, Validation Loss: 75.19
2025-02-24 20:36:29,543 - Epoch 1353, Training Loss: 70.58, Validation Loss: 75.17
2025-02-24 20:36:29,734 - Epoch 1354, Training Loss: 72.98, Validation Loss: 75.16
2025-02-24 20:36:29,915 - Epoch 1355, Training Loss: 74.64, Validation Loss: 75.15
2025-02-24 20:36:30,108 - Epoch 1356, Training Loss: 70.21, Validation Loss: 75.16
2025-02-24 20:36:30,262 - Epoch 1357, Training Loss: 72.41, Validation Loss: 75.14
2025-02-24 20:36:30,438 - Epoch 1358, Training Loss: 69.52, Validation Loss: 75.15
2025-02-24 20:36:30,592 - Epoch 1359, Training Loss: 72.97, Validation Loss: 75.13
2025-02-24 20:36:30,778 - Epoch 1360, Training Loss: 81.40, Validation Loss: 75.12
2025-02-24 20:36:30,952 - Epoch 1361, Training Loss: 70.76, Validation Loss: 75.09
2025-02-24 20:36:31,128 - Epoch 1362, Training Loss: 71.04, Validation Loss: 75.12
2025-02-24 20:36:31,282 - Epoch 1363, Training Loss: 69.01, Validation Loss: 75.15
2025-02-24 20:36:31,441 - Epoch 1364, Training Loss: 71.23, Validation Loss: 75.15
2025-02-24 20:36:31,593 - Epoch 1365, Training Loss: 66.86, Validation Loss: 75.15
2025-02-24 20:36:31,763 - Epoch 1366, Training Loss: 77.44, Validation Loss: 75.10
2025-02-24 20:36:31,914 - Epoch 1367, Training Loss: 69.35, Validation Loss: 75.10
2025-02-24 20:36:32,065 - Epoch 1368, Training Loss: 81.06, Validation Loss: 75.08
2025-02-24 20:36:32,239 - Epoch 1369, Training Loss: 72.56, Validation Loss: 75.06
2025-02-24 20:36:32,421 - Epoch 1370, Training Loss: 76.22, Validation Loss: 75.04
2025-02-24 20:36:32,593 - Epoch 1371, Training Loss: 71.74, Validation Loss: 75.04
2025-02-24 20:36:32,783 - Epoch 1372, Training Loss: 67.71, Validation Loss: 75.03
2025-02-24 20:36:32,960 - Epoch 1373, Training Loss: 73.05, Validation Loss: 75.02
2025-02-24 20:36:33,142 - Epoch 1374, Training Loss: 69.05, Validation Loss: 75.02
2025-02-24 20:36:33,294 - Epoch 1375, Training Loss: 73.08, Validation Loss: 75.03
2025-02-24 20:36:33,448 - Epoch 1376, Training Loss: 79.12, Validation Loss: 75.02
2025-02-24 20:36:33,627 - Epoch 1377, Training Loss: 82.91, Validation Loss: 74.99
2025-02-24 20:36:33,815 - Epoch 1378, Training Loss: 78.84, Validation Loss: 74.95
2025-02-24 20:36:33,994 - Epoch 1379, Training Loss: 71.00, Validation Loss: 74.95
2025-02-24 20:36:34,165 - Epoch 1380, Training Loss: 63.72, Validation Loss: 74.95
2025-02-24 20:36:34,327 - Epoch 1381, Training Loss: 78.31, Validation Loss: 74.93
2025-02-24 20:36:34,506 - Epoch 1382, Training Loss: 90.06, Validation Loss: 74.88
2025-02-24 20:36:34,693 - Epoch 1383, Training Loss: 69.07, Validation Loss: 74.90
2025-02-24 20:36:34,844 - Epoch 1384, Training Loss: 70.84, Validation Loss: 74.88
2025-02-24 20:36:35,006 - Epoch 1385, Training Loss: 73.03, Validation Loss: 74.89
2025-02-24 20:36:35,171 - Epoch 1386, Training Loss: 79.78, Validation Loss: 74.86
2025-02-24 20:36:35,358 - Epoch 1387, Training Loss: 69.69, Validation Loss: 74.86
2025-02-24 20:36:35,540 - Epoch 1388, Training Loss: 70.29, Validation Loss: 74.87
2025-02-24 20:36:35,711 - Epoch 1389, Training Loss: 73.55, Validation Loss: 74.87
2025-02-24 20:36:35,876 - Epoch 1390, Training Loss: 70.92, Validation Loss: 74.85
2025-02-24 20:36:36,051 - Epoch 1391, Training Loss: 71.22, Validation Loss: 74.84
2025-02-24 20:36:36,233 - Epoch 1392, Training Loss: 76.03, Validation Loss: 74.82
2025-02-24 20:36:36,415 - Epoch 1393, Training Loss: 86.26, Validation Loss: 74.78
2025-02-24 20:36:36,596 - Epoch 1394, Training Loss: 68.72, Validation Loss: 74.79
2025-02-24 20:36:36,763 - Epoch 1395, Training Loss: 69.30, Validation Loss: 74.79
2025-02-24 20:36:36,908 - Epoch 1396, Training Loss: 79.69, Validation Loss: 74.77
2025-02-24 20:36:37,085 - Epoch 1397, Training Loss: 81.15, Validation Loss: 74.76
2025-02-24 20:36:37,263 - Epoch 1398, Training Loss: 69.64, Validation Loss: 74.74
2025-02-24 20:36:37,444 - Epoch 1399, Training Loss: 70.66, Validation Loss: 74.73
2025-02-24 20:36:37,629 - Epoch 1400, Training Loss: 68.06, Validation Loss: 74.73
2025-02-24 20:36:37,799 - Epoch 1401, Training Loss: 71.26, Validation Loss: 74.74
2025-02-24 20:36:37,952 - Epoch 1402, Training Loss: 70.20, Validation Loss: 74.75
2025-02-24 20:36:38,106 - Epoch 1403, Training Loss: 81.57, Validation Loss: 74.71
2025-02-24 20:36:38,286 - Epoch 1404, Training Loss: 70.39, Validation Loss: 74.68
2025-02-24 20:36:38,462 - Epoch 1405, Training Loss: 81.73, Validation Loss: 74.65
2025-02-24 20:36:38,660 - Epoch 1406, Training Loss: 82.65, Validation Loss: 74.62
2025-02-24 20:36:38,885 - Epoch 1407, Training Loss: 77.73, Validation Loss: 74.59
2025-02-24 20:36:39,061 - Epoch 1408, Training Loss: 65.45, Validation Loss: 74.58
2025-02-24 20:36:39,246 - Epoch 1409, Training Loss: 70.35, Validation Loss: 74.57
2025-02-24 20:36:39,421 - Epoch 1410, Training Loss: 74.62, Validation Loss: 74.55
2025-02-24 20:36:39,598 - Epoch 1411, Training Loss: 78.81, Validation Loss: 74.52
2025-02-24 20:36:39,782 - Epoch 1412, Training Loss: 70.84, Validation Loss: 74.53
2025-02-24 20:36:39,939 - Epoch 1413, Training Loss: 73.04, Validation Loss: 74.51
2025-02-24 20:36:40,113 - Epoch 1414, Training Loss: 80.85, Validation Loss: 74.47
2025-02-24 20:36:40,296 - Epoch 1415, Training Loss: 84.50, Validation Loss: 74.45
2025-02-24 20:36:40,472 - Epoch 1416, Training Loss: 71.83, Validation Loss: 74.47
2025-02-24 20:36:40,628 - Epoch 1417, Training Loss: 89.95, Validation Loss: 74.43
2025-02-24 20:36:40,815 - Epoch 1418, Training Loss: 70.12, Validation Loss: 74.43
2025-02-24 20:36:40,994 - Epoch 1419, Training Loss: 73.53, Validation Loss: 74.40
2025-02-24 20:36:41,189 - Epoch 1420, Training Loss: 86.94, Validation Loss: 74.35
2025-02-24 20:36:41,362 - Epoch 1421, Training Loss: 73.43, Validation Loss: 74.36
2025-02-24 20:36:41,526 - Epoch 1422, Training Loss: 68.41, Validation Loss: 74.38
2025-02-24 20:36:41,687 - Epoch 1423, Training Loss: 71.27, Validation Loss: 74.38
2025-02-24 20:36:41,842 - Epoch 1424, Training Loss: 72.10, Validation Loss: 74.40
2025-02-24 20:36:42,018 - Epoch 1425, Training Loss: 77.64, Validation Loss: 74.37
2025-02-24 20:36:42,177 - Epoch 1426, Training Loss: 85.42, Validation Loss: 74.33
2025-02-24 20:36:42,359 - Epoch 1427, Training Loss: 76.68, Validation Loss: 74.34
2025-02-24 20:36:42,516 - Epoch 1428, Training Loss: 75.07, Validation Loss: 74.32
2025-02-24 20:36:42,698 - Epoch 1429, Training Loss: 66.83, Validation Loss: 74.31
2025-02-24 20:36:42,886 - Epoch 1430, Training Loss: 72.08, Validation Loss: 74.31
2025-02-24 20:36:43,063 - Epoch 1431, Training Loss: 72.64, Validation Loss: 74.29
2025-02-24 20:36:43,238 - Epoch 1432, Training Loss: 69.61, Validation Loss: 74.29
2025-02-24 20:36:43,416 - Epoch 1433, Training Loss: 78.21, Validation Loss: 74.29
2025-02-24 20:36:43,566 - Epoch 1434, Training Loss: 79.09, Validation Loss: 74.26
2025-02-24 20:36:43,758 - Epoch 1435, Training Loss: 71.07, Validation Loss: 74.25
2025-02-24 20:36:43,926 - Epoch 1436, Training Loss: 66.12, Validation Loss: 74.24
2025-02-24 20:36:44,103 - Epoch 1437, Training Loss: 89.30, Validation Loss: 74.22
2025-02-24 20:36:44,277 - Epoch 1438, Training Loss: 73.49, Validation Loss: 74.20
2025-02-24 20:36:44,464 - Epoch 1439, Training Loss: 81.50, Validation Loss: 74.16
2025-02-24 20:36:44,636 - Epoch 1440, Training Loss: 69.54, Validation Loss: 74.16
2025-02-24 20:36:44,803 - Epoch 1441, Training Loss: 71.23, Validation Loss: 74.17
2025-02-24 20:36:44,948 - Epoch 1442, Training Loss: 69.43, Validation Loss: 74.18
2025-02-24 20:36:45,107 - Epoch 1443, Training Loss: 74.37, Validation Loss: 74.16
2025-02-24 20:36:45,268 - Epoch 1444, Training Loss: 68.84, Validation Loss: 74.13
2025-02-24 20:36:45,455 - Epoch 1445, Training Loss: 81.65, Validation Loss: 74.15
2025-02-24 20:36:45,610 - Epoch 1446, Training Loss: 75.30, Validation Loss: 74.14
2025-02-24 20:36:45,777 - Epoch 1447, Training Loss: 86.96, Validation Loss: 74.12
2025-02-24 20:36:45,951 - Epoch 1448, Training Loss: 72.39, Validation Loss: 74.12
2025-02-24 20:36:46,113 - Epoch 1449, Training Loss: 84.53, Validation Loss: 74.08
2025-02-24 20:36:46,286 - Epoch 1450, Training Loss: 70.10, Validation Loss: 74.10
2025-02-24 20:36:46,443 - Epoch 1451, Training Loss: 69.20, Validation Loss: 74.14
2025-02-24 20:36:46,597 - Epoch 1452, Training Loss: 69.27, Validation Loss: 74.15
2025-02-24 20:36:46,760 - Epoch 1453, Training Loss: 64.30, Validation Loss: 74.15
2025-02-24 20:36:46,910 - Epoch 1454, Training Loss: 78.19, Validation Loss: 74.13
2025-02-24 20:36:47,063 - Epoch 1455, Training Loss: 75.65, Validation Loss: 74.12
2025-02-24 20:36:47,217 - Epoch 1456, Training Loss: 79.64, Validation Loss: 74.08
2025-02-24 20:36:47,395 - Epoch 1457, Training Loss: 79.67, Validation Loss: 74.07
2025-02-24 20:36:47,565 - Epoch 1458, Training Loss: 74.80, Validation Loss: 74.05
2025-02-24 20:36:47,759 - Epoch 1459, Training Loss: 82.50, Validation Loss: 74.02
2025-02-24 20:36:47,929 - Epoch 1460, Training Loss: 73.25, Validation Loss: 74.01
2025-02-24 20:36:48,106 - Epoch 1461, Training Loss: 76.78, Validation Loss: 74.01
2025-02-24 20:36:48,280 - Epoch 1462, Training Loss: 70.42, Validation Loss: 74.01
2025-02-24 20:36:48,443 - Epoch 1463, Training Loss: 79.94, Validation Loss: 74.02
2025-02-24 20:36:48,596 - Epoch 1464, Training Loss: 69.97, Validation Loss: 74.05
2025-02-24 20:36:48,762 - Epoch 1465, Training Loss: 71.85, Validation Loss: 74.06
2025-02-24 20:36:48,910 - Epoch 1466, Training Loss: 72.11, Validation Loss: 74.07
2025-02-24 20:36:49,064 - Epoch 1467, Training Loss: 66.01, Validation Loss: 74.08
2025-02-24 20:36:49,217 - Epoch 1468, Training Loss: 83.59, Validation Loss: 74.06
2025-02-24 20:36:49,376 - Epoch 1469, Training Loss: 72.15, Validation Loss: 74.05
2025-02-24 20:36:49,530 - Epoch 1470, Training Loss: 66.63, Validation Loss: 74.03
2025-02-24 20:36:49,684 - Epoch 1471, Training Loss: 82.52, Validation Loss: 74.00
2025-02-24 20:36:49,860 - Epoch 1472, Training Loss: 68.93, Validation Loss: 74.02
2025-02-24 20:36:50,014 - Epoch 1473, Training Loss: 69.49, Validation Loss: 74.01
2025-02-24 20:36:50,175 - Epoch 1474, Training Loss: 78.83, Validation Loss: 74.02
2025-02-24 20:36:50,335 - Epoch 1475, Training Loss: 72.99, Validation Loss: 74.00
2025-02-24 20:36:50,532 - Epoch 1476, Training Loss: 79.26, Validation Loss: 73.98
2025-02-24 20:36:50,730 - Epoch 1477, Training Loss: 69.58, Validation Loss: 74.00
2025-02-24 20:36:50,893 - Epoch 1478, Training Loss: 74.27, Validation Loss: 73.98
2025-02-24 20:36:51,049 - Epoch 1479, Training Loss: 64.32, Validation Loss: 73.98
2025-02-24 20:36:51,209 - Epoch 1480, Training Loss: 75.19, Validation Loss: 73.96
2025-02-24 20:36:51,390 - Epoch 1481, Training Loss: 89.87, Validation Loss: 73.93
2025-02-24 20:36:51,575 - Epoch 1482, Training Loss: 70.41, Validation Loss: 73.94
2025-02-24 20:36:51,744 - Epoch 1483, Training Loss: 80.72, Validation Loss: 73.90
2025-02-24 20:36:51,916 - Epoch 1484, Training Loss: 75.10, Validation Loss: 73.88
2025-02-24 20:36:52,090 - Epoch 1485, Training Loss: 70.15, Validation Loss: 73.87
2025-02-24 20:36:52,264 - Epoch 1486, Training Loss: 82.14, Validation Loss: 73.85
2025-02-24 20:36:52,447 - Epoch 1487, Training Loss: 71.88, Validation Loss: 73.85
2025-02-24 20:36:52,611 - Epoch 1488, Training Loss: 76.38, Validation Loss: 73.86
2025-02-24 20:36:52,785 - Epoch 1489, Training Loss: 75.68, Validation Loss: 73.84
2025-02-24 20:36:52,960 - Epoch 1490, Training Loss: 72.28, Validation Loss: 73.83
2025-02-24 20:36:53,154 - Epoch 1491, Training Loss: 79.84, Validation Loss: 73.80
2025-02-24 20:36:53,345 - Epoch 1492, Training Loss: 79.67, Validation Loss: 73.77
2025-02-24 20:36:53,534 - Epoch 1493, Training Loss: 77.74, Validation Loss: 73.75
2025-02-24 20:36:53,747 - Epoch 1494, Training Loss: 75.06, Validation Loss: 73.75
2025-02-24 20:36:53,973 - Epoch 1495, Training Loss: 72.33, Validation Loss: 73.75
2025-02-24 20:36:54,151 - Epoch 1496, Training Loss: 72.84, Validation Loss: 73.76
2025-02-24 20:36:54,333 - Epoch 1497, Training Loss: 67.31, Validation Loss: 73.75
2025-02-24 20:36:54,528 - Epoch 1498, Training Loss: 73.52, Validation Loss: 73.72
2025-02-24 20:36:54,734 - Epoch 1499, Training Loss: 75.84, Validation Loss: 73.73
2025-02-24 20:36:54,906 - Epoch 1500, Training Loss: 69.14, Validation Loss: 73.73
2025-02-24 20:36:55,076 - Epoch 1501, Training Loss: 70.95, Validation Loss: 73.72
2025-02-24 20:36:55,277 - Epoch 1502, Training Loss: 69.40, Validation Loss: 73.71
2025-02-24 20:36:55,466 - Epoch 1503, Training Loss: 81.56, Validation Loss: 73.69
2025-02-24 20:36:55,730 - Epoch 1504, Training Loss: 69.42, Validation Loss: 73.68
2025-02-24 20:36:55,932 - Epoch 1505, Training Loss: 72.98, Validation Loss: 73.65
2025-02-24 20:36:56,137 - Epoch 1506, Training Loss: 70.48, Validation Loss: 73.65
2025-02-24 20:36:56,332 - Epoch 1507, Training Loss: 68.49, Validation Loss: 73.65
2025-02-24 20:36:56,502 - Epoch 1508, Training Loss: 76.72, Validation Loss: 73.63
2025-02-24 20:36:56,702 - Epoch 1509, Training Loss: 79.64, Validation Loss: 73.63
2025-02-24 20:36:56,869 - Epoch 1510, Training Loss: 67.80, Validation Loss: 73.64
2025-02-24 20:36:57,033 - Epoch 1511, Training Loss: 76.80, Validation Loss: 73.62
2025-02-24 20:36:57,231 - Epoch 1512, Training Loss: 71.89, Validation Loss: 73.61
2025-02-24 20:36:57,418 - Epoch 1513, Training Loss: 67.84, Validation Loss: 73.59
2025-02-24 20:36:57,613 - Epoch 1514, Training Loss: 81.82, Validation Loss: 73.58
2025-02-24 20:36:57,814 - Epoch 1515, Training Loss: 69.96, Validation Loss: 73.58
2025-02-24 20:36:58,009 - Epoch 1516, Training Loss: 74.53, Validation Loss: 73.57
2025-02-24 20:36:58,214 - Epoch 1517, Training Loss: 70.95, Validation Loss: 73.58
2025-02-24 20:36:58,416 - Epoch 1518, Training Loss: 70.13, Validation Loss: 73.59
2025-02-24 20:36:58,594 - Epoch 1519, Training Loss: 76.68, Validation Loss: 73.56
2025-02-24 20:36:58,806 - Epoch 1520, Training Loss: 69.33, Validation Loss: 73.59
2025-02-24 20:36:58,966 - Epoch 1521, Training Loss: 74.22, Validation Loss: 73.58
2025-02-24 20:36:59,144 - Epoch 1522, Training Loss: 75.40, Validation Loss: 73.56
2025-02-24 20:36:59,332 - Epoch 1523, Training Loss: 70.21, Validation Loss: 73.57
2025-02-24 20:36:59,489 - Epoch 1524, Training Loss: 70.29, Validation Loss: 73.55
2025-02-24 20:36:59,670 - Epoch 1525, Training Loss: 72.24, Validation Loss: 73.56
2025-02-24 20:36:59,835 - Epoch 1526, Training Loss: 78.90, Validation Loss: 73.54
2025-02-24 20:37:00,020 - Epoch 1527, Training Loss: 76.85, Validation Loss: 73.55
2025-02-24 20:37:00,185 - Epoch 1528, Training Loss: 76.11, Validation Loss: 73.55
2025-02-24 20:37:00,349 - Epoch 1529, Training Loss: 69.31, Validation Loss: 73.54
2025-02-24 20:37:00,530 - Epoch 1530, Training Loss: 67.34, Validation Loss: 73.54
2025-02-24 20:37:00,693 - Epoch 1531, Training Loss: 68.50, Validation Loss: 73.52
2025-02-24 20:37:00,897 - Epoch 1532, Training Loss: 88.13, Validation Loss: 73.50
2025-02-24 20:37:01,092 - Epoch 1533, Training Loss: 80.46, Validation Loss: 73.49
2025-02-24 20:37:01,281 - Epoch 1534, Training Loss: 68.10, Validation Loss: 73.49
2025-02-24 20:37:01,448 - Epoch 1535, Training Loss: 74.92, Validation Loss: 73.47
2025-02-24 20:37:01,634 - Epoch 1536, Training Loss: 83.12, Validation Loss: 73.45
2025-02-24 20:37:01,824 - Epoch 1537, Training Loss: 68.88, Validation Loss: 73.44
2025-02-24 20:37:02,010 - Epoch 1538, Training Loss: 69.71, Validation Loss: 73.47
2025-02-24 20:37:02,170 - Epoch 1539, Training Loss: 82.84, Validation Loss: 73.45
2025-02-24 20:37:02,328 - Epoch 1540, Training Loss: 78.78, Validation Loss: 73.42
2025-02-24 20:37:02,508 - Epoch 1541, Training Loss: 72.35, Validation Loss: 73.42
2025-02-24 20:37:02,697 - Epoch 1542, Training Loss: 84.70, Validation Loss: 73.39
2025-02-24 20:37:02,877 - Epoch 1543, Training Loss: 71.80, Validation Loss: 73.38
2025-02-24 20:37:03,054 - Epoch 1544, Training Loss: 70.56, Validation Loss: 73.38
2025-02-24 20:37:03,249 - Epoch 1545, Training Loss: 77.26, Validation Loss: 73.40
2025-02-24 20:37:03,410 - Epoch 1546, Training Loss: 81.15, Validation Loss: 73.40
2025-02-24 20:37:03,569 - Epoch 1547, Training Loss: 66.11, Validation Loss: 73.41
2025-02-24 20:37:03,732 - Epoch 1548, Training Loss: 70.90, Validation Loss: 73.43
2025-02-24 20:37:03,886 - Epoch 1549, Training Loss: 71.88, Validation Loss: 73.44
2025-02-24 20:37:04,042 - Epoch 1550, Training Loss: 80.08, Validation Loss: 73.41
2025-02-24 20:37:04,214 - Epoch 1551, Training Loss: 71.41, Validation Loss: 73.41
2025-02-24 20:37:04,370 - Epoch 1552, Training Loss: 83.36, Validation Loss: 73.40
2025-02-24 20:37:04,540 - Epoch 1553, Training Loss: 69.99, Validation Loss: 73.41
2025-02-24 20:37:04,702 - Epoch 1554, Training Loss: 69.77, Validation Loss: 73.40
2025-02-24 20:37:04,859 - Epoch 1555, Training Loss: 68.12, Validation Loss: 73.40
2025-02-24 20:37:05,023 - Epoch 1556, Training Loss: 72.81, Validation Loss: 73.38
2025-02-24 20:37:05,207 - Epoch 1557, Training Loss: 72.93, Validation Loss: 73.34
2025-02-24 20:37:05,390 - Epoch 1558, Training Loss: 72.52, Validation Loss: 73.34
2025-02-24 20:37:05,585 - Epoch 1559, Training Loss: 70.56, Validation Loss: 73.34
2025-02-24 20:37:05,782 - Epoch 1560, Training Loss: 79.24, Validation Loss: 73.30
2025-02-24 20:37:05,963 - Epoch 1561, Training Loss: 74.50, Validation Loss: 73.27
2025-02-24 20:37:06,147 - Epoch 1562, Training Loss: 78.16, Validation Loss: 73.25
2025-02-24 20:37:06,343 - Epoch 1563, Training Loss: 66.88, Validation Loss: 73.23
2025-02-24 20:37:06,528 - Epoch 1564, Training Loss: 79.12, Validation Loss: 73.22
2025-02-24 20:37:06,716 - Epoch 1565, Training Loss: 84.42, Validation Loss: 73.20
2025-02-24 20:37:06,887 - Epoch 1566, Training Loss: 81.90, Validation Loss: 73.17
2025-02-24 20:37:07,066 - Epoch 1567, Training Loss: 80.55, Validation Loss: 73.17
2025-02-24 20:37:07,230 - Epoch 1568, Training Loss: 72.56, Validation Loss: 73.17
2025-02-24 20:37:07,398 - Epoch 1569, Training Loss: 72.51, Validation Loss: 73.15
2025-02-24 20:37:07,581 - Epoch 1570, Training Loss: 79.02, Validation Loss: 73.12
2025-02-24 20:37:07,768 - Epoch 1571, Training Loss: 69.02, Validation Loss: 73.12
2025-02-24 20:37:07,949 - Epoch 1572, Training Loss: 82.29, Validation Loss: 73.08
2025-02-24 20:37:08,137 - Epoch 1573, Training Loss: 68.26, Validation Loss: 73.10
2025-02-24 20:37:08,309 - Epoch 1574, Training Loss: 66.67, Validation Loss: 73.11
2025-02-24 20:37:08,467 - Epoch 1575, Training Loss: 80.55, Validation Loss: 73.10
2025-02-24 20:37:08,641 - Epoch 1576, Training Loss: 69.08, Validation Loss: 73.10
2025-02-24 20:37:08,805 - Epoch 1577, Training Loss: 67.65, Validation Loss: 73.09
2025-02-24 20:37:08,980 - Epoch 1578, Training Loss: 74.46, Validation Loss: 73.09
2025-02-24 20:37:09,135 - Epoch 1579, Training Loss: 79.36, Validation Loss: 73.09
2025-02-24 20:37:09,298 - Epoch 1580, Training Loss: 72.40, Validation Loss: 73.07
2025-02-24 20:37:09,476 - Epoch 1581, Training Loss: 76.39, Validation Loss: 73.06
2025-02-24 20:37:09,661 - Epoch 1582, Training Loss: 78.65, Validation Loss: 73.05
2025-02-24 20:37:09,833 - Epoch 1583, Training Loss: 68.53, Validation Loss: 73.05
2025-02-24 20:37:09,995 - Epoch 1584, Training Loss: 80.37, Validation Loss: 73.02
2025-02-24 20:37:10,172 - Epoch 1585, Training Loss: 72.46, Validation Loss: 73.02
2025-02-24 20:37:10,334 - Epoch 1586, Training Loss: 64.45, Validation Loss: 73.02
2025-02-24 20:37:10,559 - Epoch 1587, Training Loss: 74.97, Validation Loss: 73.00
2025-02-24 20:37:10,760 - Epoch 1588, Training Loss: 74.21, Validation Loss: 72.99
2025-02-24 20:37:10,948 - Epoch 1589, Training Loss: 80.80, Validation Loss: 72.94
2025-02-24 20:37:11,140 - Epoch 1590, Training Loss: 70.60, Validation Loss: 72.92
2025-02-24 20:37:11,319 - Epoch 1591, Training Loss: 71.09, Validation Loss: 72.91
2025-02-24 20:37:11,505 - Epoch 1592, Training Loss: 82.59, Validation Loss: 72.89
2025-02-24 20:37:11,682 - Epoch 1593, Training Loss: 69.85, Validation Loss: 72.87
2025-02-24 20:37:11,870 - Epoch 1594, Training Loss: 77.26, Validation Loss: 72.86
2025-02-24 20:37:12,050 - Epoch 1595, Training Loss: 81.97, Validation Loss: 72.83
2025-02-24 20:37:12,236 - Epoch 1596, Training Loss: 74.27, Validation Loss: 72.85
2025-02-24 20:37:12,398 - Epoch 1597, Training Loss: 67.14, Validation Loss: 72.84
2025-02-24 20:37:12,550 - Epoch 1598, Training Loss: 69.52, Validation Loss: 72.83
2025-02-24 20:37:12,729 - Epoch 1599, Training Loss: 68.29, Validation Loss: 72.82
2025-02-24 20:37:12,912 - Epoch 1600, Training Loss: 69.70, Validation Loss: 72.80
2025-02-24 20:37:13,113 - Epoch 1601, Training Loss: 70.63, Validation Loss: 72.80
2025-02-24 20:37:13,299 - Epoch 1602, Training Loss: 71.96, Validation Loss: 72.82
2025-02-24 20:37:13,459 - Epoch 1603, Training Loss: 69.76, Validation Loss: 72.83
2025-02-24 20:37:13,618 - Epoch 1604, Training Loss: 74.51, Validation Loss: 72.81
2025-02-24 20:37:13,784 - Epoch 1605, Training Loss: 80.72, Validation Loss: 72.81
2025-02-24 20:37:13,948 - Epoch 1606, Training Loss: 70.70, Validation Loss: 72.82
2025-02-24 20:37:14,110 - Epoch 1607, Training Loss: 91.92, Validation Loss: 72.80
2025-02-24 20:37:14,322 - Epoch 1608, Training Loss: 73.79, Validation Loss: 72.80
2025-02-24 20:37:14,481 - Epoch 1609, Training Loss: 68.64, Validation Loss: 72.80
2025-02-24 20:37:14,670 - Epoch 1610, Training Loss: 73.82, Validation Loss: 72.78
2025-02-24 20:37:14,852 - Epoch 1611, Training Loss: 77.07, Validation Loss: 72.79
2025-02-24 20:37:15,017 - Epoch 1612, Training Loss: 87.75, Validation Loss: 72.75
2025-02-24 20:37:15,210 - Epoch 1613, Training Loss: 69.11, Validation Loss: 72.76
2025-02-24 20:37:15,369 - Epoch 1614, Training Loss: 81.91, Validation Loss: 72.73
2025-02-24 20:37:15,562 - Epoch 1615, Training Loss: 72.13, Validation Loss: 72.72
2025-02-24 20:37:15,753 - Epoch 1616, Training Loss: 68.61, Validation Loss: 72.71
2025-02-24 20:37:15,948 - Epoch 1617, Training Loss: 66.05, Validation Loss: 72.71
2025-02-24 20:37:16,145 - Epoch 1618, Training Loss: 86.07, Validation Loss: 72.68
2025-02-24 20:37:16,333 - Epoch 1619, Training Loss: 74.34, Validation Loss: 72.69
2025-02-24 20:37:16,520 - Epoch 1620, Training Loss: 75.71, Validation Loss: 72.68
2025-02-24 20:37:16,673 - Epoch 1621, Training Loss: 78.88, Validation Loss: 72.65
2025-02-24 20:37:16,860 - Epoch 1622, Training Loss: 71.20, Validation Loss: 72.64
2025-02-24 20:37:17,048 - Epoch 1623, Training Loss: 77.57, Validation Loss: 72.63
2025-02-24 20:37:17,241 - Epoch 1624, Training Loss: 83.20, Validation Loss: 72.61
2025-02-24 20:37:17,424 - Epoch 1625, Training Loss: 74.50, Validation Loss: 72.60
2025-02-24 20:37:17,609 - Epoch 1626, Training Loss: 74.95, Validation Loss: 72.59
2025-02-24 20:37:17,797 - Epoch 1627, Training Loss: 69.01, Validation Loss: 72.57
2025-02-24 20:37:17,986 - Epoch 1628, Training Loss: 76.62, Validation Loss: 72.57
2025-02-24 20:37:18,167 - Epoch 1629, Training Loss: 76.87, Validation Loss: 72.58
2025-02-24 20:37:18,348 - Epoch 1630, Training Loss: 66.67, Validation Loss: 72.59
2025-02-24 20:37:18,511 - Epoch 1631, Training Loss: 82.91, Validation Loss: 72.57
2025-02-24 20:37:18,698 - Epoch 1632, Training Loss: 70.69, Validation Loss: 72.57
2025-02-24 20:37:18,856 - Epoch 1633, Training Loss: 82.30, Validation Loss: 72.54
2025-02-24 20:37:19,034 - Epoch 1634, Training Loss: 72.13, Validation Loss: 72.53
2025-02-24 20:37:19,219 - Epoch 1635, Training Loss: 82.90, Validation Loss: 72.52
2025-02-24 20:37:19,428 - Epoch 1636, Training Loss: 68.83, Validation Loss: 72.51
2025-02-24 20:37:19,606 - Epoch 1637, Training Loss: 86.75, Validation Loss: 72.47
2025-02-24 20:37:19,796 - Epoch 1638, Training Loss: 67.12, Validation Loss: 72.48
2025-02-24 20:37:19,955 - Epoch 1639, Training Loss: 68.91, Validation Loss: 72.48
2025-02-24 20:37:20,120 - Epoch 1640, Training Loss: 79.34, Validation Loss: 72.45
2025-02-24 20:37:20,295 - Epoch 1641, Training Loss: 70.20, Validation Loss: 72.47
2025-02-24 20:37:20,456 - Epoch 1642, Training Loss: 67.05, Validation Loss: 72.47
2025-02-24 20:37:20,611 - Epoch 1643, Training Loss: 83.28, Validation Loss: 72.47
2025-02-24 20:37:20,769 - Epoch 1644, Training Loss: 66.19, Validation Loss: 72.49
2025-02-24 20:37:20,926 - Epoch 1645, Training Loss: 83.75, Validation Loss: 72.48
2025-02-24 20:37:21,084 - Epoch 1646, Training Loss: 74.08, Validation Loss: 72.48
2025-02-24 20:37:21,237 - Epoch 1647, Training Loss: 85.41, Validation Loss: 72.48
2025-02-24 20:37:21,413 - Epoch 1648, Training Loss: 69.82, Validation Loss: 72.48
2025-02-24 20:37:21,586 - Epoch 1649, Training Loss: 67.25, Validation Loss: 72.46
2025-02-24 20:37:21,750 - Epoch 1650, Training Loss: 70.23, Validation Loss: 72.47
2025-02-24 20:37:21,904 - Epoch 1651, Training Loss: 68.08, Validation Loss: 72.48
2025-02-24 20:37:22,065 - Epoch 1652, Training Loss: 93.63, Validation Loss: 72.45
2025-02-24 20:37:22,239 - Epoch 1653, Training Loss: 79.54, Validation Loss: 72.45
2025-02-24 20:37:22,409 - Epoch 1654, Training Loss: 76.03, Validation Loss: 72.44
2025-02-24 20:37:22,586 - Epoch 1655, Training Loss: 75.53, Validation Loss: 72.43
2025-02-24 20:37:22,772 - Epoch 1656, Training Loss: 75.50, Validation Loss: 72.43
2025-02-24 20:37:22,970 - Epoch 1657, Training Loss: 70.54, Validation Loss: 72.42
2025-02-24 20:37:23,162 - Epoch 1658, Training Loss: 67.44, Validation Loss: 72.43
2025-02-24 20:37:23,328 - Epoch 1659, Training Loss: 76.44, Validation Loss: 72.40
2025-02-24 20:37:23,517 - Epoch 1660, Training Loss: 66.51, Validation Loss: 72.40
2025-02-24 20:37:23,708 - Epoch 1661, Training Loss: 71.64, Validation Loss: 72.39
2025-02-24 20:37:23,908 - Epoch 1662, Training Loss: 72.23, Validation Loss: 72.40
2025-02-24 20:37:24,061 - Epoch 1663, Training Loss: 77.17, Validation Loss: 72.37
2025-02-24 20:37:24,243 - Epoch 1664, Training Loss: 68.07, Validation Loss: 72.37
2025-02-24 20:37:24,417 - Epoch 1665, Training Loss: 84.00, Validation Loss: 72.34
2025-02-24 20:37:24,605 - Epoch 1666, Training Loss: 72.31, Validation Loss: 72.33
2025-02-24 20:37:24,790 - Epoch 1667, Training Loss: 78.70, Validation Loss: 72.34
2025-02-24 20:37:24,952 - Epoch 1668, Training Loss: 69.34, Validation Loss: 72.34
2025-02-24 20:37:25,130 - Epoch 1669, Training Loss: 68.10, Validation Loss: 72.34
2025-02-24 20:37:25,308 - Epoch 1670, Training Loss: 84.67, Validation Loss: 72.30
2025-02-24 20:37:25,498 - Epoch 1671, Training Loss: 69.25, Validation Loss: 72.32
2025-02-24 20:37:25,672 - Epoch 1672, Training Loss: 72.01, Validation Loss: 72.33
2025-02-24 20:37:25,830 - Epoch 1673, Training Loss: 71.13, Validation Loss: 72.33
2025-02-24 20:37:25,987 - Epoch 1674, Training Loss: 78.49, Validation Loss: 72.32
2025-02-24 20:37:26,142 - Epoch 1675, Training Loss: 73.04, Validation Loss: 72.34
2025-02-24 20:37:26,299 - Epoch 1676, Training Loss: 69.68, Validation Loss: 72.33
2025-02-24 20:37:26,452 - Epoch 1677, Training Loss: 73.35, Validation Loss: 72.34
2025-02-24 20:37:26,614 - Epoch 1678, Training Loss: 69.41, Validation Loss: 72.33
2025-02-24 20:37:26,780 - Epoch 1679, Training Loss: 77.62, Validation Loss: 72.33
2025-02-24 20:37:26,944 - Epoch 1680, Training Loss: 72.54, Validation Loss: 72.32
2025-02-24 20:37:27,094 - Epoch 1681, Training Loss: 75.37, Validation Loss: 72.33
2025-02-24 20:37:27,248 - Epoch 1682, Training Loss: 65.02, Validation Loss: 72.33
2025-02-24 20:37:27,402 - Epoch 1683, Training Loss: 86.58, Validation Loss: 72.30
2025-02-24 20:37:27,581 - Epoch 1684, Training Loss: 70.02, Validation Loss: 72.30
2025-02-24 20:37:27,761 - Epoch 1685, Training Loss: 75.58, Validation Loss: 72.30
2025-02-24 20:37:27,943 - Epoch 1686, Training Loss: 68.39, Validation Loss: 72.29
2025-02-24 20:37:28,126 - Epoch 1687, Training Loss: 66.09, Validation Loss: 72.29
2025-02-24 20:37:28,310 - Epoch 1688, Training Loss: 76.75, Validation Loss: 72.26
2025-02-24 20:37:28,493 - Epoch 1689, Training Loss: 71.16, Validation Loss: 72.25
2025-02-24 20:37:28,686 - Epoch 1690, Training Loss: 74.00, Validation Loss: 72.25
2025-02-24 20:37:28,838 - Epoch 1691, Training Loss: 68.75, Validation Loss: 72.27
2025-02-24 20:37:28,997 - Epoch 1692, Training Loss: 72.54, Validation Loss: 72.24
2025-02-24 20:37:29,227 - Epoch 1693, Training Loss: 75.31, Validation Loss: 72.23
2025-02-24 20:37:29,445 - Epoch 1694, Training Loss: 69.75, Validation Loss: 72.21
2025-02-24 20:37:29,674 - Epoch 1695, Training Loss: 68.22, Validation Loss: 72.21
2025-02-24 20:37:29,869 - Epoch 1696, Training Loss: 79.30, Validation Loss: 72.19
2025-02-24 20:37:30,070 - Epoch 1697, Training Loss: 66.63, Validation Loss: 72.18
2025-02-24 20:37:30,258 - Epoch 1698, Training Loss: 78.36, Validation Loss: 72.18
2025-02-24 20:37:30,425 - Epoch 1699, Training Loss: 66.28, Validation Loss: 72.19
2025-02-24 20:37:30,586 - Epoch 1700, Training Loss: 68.47, Validation Loss: 72.19
2025-02-24 20:37:30,792 - Epoch 1701, Training Loss: 74.48, Validation Loss: 72.19
2025-02-24 20:37:31,049 - Epoch 1702, Training Loss: 68.25, Validation Loss: 72.19
2025-02-24 20:37:31,248 - Epoch 1703, Training Loss: 67.63, Validation Loss: 72.17
2025-02-24 20:37:31,453 - Epoch 1704, Training Loss: 72.82, Validation Loss: 72.15
2025-02-24 20:37:31,668 - Epoch 1705, Training Loss: 84.25, Validation Loss: 72.13
2025-02-24 20:37:31,865 - Epoch 1706, Training Loss: 70.35, Validation Loss: 72.14
2025-02-24 20:37:32,045 - Epoch 1707, Training Loss: 69.78, Validation Loss: 72.14
2025-02-24 20:37:32,216 - Epoch 1708, Training Loss: 77.39, Validation Loss: 72.13
2025-02-24 20:37:32,415 - Epoch 1709, Training Loss: 69.14, Validation Loss: 72.17
2025-02-24 20:37:32,582 - Epoch 1710, Training Loss: 86.58, Validation Loss: 72.14
2025-02-24 20:37:32,753 - Epoch 1711, Training Loss: 77.89, Validation Loss: 72.12
2025-02-24 20:37:32,943 - Epoch 1712, Training Loss: 75.89, Validation Loss: 72.13
2025-02-24 20:37:33,117 - Epoch 1713, Training Loss: 67.43, Validation Loss: 72.14
2025-02-24 20:37:33,284 - Epoch 1714, Training Loss: 76.75, Validation Loss: 72.14
2025-02-24 20:37:33,462 - Epoch 1715, Training Loss: 83.76, Validation Loss: 72.13
2025-02-24 20:37:33,633 - Epoch 1716, Training Loss: 80.15, Validation Loss: 72.11
2025-02-24 20:37:33,826 - Epoch 1717, Training Loss: 79.17, Validation Loss: 72.11
2025-02-24 20:37:34,014 - Epoch 1718, Training Loss: 80.06, Validation Loss: 72.09
2025-02-24 20:37:34,211 - Epoch 1719, Training Loss: 71.65, Validation Loss: 72.08
2025-02-24 20:37:34,409 - Epoch 1720, Training Loss: 64.07, Validation Loss: 72.08
2025-02-24 20:37:34,611 - Epoch 1721, Training Loss: 89.23, Validation Loss: 72.04
2025-02-24 20:37:34,829 - Epoch 1722, Training Loss: 68.51, Validation Loss: 72.04
2025-02-24 20:37:35,112 - Epoch 1723, Training Loss: 70.77, Validation Loss: 72.04
2025-02-24 20:37:35,288 - Epoch 1724, Training Loss: 66.80, Validation Loss: 72.05
2025-02-24 20:37:35,461 - Epoch 1725, Training Loss: 71.23, Validation Loss: 72.03
2025-02-24 20:37:35,647 - Epoch 1726, Training Loss: 68.12, Validation Loss: 72.04
2025-02-24 20:37:35,813 - Epoch 1727, Training Loss: 75.81, Validation Loss: 72.04
2025-02-24 20:37:35,975 - Epoch 1728, Training Loss: 75.43, Validation Loss: 72.05
2025-02-24 20:37:36,143 - Epoch 1729, Training Loss: 75.02, Validation Loss: 72.04
2025-02-24 20:37:36,308 - Epoch 1730, Training Loss: 68.82, Validation Loss: 72.02
2025-02-24 20:37:36,493 - Epoch 1731, Training Loss: 72.37, Validation Loss: 72.01
2025-02-24 20:37:36,682 - Epoch 1732, Training Loss: 78.64, Validation Loss: 72.02
2025-02-24 20:37:36,852 - Epoch 1733, Training Loss: 66.45, Validation Loss: 72.03
2025-02-24 20:37:37,013 - Epoch 1734, Training Loss: 68.54, Validation Loss: 72.03
2025-02-24 20:37:37,178 - Epoch 1735, Training Loss: 68.97, Validation Loss: 72.04
2025-02-24 20:37:37,348 - Epoch 1736, Training Loss: 80.11, Validation Loss: 72.00
2025-02-24 20:37:37,541 - Epoch 1737, Training Loss: 65.48, Validation Loss: 71.99
2025-02-24 20:37:37,724 - Epoch 1738, Training Loss: 69.17, Validation Loss: 72.01
2025-02-24 20:37:37,895 - Epoch 1739, Training Loss: 70.46, Validation Loss: 72.01
2025-02-24 20:37:38,059 - Epoch 1740, Training Loss: 71.18, Validation Loss: 72.03
2025-02-24 20:37:38,233 - Epoch 1741, Training Loss: 81.45, Validation Loss: 72.02
2025-02-24 20:37:38,393 - Epoch 1742, Training Loss: 71.53, Validation Loss: 72.00
2025-02-24 20:37:38,557 - Epoch 1743, Training Loss: 77.58, Validation Loss: 71.99
2025-02-24 20:37:38,743 - Epoch 1744, Training Loss: 72.59, Validation Loss: 71.99
2025-02-24 20:37:38,917 - Epoch 1745, Training Loss: 73.20, Validation Loss: 72.00
2025-02-24 20:37:39,078 - Epoch 1746, Training Loss: 70.87, Validation Loss: 72.00
2025-02-24 20:37:39,245 - Epoch 1747, Training Loss: 78.71, Validation Loss: 71.99
2025-02-24 20:37:39,410 - Epoch 1748, Training Loss: 70.04, Validation Loss: 71.98
2025-02-24 20:37:39,600 - Epoch 1749, Training Loss: 82.44, Validation Loss: 71.95
2025-02-24 20:37:39,790 - Epoch 1750, Training Loss: 71.41, Validation Loss: 71.96
2025-02-24 20:37:39,959 - Epoch 1751, Training Loss: 68.44, Validation Loss: 71.96
2025-02-24 20:37:40,118 - Epoch 1752, Training Loss: 68.09, Validation Loss: 71.96
2025-02-24 20:37:40,282 - Epoch 1753, Training Loss: 67.63, Validation Loss: 71.97
2025-02-24 20:37:40,450 - Epoch 1754, Training Loss: 83.31, Validation Loss: 71.97
2025-02-24 20:37:40,615 - Epoch 1755, Training Loss: 77.87, Validation Loss: 71.97
2025-02-24 20:37:40,776 - Epoch 1756, Training Loss: 69.26, Validation Loss: 71.96
2025-02-24 20:37:40,942 - Epoch 1757, Training Loss: 70.83, Validation Loss: 71.96
2025-02-24 20:37:41,099 - Epoch 1758, Training Loss: 77.25, Validation Loss: 71.95
2025-02-24 20:37:41,292 - Epoch 1759, Training Loss: 75.73, Validation Loss: 71.93
2025-02-24 20:37:41,482 - Epoch 1760, Training Loss: 82.19, Validation Loss: 71.91
2025-02-24 20:37:41,669 - Epoch 1761, Training Loss: 76.64, Validation Loss: 71.91
2025-02-24 20:37:41,832 - Epoch 1762, Training Loss: 77.06, Validation Loss: 71.91
2025-02-24 20:37:42,018 - Epoch 1763, Training Loss: 77.48, Validation Loss: 71.88
2025-02-24 20:37:42,208 - Epoch 1764, Training Loss: 85.89, Validation Loss: 71.85
2025-02-24 20:37:42,398 - Epoch 1765, Training Loss: 69.39, Validation Loss: 71.84
2025-02-24 20:37:42,580 - Epoch 1766, Training Loss: 70.77, Validation Loss: 71.85
2025-02-24 20:37:42,746 - Epoch 1767, Training Loss: 70.56, Validation Loss: 71.85
2025-02-24 20:37:42,914 - Epoch 1768, Training Loss: 76.56, Validation Loss: 71.82
2025-02-24 20:37:43,104 - Epoch 1769, Training Loss: 88.12, Validation Loss: 71.78
2025-02-24 20:37:43,352 - Epoch 1770, Training Loss: 66.22, Validation Loss: 71.79
2025-02-24 20:37:43,528 - Epoch 1771, Training Loss: 81.72, Validation Loss: 71.76
2025-02-24 20:37:43,719 - Epoch 1772, Training Loss: 71.86, Validation Loss: 71.75
2025-02-24 20:37:43,901 - Epoch 1773, Training Loss: 69.71, Validation Loss: 71.77
2025-02-24 20:37:44,062 - Epoch 1774, Training Loss: 70.01, Validation Loss: 71.80
2025-02-24 20:37:44,223 - Epoch 1775, Training Loss: 69.46, Validation Loss: 71.79
2025-02-24 20:37:44,394 - Epoch 1776, Training Loss: 67.23, Validation Loss: 71.78
2025-02-24 20:37:44,553 - Epoch 1777, Training Loss: 71.37, Validation Loss: 71.75
2025-02-24 20:37:44,727 - Epoch 1778, Training Loss: 71.12, Validation Loss: 71.77
2025-02-24 20:37:44,896 - Epoch 1779, Training Loss: 67.66, Validation Loss: 71.76
2025-02-24 20:37:45,060 - Epoch 1780, Training Loss: 77.06, Validation Loss: 71.74
2025-02-24 20:37:45,244 - Epoch 1781, Training Loss: 71.39, Validation Loss: 71.75
2025-02-24 20:37:45,408 - Epoch 1782, Training Loss: 71.43, Validation Loss: 71.76
2025-02-24 20:37:45,564 - Epoch 1783, Training Loss: 67.44, Validation Loss: 71.77
2025-02-24 20:37:45,744 - Epoch 1784, Training Loss: 69.42, Validation Loss: 71.77
2025-02-24 20:37:45,898 - Epoch 1785, Training Loss: 75.46, Validation Loss: 71.76
2025-02-24 20:37:46,065 - Epoch 1786, Training Loss: 73.22, Validation Loss: 71.76
2025-02-24 20:37:46,230 - Epoch 1787, Training Loss: 78.09, Validation Loss: 71.75
2025-02-24 20:37:46,403 - Epoch 1788, Training Loss: 67.90, Validation Loss: 71.74
2025-02-24 20:37:46,586 - Epoch 1789, Training Loss: 69.48, Validation Loss: 71.73
2025-02-24 20:37:46,785 - Epoch 1790, Training Loss: 79.57, Validation Loss: 71.70
2025-02-24 20:37:46,986 - Epoch 1791, Training Loss: 77.09, Validation Loss: 71.69
2025-02-24 20:37:47,176 - Epoch 1792, Training Loss: 73.54, Validation Loss: 71.66
2025-02-24 20:37:47,367 - Epoch 1793, Training Loss: 66.52, Validation Loss: 71.66
2025-02-24 20:37:47,581 - Epoch 1794, Training Loss: 81.07, Validation Loss: 71.63
2025-02-24 20:37:47,804 - Epoch 1795, Training Loss: 73.96, Validation Loss: 71.65
2025-02-24 20:37:47,977 - Epoch 1796, Training Loss: 76.07, Validation Loss: 71.62
2025-02-24 20:37:48,178 - Epoch 1797, Training Loss: 66.16, Validation Loss: 71.62
2025-02-24 20:37:48,349 - Epoch 1798, Training Loss: 88.30, Validation Loss: 71.59
2025-02-24 20:37:48,549 - Epoch 1799, Training Loss: 76.03, Validation Loss: 71.60
2025-02-24 20:37:48,725 - Epoch 1800, Training Loss: 82.89, Validation Loss: 71.58
2025-02-24 20:37:48,928 - Epoch 1801, Training Loss: 76.12, Validation Loss: 71.58
2025-02-24 20:37:49,115 - Epoch 1802, Training Loss: 77.38, Validation Loss: 71.60
2025-02-24 20:37:49,274 - Epoch 1803, Training Loss: 65.87, Validation Loss: 71.60
2025-02-24 20:37:49,450 - Epoch 1804, Training Loss: 76.86, Validation Loss: 71.59
2025-02-24 20:37:49,646 - Epoch 1805, Training Loss: 73.80, Validation Loss: 71.59
2025-02-24 20:37:49,833 - Epoch 1806, Training Loss: 67.66, Validation Loss: 71.59
2025-02-24 20:37:50,015 - Epoch 1807, Training Loss: 79.20, Validation Loss: 71.61
2025-02-24 20:37:50,194 - Epoch 1808, Training Loss: 75.25, Validation Loss: 71.60
2025-02-24 20:37:50,371 - Epoch 1809, Training Loss: 68.43, Validation Loss: 71.58
2025-02-24 20:37:50,555 - Epoch 1810, Training Loss: 76.39, Validation Loss: 71.58
2025-02-24 20:37:50,793 - Epoch 1811, Training Loss: 72.80, Validation Loss: 71.57
2025-02-24 20:37:50,995 - Epoch 1812, Training Loss: 81.28, Validation Loss: 71.55
2025-02-24 20:37:51,197 - Epoch 1813, Training Loss: 65.88, Validation Loss: 71.57
2025-02-24 20:37:51,380 - Epoch 1814, Training Loss: 70.58, Validation Loss: 71.55
2025-02-24 20:37:51,579 - Epoch 1815, Training Loss: 73.29, Validation Loss: 71.54
2025-02-24 20:37:51,783 - Epoch 1816, Training Loss: 71.00, Validation Loss: 71.53
2025-02-24 20:37:51,986 - Epoch 1817, Training Loss: 76.55, Validation Loss: 71.51
2025-02-24 20:37:52,186 - Epoch 1818, Training Loss: 67.78, Validation Loss: 71.51
2025-02-24 20:37:52,383 - Epoch 1819, Training Loss: 68.36, Validation Loss: 71.52
2025-02-24 20:37:52,560 - Epoch 1820, Training Loss: 73.15, Validation Loss: 71.52
2025-02-24 20:37:52,730 - Epoch 1821, Training Loss: 74.71, Validation Loss: 71.50
2025-02-24 20:37:52,928 - Epoch 1822, Training Loss: 66.82, Validation Loss: 71.51
2025-02-24 20:37:53,109 - Epoch 1823, Training Loss: 70.81, Validation Loss: 71.50
2025-02-24 20:37:53,295 - Epoch 1824, Training Loss: 81.62, Validation Loss: 71.45
2025-02-24 20:37:53,511 - Epoch 1825, Training Loss: 70.89, Validation Loss: 71.47
2025-02-24 20:37:53,681 - Epoch 1826, Training Loss: 84.01, Validation Loss: 71.44
2025-02-24 20:37:53,881 - Epoch 1827, Training Loss: 66.56, Validation Loss: 71.42
2025-02-24 20:37:54,076 - Epoch 1828, Training Loss: 72.33, Validation Loss: 71.40
2025-02-24 20:37:54,276 - Epoch 1829, Training Loss: 67.11, Validation Loss: 71.39
2025-02-24 20:37:54,471 - Epoch 1830, Training Loss: 74.98, Validation Loss: 71.38
2025-02-24 20:37:54,666 - Epoch 1831, Training Loss: 67.26, Validation Loss: 71.39
2025-02-24 20:37:54,844 - Epoch 1832, Training Loss: 69.45, Validation Loss: 71.40
2025-02-24 20:37:55,011 - Epoch 1833, Training Loss: 65.21, Validation Loss: 71.42
2025-02-24 20:37:55,183 - Epoch 1834, Training Loss: 71.88, Validation Loss: 71.39
2025-02-24 20:37:55,352 - Epoch 1835, Training Loss: 81.80, Validation Loss: 71.37
2025-02-24 20:37:55,545 - Epoch 1836, Training Loss: 69.66, Validation Loss: 71.40
2025-02-24 20:37:55,710 - Epoch 1837, Training Loss: 84.33, Validation Loss: 71.38
2025-02-24 20:37:55,871 - Epoch 1838, Training Loss: 69.38, Validation Loss: 71.39
2025-02-24 20:37:56,041 - Epoch 1839, Training Loss: 76.29, Validation Loss: 71.39
2025-02-24 20:37:56,212 - Epoch 1840, Training Loss: 68.56, Validation Loss: 71.40
2025-02-24 20:37:56,368 - Epoch 1841, Training Loss: 67.31, Validation Loss: 71.39
2025-02-24 20:37:56,532 - Epoch 1842, Training Loss: 85.30, Validation Loss: 71.39
2025-02-24 20:37:56,693 - Epoch 1843, Training Loss: 71.12, Validation Loss: 71.38
2025-02-24 20:37:56,864 - Epoch 1844, Training Loss: 70.99, Validation Loss: 71.36
2025-02-24 20:37:57,047 - Epoch 1845, Training Loss: 69.69, Validation Loss: 71.36
2025-02-24 20:37:57,248 - Epoch 1846, Training Loss: 65.95, Validation Loss: 71.36
2025-02-24 20:37:57,415 - Epoch 1847, Training Loss: 66.50, Validation Loss: 71.36
2025-02-24 20:37:57,580 - Epoch 1848, Training Loss: 68.64, Validation Loss: 71.36
2025-02-24 20:37:57,747 - Epoch 1849, Training Loss: 74.29, Validation Loss: 71.33
2025-02-24 20:37:57,932 - Epoch 1850, Training Loss: 80.24, Validation Loss: 71.31
2025-02-24 20:37:58,125 - Epoch 1851, Training Loss: 77.23, Validation Loss: 71.31
2025-02-24 20:37:58,314 - Epoch 1852, Training Loss: 75.98, Validation Loss: 71.32
2025-02-24 20:37:58,479 - Epoch 1853, Training Loss: 79.15, Validation Loss: 71.31
2025-02-24 20:37:58,673 - Epoch 1854, Training Loss: 73.08, Validation Loss: 71.29
2025-02-24 20:37:58,863 - Epoch 1855, Training Loss: 67.80, Validation Loss: 71.31
2025-02-24 20:37:59,030 - Epoch 1856, Training Loss: 76.25, Validation Loss: 71.28
2025-02-24 20:37:59,211 - Epoch 1857, Training Loss: 68.70, Validation Loss: 71.29
2025-02-24 20:37:59,377 - Epoch 1858, Training Loss: 77.79, Validation Loss: 71.27
2025-02-24 20:37:59,562 - Epoch 1859, Training Loss: 65.83, Validation Loss: 71.26
2025-02-24 20:37:59,743 - Epoch 1860, Training Loss: 71.44, Validation Loss: 71.25
2025-02-24 20:37:59,934 - Epoch 1861, Training Loss: 70.64, Validation Loss: 71.25
2025-02-24 20:38:00,098 - Epoch 1862, Training Loss: 75.81, Validation Loss: 71.23
2025-02-24 20:38:00,294 - Epoch 1863, Training Loss: 65.60, Validation Loss: 71.25
2025-02-24 20:38:00,583 - Epoch 1864, Training Loss: 69.13, Validation Loss: 71.25
2025-02-24 20:38:00,769 - Epoch 1865, Training Loss: 80.84, Validation Loss: 71.25
2025-02-24 20:38:00,966 - Epoch 1866, Training Loss: 69.06, Validation Loss: 71.26
2025-02-24 20:38:01,149 - Epoch 1867, Training Loss: 69.10, Validation Loss: 71.28
2025-02-24 20:38:01,331 - Epoch 1868, Training Loss: 79.91, Validation Loss: 71.28
2025-02-24 20:38:01,507 - Epoch 1869, Training Loss: 69.20, Validation Loss: 71.30
2025-02-24 20:38:01,733 - Epoch 1870, Training Loss: 69.21, Validation Loss: 71.33
2025-02-24 20:38:01,917 - Epoch 1871, Training Loss: 76.44, Validation Loss: 71.31
2025-02-24 20:38:02,101 - Epoch 1872, Training Loss: 74.59, Validation Loss: 71.28
2025-02-24 20:38:02,278 - Epoch 1873, Training Loss: 77.61, Validation Loss: 71.28
2025-02-24 20:38:02,460 - Epoch 1874, Training Loss: 77.22, Validation Loss: 71.27
2025-02-24 20:38:02,639 - Epoch 1875, Training Loss: 72.53, Validation Loss: 71.28
2025-02-24 20:38:02,803 - Epoch 1876, Training Loss: 71.54, Validation Loss: 71.26
2025-02-24 20:38:02,964 - Epoch 1877, Training Loss: 68.85, Validation Loss: 71.24
2025-02-24 20:38:03,131 - Epoch 1878, Training Loss: 69.15, Validation Loss: 71.25
2025-02-24 20:38:03,304 - Epoch 1879, Training Loss: 69.22, Validation Loss: 71.24
2025-02-24 20:38:03,478 - Epoch 1880, Training Loss: 70.68, Validation Loss: 71.24
2025-02-24 20:38:03,644 - Epoch 1881, Training Loss: 68.68, Validation Loss: 71.22
2025-02-24 20:38:03,832 - Epoch 1882, Training Loss: 70.80, Validation Loss: 71.21
2025-02-24 20:38:04,016 - Epoch 1883, Training Loss: 71.71, Validation Loss: 71.20
2025-02-24 20:38:04,208 - Epoch 1884, Training Loss: 74.58, Validation Loss: 71.20
2025-02-24 20:38:04,378 - Epoch 1885, Training Loss: 72.17, Validation Loss: 71.19
2025-02-24 20:38:04,563 - Epoch 1886, Training Loss: 80.08, Validation Loss: 71.18
2025-02-24 20:38:04,764 - Epoch 1887, Training Loss: 74.14, Validation Loss: 71.15
2025-02-24 20:38:04,959 - Epoch 1888, Training Loss: 69.74, Validation Loss: 71.16
2025-02-24 20:38:05,121 - Epoch 1889, Training Loss: 77.33, Validation Loss: 71.17
2025-02-24 20:38:05,300 - Epoch 1890, Training Loss: 71.85, Validation Loss: 71.15
2025-02-24 20:38:05,494 - Epoch 1891, Training Loss: 71.64, Validation Loss: 71.17
2025-02-24 20:38:05,672 - Epoch 1892, Training Loss: 71.56, Validation Loss: 71.17
2025-02-24 20:38:05,844 - Epoch 1893, Training Loss: 85.62, Validation Loss: 71.16
2025-02-24 20:38:06,011 - Epoch 1894, Training Loss: 73.93, Validation Loss: 71.16
2025-02-24 20:38:06,176 - Epoch 1895, Training Loss: 69.66, Validation Loss: 71.18
2025-02-24 20:38:06,348 - Epoch 1896, Training Loss: 70.18, Validation Loss: 71.19
2025-02-24 20:38:06,513 - Epoch 1897, Training Loss: 69.23, Validation Loss: 71.19
2025-02-24 20:38:06,683 - Epoch 1898, Training Loss: 87.43, Validation Loss: 71.16
2025-02-24 20:38:06,848 - Epoch 1899, Training Loss: 68.96, Validation Loss: 71.19
2025-02-24 20:38:07,019 - Epoch 1900, Training Loss: 78.04, Validation Loss: 71.18
2025-02-24 20:38:07,182 - Epoch 1901, Training Loss: 71.30, Validation Loss: 71.17
2025-02-24 20:38:07,359 - Epoch 1902, Training Loss: 64.94, Validation Loss: 71.16
2025-02-24 20:38:07,530 - Epoch 1903, Training Loss: 84.50, Validation Loss: 71.14
2025-02-24 20:38:07,731 - Epoch 1904, Training Loss: 70.91, Validation Loss: 71.13
2025-02-24 20:38:07,920 - Epoch 1905, Training Loss: 77.97, Validation Loss: 71.12
2025-02-24 20:38:08,114 - Epoch 1906, Training Loss: 72.19, Validation Loss: 71.14
2025-02-24 20:38:08,282 - Epoch 1907, Training Loss: 74.11, Validation Loss: 71.13
2025-02-24 20:38:08,450 - Epoch 1908, Training Loss: 69.02, Validation Loss: 71.11
2025-02-24 20:38:08,660 - Epoch 1909, Training Loss: 69.94, Validation Loss: 71.12
2025-02-24 20:38:08,823 - Epoch 1910, Training Loss: 69.41, Validation Loss: 71.12
2025-02-24 20:38:09,035 - Epoch 1911, Training Loss: 73.67, Validation Loss: 71.12
2025-02-24 20:38:09,214 - Epoch 1912, Training Loss: 73.29, Validation Loss: 71.12
2025-02-24 20:38:09,387 - Epoch 1913, Training Loss: 69.56, Validation Loss: 71.11
2025-02-24 20:38:09,582 - Epoch 1914, Training Loss: 69.67, Validation Loss: 71.13
2025-02-24 20:38:09,760 - Epoch 1915, Training Loss: 71.16, Validation Loss: 71.10
2025-02-24 20:38:09,949 - Epoch 1916, Training Loss: 78.54, Validation Loss: 71.08
2025-02-24 20:38:10,142 - Epoch 1917, Training Loss: 77.34, Validation Loss: 71.07
2025-02-24 20:38:10,335 - Epoch 1918, Training Loss: 72.43, Validation Loss: 71.09
2025-02-24 20:38:10,499 - Epoch 1919, Training Loss: 73.05, Validation Loss: 71.11
2025-02-24 20:38:10,667 - Epoch 1920, Training Loss: 76.66, Validation Loss: 71.11
2025-02-24 20:38:10,828 - Epoch 1921, Training Loss: 68.89, Validation Loss: 71.09
2025-02-24 20:38:11,001 - Epoch 1922, Training Loss: 68.33, Validation Loss: 71.09
2025-02-24 20:38:11,166 - Epoch 1923, Training Loss: 69.09, Validation Loss: 71.12
2025-02-24 20:38:11,334 - Epoch 1924, Training Loss: 71.35, Validation Loss: 71.09
2025-02-24 20:38:11,497 - Epoch 1925, Training Loss: 67.42, Validation Loss: 71.09
2025-02-24 20:38:11,676 - Epoch 1926, Training Loss: 66.43, Validation Loss: 71.08
2025-02-24 20:38:11,847 - Epoch 1927, Training Loss: 69.03, Validation Loss: 71.08
2025-02-24 20:38:12,024 - Epoch 1928, Training Loss: 73.17, Validation Loss: 71.08
2025-02-24 20:38:12,193 - Epoch 1929, Training Loss: 68.13, Validation Loss: 71.07
2025-02-24 20:38:12,363 - Epoch 1930, Training Loss: 72.20, Validation Loss: 71.07
2025-02-24 20:38:12,531 - Epoch 1931, Training Loss: 72.74, Validation Loss: 71.07
2025-02-24 20:38:12,701 - Epoch 1932, Training Loss: 72.48, Validation Loss: 71.08
2025-02-24 20:38:12,866 - Epoch 1933, Training Loss: 76.25, Validation Loss: 71.06
2025-02-24 20:38:13,064 - Epoch 1934, Training Loss: 74.04, Validation Loss: 71.04
2025-02-24 20:38:13,261 - Epoch 1935, Training Loss: 81.63, Validation Loss: 71.02
2025-02-24 20:38:13,454 - Epoch 1936, Training Loss: 68.34, Validation Loss: 71.01
2025-02-24 20:38:13,639 - Epoch 1937, Training Loss: 68.68, Validation Loss: 71.01
2025-02-24 20:38:13,799 - Epoch 1938, Training Loss: 67.97, Validation Loss: 71.02
2025-02-24 20:38:13,973 - Epoch 1939, Training Loss: 88.50, Validation Loss: 70.98
2025-02-24 20:38:14,155 - Epoch 1940, Training Loss: 70.17, Validation Loss: 70.99
2025-02-24 20:38:14,315 - Epoch 1941, Training Loss: 86.44, Validation Loss: 70.96
2025-02-24 20:38:14,494 - Epoch 1942, Training Loss: 67.04, Validation Loss: 70.96
2025-02-24 20:38:14,679 - Epoch 1943, Training Loss: 70.25, Validation Loss: 70.97
2025-02-24 20:38:14,827 - Epoch 1944, Training Loss: 83.58, Validation Loss: 70.94
2025-02-24 20:38:15,016 - Epoch 1945, Training Loss: 68.08, Validation Loss: 70.93
2025-02-24 20:38:15,194 - Epoch 1946, Training Loss: 85.99, Validation Loss: 70.92
2025-02-24 20:38:15,376 - Epoch 1947, Training Loss: 78.57, Validation Loss: 70.89
2025-02-24 20:38:15,555 - Epoch 1948, Training Loss: 70.12, Validation Loss: 70.87
2025-02-24 20:38:15,743 - Epoch 1949, Training Loss: 64.57, Validation Loss: 70.88
2025-02-24 20:38:15,932 - Epoch 1950, Training Loss: 66.58, Validation Loss: 70.87
2025-02-24 20:38:16,138 - Epoch 1951, Training Loss: 70.34, Validation Loss: 70.89
2025-02-24 20:38:16,300 - Epoch 1952, Training Loss: 75.55, Validation Loss: 70.89
2025-02-24 20:38:16,469 - Epoch 1953, Training Loss: 70.54, Validation Loss: 70.89
2025-02-24 20:38:16,628 - Epoch 1954, Training Loss: 79.57, Validation Loss: 70.88
2025-02-24 20:38:16,792 - Epoch 1955, Training Loss: 76.87, Validation Loss: 70.87
2025-02-24 20:38:16,947 - Epoch 1956, Training Loss: 69.70, Validation Loss: 70.88
2025-02-24 20:38:17,102 - Epoch 1957, Training Loss: 73.46, Validation Loss: 70.90
2025-02-24 20:38:17,258 - Epoch 1958, Training Loss: 69.77, Validation Loss: 70.89
2025-02-24 20:38:17,409 - Epoch 1959, Training Loss: 68.69, Validation Loss: 70.88
2025-02-24 20:38:17,575 - Epoch 1960, Training Loss: 64.56, Validation Loss: 70.87
2025-02-24 20:38:17,730 - Epoch 1961, Training Loss: 69.77, Validation Loss: 70.88
2025-02-24 20:38:17,888 - Epoch 1962, Training Loss: 73.48, Validation Loss: 70.86
2025-02-24 20:38:18,062 - Epoch 1963, Training Loss: 75.82, Validation Loss: 70.86
2025-02-24 20:38:18,218 - Epoch 1964, Training Loss: 83.10, Validation Loss: 70.83
2025-02-24 20:38:18,405 - Epoch 1965, Training Loss: 68.24, Validation Loss: 70.81
2025-02-24 20:38:18,604 - Epoch 1966, Training Loss: 80.64, Validation Loss: 70.80
2025-02-24 20:38:18,791 - Epoch 1967, Training Loss: 76.56, Validation Loss: 70.80
2025-02-24 20:38:18,968 - Epoch 1968, Training Loss: 71.51, Validation Loss: 70.79
2025-02-24 20:38:19,150 - Epoch 1969, Training Loss: 68.22, Validation Loss: 70.79
2025-02-24 20:38:19,311 - Epoch 1970, Training Loss: 69.44, Validation Loss: 70.80
2025-02-24 20:38:19,485 - Epoch 1971, Training Loss: 77.32, Validation Loss: 70.80
2025-02-24 20:38:19,642 - Epoch 1972, Training Loss: 74.06, Validation Loss: 70.80
2025-02-24 20:38:19,793 - Epoch 1973, Training Loss: 67.23, Validation Loss: 70.80
2025-02-24 20:38:19,945 - Epoch 1974, Training Loss: 76.03, Validation Loss: 70.80
2025-02-24 20:38:20,098 - Epoch 1975, Training Loss: 68.53, Validation Loss: 70.80
2025-02-24 20:38:20,287 - Epoch 1976, Training Loss: 82.01, Validation Loss: 70.78
2025-02-24 20:38:20,468 - Epoch 1977, Training Loss: 65.95, Validation Loss: 70.78
2025-02-24 20:38:20,663 - Epoch 1978, Training Loss: 76.48, Validation Loss: 70.77
2025-02-24 20:38:20,836 - Epoch 1979, Training Loss: 67.69, Validation Loss: 70.77
2025-02-24 20:38:21,017 - Epoch 1980, Training Loss: 72.70, Validation Loss: 70.76
2025-02-24 20:38:21,193 - Epoch 1981, Training Loss: 77.78, Validation Loss: 70.76
2025-02-24 20:38:21,349 - Epoch 1982, Training Loss: 68.47, Validation Loss: 70.77
2025-02-24 20:38:21,501 - Epoch 1983, Training Loss: 75.80, Validation Loss: 70.76
2025-02-24 20:38:21,688 - Epoch 1984, Training Loss: 70.80, Validation Loss: 70.75
2025-02-24 20:38:21,855 - Epoch 1985, Training Loss: 73.80, Validation Loss: 70.72
2025-02-24 20:38:22,030 - Epoch 1986, Training Loss: 74.41, Validation Loss: 70.73
2025-02-24 20:38:22,178 - Epoch 1987, Training Loss: 72.38, Validation Loss: 70.71
2025-02-24 20:38:22,357 - Epoch 1988, Training Loss: 67.08, Validation Loss: 70.72
2025-02-24 20:38:22,512 - Epoch 1989, Training Loss: 69.06, Validation Loss: 70.71
2025-02-24 20:38:22,675 - Epoch 1990, Training Loss: 72.79, Validation Loss: 70.71
2025-02-24 20:38:22,829 - Epoch 1991, Training Loss: 70.07, Validation Loss: 70.74
2025-02-24 20:38:22,981 - Epoch 1992, Training Loss: 69.95, Validation Loss: 70.74
2025-02-24 20:38:23,135 - Epoch 1993, Training Loss: 69.89, Validation Loss: 70.73
2025-02-24 20:38:23,293 - Epoch 1994, Training Loss: 66.86, Validation Loss: 70.71
2025-02-24 20:38:23,448 - Epoch 1995, Training Loss: 77.07, Validation Loss: 70.69
2025-02-24 20:38:23,656 - Epoch 1996, Training Loss: 76.29, Validation Loss: 70.69
2025-02-24 20:38:23,811 - Epoch 1997, Training Loss: 77.07, Validation Loss: 70.68
2025-02-24 20:38:24,004 - Epoch 1998, Training Loss: 76.02, Validation Loss: 70.68
2025-02-24 20:38:24,182 - Epoch 1999, Training Loss: 67.31, Validation Loss: 70.71
2025-02-24 20:38:24,346 - Epoch 2000, Training Loss: 75.98, Validation Loss: 70.72
2025-02-24 20:38:24,621 - learning rate: 0.01
2025-02-24 20:38:24,621 - Test RMSE: 7.318987607955933, Test MAE: 1.052505612373352
2025-02-24 20:47:46,057 - -----------------------Starting training-------------------------
2025-02-24 20:47:46,057 - learning rate: 0.02
2025-02-24 20:47:46,283 - Epoch 1, Training Loss: 191.50, Validation Loss: 200.15
2025-02-24 20:47:46,509 - Epoch 2, Training Loss: 150.45, Validation Loss: 183.70
2025-02-24 20:47:46,721 - Epoch 3, Training Loss: 139.05, Validation Loss: 170.36
2025-02-24 20:47:46,932 - Epoch 4, Training Loss: 118.08, Validation Loss: 159.44
2025-02-24 20:47:47,149 - Epoch 5, Training Loss: 126.07, Validation Loss: 150.31
2025-02-24 20:47:47,364 - Epoch 6, Training Loss: 115.46, Validation Loss: 142.11
2025-02-24 20:47:47,579 - Epoch 7, Training Loss: 104.73, Validation Loss: 134.98
2025-02-24 20:47:47,794 - Epoch 8, Training Loss: 104.22, Validation Loss: 129.04
2025-02-24 20:47:48,012 - Epoch 9, Training Loss: 112.58, Validation Loss: 123.35
2025-02-24 20:47:48,234 - Epoch 10, Training Loss: 108.90, Validation Loss: 117.99
2025-02-24 20:47:48,459 - Epoch 11, Training Loss: 104.25, Validation Loss: 113.46
2025-02-24 20:47:48,684 - Epoch 12, Training Loss: 93.98, Validation Loss: 109.49
2025-02-24 20:47:48,917 - Epoch 13, Training Loss: 89.72, Validation Loss: 106.18
2025-02-24 20:47:49,130 - Epoch 14, Training Loss: 80.34, Validation Loss: 103.47
2025-02-24 20:47:49,351 - Epoch 15, Training Loss: 98.55, Validation Loss: 101.14
2025-02-24 20:47:49,564 - Epoch 16, Training Loss: 80.02, Validation Loss: 98.49
2025-02-24 20:47:49,785 - Epoch 17, Training Loss: 110.49, Validation Loss: 96.28
2025-02-24 20:47:50,000 - Epoch 18, Training Loss: 90.94, Validation Loss: 93.56
2025-02-24 20:47:50,234 - Epoch 19, Training Loss: 78.36, Validation Loss: 91.37
2025-02-24 20:47:50,447 - Epoch 20, Training Loss: 82.63, Validation Loss: 89.66
2025-02-24 20:47:50,658 - Epoch 21, Training Loss: 81.00, Validation Loss: 87.98
2025-02-24 20:47:50,879 - Epoch 22, Training Loss: 78.53, Validation Loss: 86.26
2025-02-24 20:47:51,098 - Epoch 23, Training Loss: 75.83, Validation Loss: 84.83
2025-02-24 20:47:51,322 - Epoch 24, Training Loss: 78.25, Validation Loss: 83.62
2025-02-24 20:47:51,542 - Epoch 25, Training Loss: 78.09, Validation Loss: 82.60
2025-02-24 20:47:51,752 - Epoch 26, Training Loss: 80.96, Validation Loss: 81.49
2025-02-24 20:47:51,982 - Epoch 27, Training Loss: 71.15, Validation Loss: 80.76
2025-02-24 20:47:52,206 - Epoch 28, Training Loss: 75.94, Validation Loss: 80.07
2025-02-24 20:47:52,418 - Epoch 29, Training Loss: 80.47, Validation Loss: 78.81
2025-02-24 20:47:52,630 - Epoch 30, Training Loss: 72.94, Validation Loss: 77.36
2025-02-24 20:47:52,842 - Epoch 31, Training Loss: 73.14, Validation Loss: 76.33
2025-02-24 20:47:53,056 - Epoch 32, Training Loss: 72.77, Validation Loss: 75.30
2025-02-24 20:47:53,269 - Epoch 33, Training Loss: 72.70, Validation Loss: 74.73
2025-02-24 20:47:53,488 - Epoch 34, Training Loss: 72.94, Validation Loss: 74.41
2025-02-24 20:47:53,702 - Epoch 35, Training Loss: 71.45, Validation Loss: 73.94
2025-02-24 20:47:53,917 - Epoch 36, Training Loss: 73.96, Validation Loss: 73.40
2025-02-24 20:47:54,135 - Epoch 37, Training Loss: 77.98, Validation Loss: 72.72
2025-02-24 20:47:54,351 - Epoch 38, Training Loss: 74.01, Validation Loss: 72.48
2025-02-24 20:47:54,570 - Epoch 39, Training Loss: 64.79, Validation Loss: 72.07
2025-02-24 20:47:54,785 - Epoch 40, Training Loss: 69.36, Validation Loss: 71.87
2025-02-24 20:47:55,002 - Epoch 41, Training Loss: 70.01, Validation Loss: 71.39
2025-02-24 20:47:55,223 - Epoch 42, Training Loss: 71.79, Validation Loss: 70.45
2025-02-24 20:47:55,447 - Epoch 43, Training Loss: 71.43, Validation Loss: 69.79
2025-02-24 20:47:55,666 - Epoch 44, Training Loss: 76.36, Validation Loss: 69.30
2025-02-24 20:47:55,881 - Epoch 45, Training Loss: 66.92, Validation Loss: 69.03
2025-02-24 20:47:56,093 - Epoch 46, Training Loss: 78.37, Validation Loss: 68.98
2025-02-24 20:47:56,309 - Epoch 47, Training Loss: 71.83, Validation Loss: 68.85
2025-02-24 20:47:56,525 - Epoch 48, Training Loss: 70.76, Validation Loss: 69.16
2025-02-24 20:47:56,718 - Epoch 49, Training Loss: 78.17, Validation Loss: 68.99
2025-02-24 20:47:56,931 - Epoch 50, Training Loss: 71.39, Validation Loss: 68.80
2025-02-24 20:47:57,155 - Epoch 51, Training Loss: 71.62, Validation Loss: 68.25
2025-02-24 20:47:57,384 - Epoch 52, Training Loss: 69.86, Validation Loss: 68.61
2025-02-24 20:47:57,597 - Epoch 53, Training Loss: 74.09, Validation Loss: 68.61
2025-02-24 20:47:57,803 - Epoch 54, Training Loss: 71.41, Validation Loss: 67.71
2025-02-24 20:47:58,023 - Epoch 55, Training Loss: 73.51, Validation Loss: 67.55
2025-02-24 20:47:58,249 - Epoch 56, Training Loss: 70.59, Validation Loss: 67.47
2025-02-24 20:47:58,484 - Epoch 57, Training Loss: 63.33, Validation Loss: 67.81
2025-02-24 20:47:58,689 - Epoch 58, Training Loss: 76.51, Validation Loss: 67.54
2025-02-24 20:47:58,885 - Epoch 59, Training Loss: 72.21, Validation Loss: 66.77
2025-02-24 20:47:59,098 - Epoch 60, Training Loss: 79.17, Validation Loss: 66.41
2025-02-24 20:47:59,314 - Epoch 61, Training Loss: 71.14, Validation Loss: 66.10
2025-02-24 20:47:59,529 - Epoch 62, Training Loss: 73.51, Validation Loss: 66.13
2025-02-24 20:47:59,729 - Epoch 63, Training Loss: 77.71, Validation Loss: 65.96
2025-02-24 20:47:59,972 - Epoch 64, Training Loss: 70.83, Validation Loss: 65.89
2025-02-24 20:48:00,220 - Epoch 65, Training Loss: 76.90, Validation Loss: 65.79
2025-02-24 20:48:00,464 - Epoch 66, Training Loss: 70.71, Validation Loss: 65.92
2025-02-24 20:48:00,667 - Epoch 67, Training Loss: 67.80, Validation Loss: 65.79
2025-02-24 20:48:00,914 - Epoch 68, Training Loss: 72.15, Validation Loss: 65.57
2025-02-24 20:48:01,171 - Epoch 69, Training Loss: 66.32, Validation Loss: 65.59
2025-02-24 20:48:01,391 - Epoch 70, Training Loss: 68.23, Validation Loss: 65.30
2025-02-24 20:48:01,627 - Epoch 71, Training Loss: 66.03, Validation Loss: 65.65
2025-02-24 20:48:01,818 - Epoch 72, Training Loss: 70.50, Validation Loss: 66.35
2025-02-24 20:48:02,031 - Epoch 73, Training Loss: 65.05, Validation Loss: 67.34
2025-02-24 20:48:02,245 - Epoch 74, Training Loss: 80.31, Validation Loss: 66.97
2025-02-24 20:48:02,447 - Epoch 75, Training Loss: 81.51, Validation Loss: 65.89
2025-02-24 20:48:02,666 - Epoch 76, Training Loss: 67.24, Validation Loss: 65.08
2025-02-24 20:48:02,903 - Epoch 77, Training Loss: 69.81, Validation Loss: 64.87
2025-02-24 20:48:03,134 - Epoch 78, Training Loss: 68.03, Validation Loss: 64.88
2025-02-24 20:48:03,327 - Epoch 79, Training Loss: 66.29, Validation Loss: 64.48
2025-02-24 20:48:03,538 - Epoch 80, Training Loss: 75.50, Validation Loss: 63.97
2025-02-24 20:48:03,764 - Epoch 81, Training Loss: 67.59, Validation Loss: 63.54
2025-02-24 20:48:04,003 - Epoch 82, Training Loss: 74.18, Validation Loss: 63.73
2025-02-24 20:48:04,196 - Epoch 83, Training Loss: 76.80, Validation Loss: 63.97
2025-02-24 20:48:04,387 - Epoch 84, Training Loss: 81.13, Validation Loss: 63.62
2025-02-24 20:48:04,583 - Epoch 85, Training Loss: 76.12, Validation Loss: 62.79
2025-02-24 20:48:04,803 - Epoch 86, Training Loss: 76.15, Validation Loss: 62.51
2025-02-24 20:48:05,018 - Epoch 87, Training Loss: 68.20, Validation Loss: 62.26
2025-02-24 20:48:05,263 - Epoch 88, Training Loss: 70.27, Validation Loss: 62.25
2025-02-24 20:48:05,507 - Epoch 89, Training Loss: 66.17, Validation Loss: 62.66
2025-02-24 20:48:05,713 - Epoch 90, Training Loss: 68.57, Validation Loss: 63.47
2025-02-24 20:48:05,905 - Epoch 91, Training Loss: 66.69, Validation Loss: 63.90
2025-02-24 20:48:06,099 - Epoch 92, Training Loss: 68.29, Validation Loss: 63.78
2025-02-24 20:48:06,290 - Epoch 93, Training Loss: 67.15, Validation Loss: 64.03
2025-02-24 20:48:06,485 - Epoch 94, Training Loss: 76.76, Validation Loss: 64.03
2025-02-24 20:48:06,676 - Epoch 95, Training Loss: 67.32, Validation Loss: 64.09
2025-02-24 20:48:06,875 - Epoch 96, Training Loss: 73.11, Validation Loss: 64.44
2025-02-24 20:48:07,066 - Epoch 97, Training Loss: 68.73, Validation Loss: 64.09
2025-02-24 20:48:07,274 - Epoch 98, Training Loss: 70.86, Validation Loss: 63.77
2025-02-24 20:48:07,467 - Epoch 99, Training Loss: 80.19, Validation Loss: 64.73
2025-02-24 20:48:07,665 - Epoch 100, Training Loss: 70.22, Validation Loss: 65.19
2025-02-24 20:48:07,856 - Epoch 101, Training Loss: 78.38, Validation Loss: 66.05
2025-02-24 20:48:08,060 - Epoch 102, Training Loss: 76.50, Validation Loss: 66.43
2025-02-24 20:48:08,273 - Epoch 103, Training Loss: 75.31, Validation Loss: 65.94
2025-02-24 20:48:08,468 - Epoch 104, Training Loss: 77.82, Validation Loss: 65.18
2025-02-24 20:48:08,667 - Epoch 105, Training Loss: 76.86, Validation Loss: 64.84
2025-02-24 20:48:08,872 - Epoch 106, Training Loss: 78.16, Validation Loss: 64.36
2025-02-24 20:48:09,069 - Epoch 107, Training Loss: 68.08, Validation Loss: 64.27
2025-02-24 20:48:09,263 - Epoch 108, Training Loss: 74.26, Validation Loss: 64.34
2025-02-24 20:48:09,263 - Early stopping at epoch 108 due to no improvement in validation loss.
2025-02-24 20:48:09,487 - learning rate: 0.02
2025-02-24 20:48:09,487 - Test RMSE: 7.444543838500977, Test MAE: 1.1670073866844177
2025-02-25 14:13:18,229 - -----------------------Starting training-------------------------
2025-02-25 14:13:18,230 - learning rate: 0.02
2025-02-25 14:13:18,458 - Epoch 1, Training Loss: 191.50, Validation Loss: 200.15
2025-02-25 14:13:18,673 - Epoch 2, Training Loss: 150.45, Validation Loss: 183.70
2025-02-25 14:13:18,930 - learning rate: 0.02
2025-02-25 14:13:18,930 - Test RMSE: 11.78695011138916, Test MAE: 1.7256059646606445
2025-02-25 14:13:48,449 - -----------------------Starting training-------------------------
2025-02-25 14:13:48,449 - learning rate: 0.02
2025-02-25 14:13:48,652 - Epoch 1, Training Loss: 191.50, Validation Loss: 200.15
2025-02-25 14:13:48,900 - learning rate: 0.02
2025-02-25 14:13:48,901 - Test RMSE: 12.287065029144287, Test MAE: 1.9188212752342224
2025-02-25 14:23:52,427 - -----------------------Starting training-------------------------
2025-02-25 14:23:52,427 - learning rate: 0.02
2025-02-25 14:23:52,618 - Epoch 1, Training Loss: 153.32, Validation Loss: 201.67
2025-02-25 14:23:52,839 - Epoch 2, Training Loss: 162.10, Validation Loss: 186.03
2025-02-25 14:23:53,057 - Epoch 3, Training Loss: 148.49, Validation Loss: 172.72
2025-02-25 14:23:53,262 - Epoch 4, Training Loss: 130.14, Validation Loss: 161.39
2025-02-25 14:23:53,475 - Epoch 5, Training Loss: 149.71, Validation Loss: 152.09
2025-02-25 14:23:53,681 - Epoch 6, Training Loss: 109.37, Validation Loss: 143.68
2025-02-25 14:23:53,914 - Epoch 7, Training Loss: 111.55, Validation Loss: 136.82
2025-02-25 14:23:54,110 - Epoch 8, Training Loss: 109.70, Validation Loss: 130.86
2025-02-25 14:23:54,317 - Epoch 9, Training Loss: 115.08, Validation Loss: 125.49
2025-02-25 14:23:54,519 - Epoch 10, Training Loss: 116.34, Validation Loss: 120.52
2025-02-25 14:23:54,722 - Epoch 11, Training Loss: 91.60, Validation Loss: 115.91
2025-02-25 14:23:54,920 - Epoch 12, Training Loss: 97.09, Validation Loss: 111.97
2025-02-25 14:23:55,135 - Epoch 13, Training Loss: 111.25, Validation Loss: 108.42
2025-02-25 14:23:55,363 - Epoch 14, Training Loss: 98.39, Validation Loss: 105.03
2025-02-25 14:23:55,560 - Epoch 15, Training Loss: 98.52, Validation Loss: 102.22
2025-02-25 14:23:55,764 - Epoch 16, Training Loss: 106.31, Validation Loss: 99.19
2025-02-25 14:23:55,966 - Epoch 17, Training Loss: 79.47, Validation Loss: 96.66
2025-02-25 14:23:56,203 - Epoch 18, Training Loss: 84.68, Validation Loss: 95.01
2025-02-25 14:23:56,451 - Epoch 19, Training Loss: 87.47, Validation Loss: 93.39
2025-02-25 14:23:56,655 - Epoch 20, Training Loss: 87.93, Validation Loss: 91.49
2025-02-25 14:23:56,863 - Epoch 21, Training Loss: 101.37, Validation Loss: 89.62
2025-02-25 14:23:57,069 - Epoch 22, Training Loss: 76.46, Validation Loss: 87.89
2025-02-25 14:23:57,308 - Epoch 23, Training Loss: 75.23, Validation Loss: 86.45
2025-02-25 14:23:57,515 - Epoch 24, Training Loss: 76.47, Validation Loss: 85.36
2025-02-25 14:23:57,720 - Epoch 25, Training Loss: 81.60, Validation Loss: 84.18
2025-02-25 14:23:57,926 - Epoch 26, Training Loss: 74.26, Validation Loss: 83.19
2025-02-25 14:23:58,128 - Epoch 27, Training Loss: 74.33, Validation Loss: 82.22
2025-02-25 14:23:58,331 - Epoch 28, Training Loss: 73.92, Validation Loss: 81.16
2025-02-25 14:23:58,532 - Epoch 29, Training Loss: 80.87, Validation Loss: 80.11
2025-02-25 14:23:58,730 - Epoch 30, Training Loss: 73.30, Validation Loss: 79.10
2025-02-25 14:23:58,933 - Epoch 31, Training Loss: 79.76, Validation Loss: 78.69
2025-02-25 14:23:59,144 - Epoch 32, Training Loss: 73.88, Validation Loss: 77.99
2025-02-25 14:23:59,354 - Epoch 33, Training Loss: 72.73, Validation Loss: 77.25
2025-02-25 14:23:59,559 - Epoch 34, Training Loss: 70.85, Validation Loss: 76.49
2025-02-25 14:23:59,764 - Epoch 35, Training Loss: 66.81, Validation Loss: 76.03
2025-02-25 14:23:59,966 - Epoch 36, Training Loss: 68.75, Validation Loss: 76.04
2025-02-25 14:24:00,162 - Epoch 37, Training Loss: 84.89, Validation Loss: 75.60
2025-02-25 14:24:00,365 - Epoch 38, Training Loss: 80.17, Validation Loss: 74.24
2025-02-25 14:24:00,580 - Epoch 39, Training Loss: 73.22, Validation Loss: 73.26
2025-02-25 14:24:00,806 - Epoch 40, Training Loss: 72.13, Validation Loss: 73.31
2025-02-25 14:24:01,020 - Epoch 41, Training Loss: 70.73, Validation Loss: 72.78
2025-02-25 14:24:01,259 - Epoch 42, Training Loss: 74.56, Validation Loss: 71.47
2025-02-25 14:24:01,484 - Epoch 43, Training Loss: 71.09, Validation Loss: 71.36
2025-02-25 14:24:01,708 - Epoch 44, Training Loss: 66.23, Validation Loss: 71.66
2025-02-25 14:24:01,914 - Epoch 45, Training Loss: 81.32, Validation Loss: 71.41
2025-02-25 14:24:02,117 - Epoch 46, Training Loss: 76.47, Validation Loss: 70.14
2025-02-25 14:24:02,336 - Epoch 47, Training Loss: 77.23, Validation Loss: 68.93
2025-02-25 14:24:02,557 - Epoch 48, Training Loss: 67.10, Validation Loss: 68.14
2025-02-25 14:24:02,782 - Epoch 49, Training Loss: 69.84, Validation Loss: 67.69
2025-02-25 14:24:03,013 - Epoch 50, Training Loss: 73.33, Validation Loss: 67.52
2025-02-25 14:24:03,234 - Epoch 51, Training Loss: 69.13, Validation Loss: 68.20
2025-02-25 14:24:03,458 - Epoch 52, Training Loss: 64.36, Validation Loss: 68.36
2025-02-25 14:24:03,664 - Epoch 53, Training Loss: 68.74, Validation Loss: 68.49
2025-02-25 14:24:03,881 - Epoch 54, Training Loss: 69.13, Validation Loss: 68.34
2025-02-25 14:24:04,077 - Epoch 55, Training Loss: 75.85, Validation Loss: 68.41
2025-02-25 14:24:04,279 - Epoch 56, Training Loss: 71.78, Validation Loss: 68.86
2025-02-25 14:24:04,477 - Epoch 57, Training Loss: 76.89, Validation Loss: 67.93
2025-02-25 14:24:04,659 - Epoch 58, Training Loss: 65.33, Validation Loss: 66.72
2025-02-25 14:24:04,862 - Epoch 59, Training Loss: 71.40, Validation Loss: 66.21
2025-02-25 14:24:05,072 - Epoch 60, Training Loss: 66.65, Validation Loss: 65.72
2025-02-25 14:24:05,280 - Epoch 61, Training Loss: 80.04, Validation Loss: 65.32
2025-02-25 14:24:05,488 - Epoch 62, Training Loss: 81.93, Validation Loss: 64.31
2025-02-25 14:24:05,696 - Epoch 63, Training Loss: 80.71, Validation Loss: 63.58
2025-02-25 14:24:05,895 - Epoch 64, Training Loss: 69.02, Validation Loss: 63.35
2025-02-25 14:24:06,101 - Epoch 65, Training Loss: 73.26, Validation Loss: 63.89
2025-02-25 14:24:06,284 - Epoch 66, Training Loss: 69.98, Validation Loss: 63.82
2025-02-25 14:24:06,464 - Epoch 67, Training Loss: 69.42, Validation Loss: 63.88
2025-02-25 14:24:06,645 - Epoch 68, Training Loss: 69.47, Validation Loss: 63.85
2025-02-25 14:24:06,824 - Epoch 69, Training Loss: 68.04, Validation Loss: 63.72
2025-02-25 14:24:07,012 - Epoch 70, Training Loss: 69.45, Validation Loss: 63.81
2025-02-25 14:24:07,200 - Epoch 71, Training Loss: 70.17, Validation Loss: 63.40
2025-02-25 14:24:07,387 - Epoch 72, Training Loss: 76.83, Validation Loss: 62.92
2025-02-25 14:24:07,588 - Epoch 73, Training Loss: 76.05, Validation Loss: 62.41
2025-02-25 14:24:07,785 - Epoch 74, Training Loss: 72.83, Validation Loss: 62.89
2025-02-25 14:24:07,970 - Epoch 75, Training Loss: 63.28, Validation Loss: 63.47
2025-02-25 14:24:08,147 - Epoch 76, Training Loss: 78.01, Validation Loss: 63.48
2025-02-25 14:24:08,329 - Epoch 77, Training Loss: 72.60, Validation Loss: 64.33
2025-02-25 14:24:08,515 - Epoch 78, Training Loss: 67.94, Validation Loss: 64.45
2025-02-25 14:24:08,696 - Epoch 79, Training Loss: 67.88, Validation Loss: 65.01
2025-02-25 14:24:08,875 - Epoch 80, Training Loss: 75.64, Validation Loss: 68.13
2025-02-25 14:24:09,056 - Epoch 81, Training Loss: 67.61, Validation Loss: 68.10
2025-02-25 14:24:09,236 - Epoch 82, Training Loss: 68.94, Validation Loss: 68.36
2025-02-25 14:24:09,423 - Epoch 83, Training Loss: 74.66, Validation Loss: 67.53
2025-02-25 14:24:09,600 - Epoch 84, Training Loss: 70.14, Validation Loss: 64.70
2025-02-25 14:24:09,781 - Epoch 85, Training Loss: 69.21, Validation Loss: 63.61
2025-02-25 14:24:09,960 - Epoch 86, Training Loss: 75.33, Validation Loss: 63.30
2025-02-25 14:24:10,151 - Epoch 87, Training Loss: 69.50, Validation Loss: 63.89
2025-02-25 14:24:10,335 - Epoch 88, Training Loss: 68.44, Validation Loss: 64.33
2025-02-25 14:24:10,520 - Epoch 89, Training Loss: 63.01, Validation Loss: 64.40
2025-02-25 14:24:10,716 - Epoch 90, Training Loss: 67.99, Validation Loss: 63.75
2025-02-25 14:24:10,898 - Epoch 91, Training Loss: 65.85, Validation Loss: 66.99
2025-02-25 14:24:11,077 - Epoch 92, Training Loss: 72.99, Validation Loss: 65.28
2025-02-25 14:24:11,260 - Epoch 93, Training Loss: 68.45, Validation Loss: 64.24
2025-02-25 14:24:11,260 - Early stopping at epoch 93 due to no improvement in validation loss.
2025-02-25 14:24:11,479 - learning rate: 0.02
2025-02-25 14:24:11,480 - Test RMSE: 6.987890720367432, Test MAE: 1.1916662156581879
2025-02-25 14:25:47,250 - -----------------------Starting training-------------------------
2025-02-25 14:25:47,250 - learning rate: 0.01
2025-02-25 14:25:47,438 - Epoch 1, Training Loss: 155.93, Validation Loss: 211.22
2025-02-25 14:25:47,650 - Epoch 2, Training Loss: 170.02, Validation Loss: 199.76
2025-02-25 14:25:47,856 - Epoch 3, Training Loss: 159.60, Validation Loss: 189.31
2025-02-25 14:25:48,073 - Epoch 4, Training Loss: 141.69, Validation Loss: 179.76
2025-02-25 14:25:48,277 - Epoch 5, Training Loss: 165.57, Validation Loss: 171.24
2025-02-25 14:25:48,486 - Epoch 6, Training Loss: 120.90, Validation Loss: 163.46
2025-02-25 14:25:48,693 - Epoch 7, Training Loss: 124.75, Validation Loss: 156.76
2025-02-25 14:25:48,901 - Epoch 8, Training Loss: 123.56, Validation Loss: 150.59
2025-02-25 14:25:49,109 - Epoch 9, Training Loss: 128.37, Validation Loss: 145.02
2025-02-25 14:25:49,322 - Epoch 10, Training Loss: 131.45, Validation Loss: 139.85
2025-02-25 14:25:49,533 - Epoch 11, Training Loss: 103.82, Validation Loss: 135.04
2025-02-25 14:25:49,746 - Epoch 12, Training Loss: 109.78, Validation Loss: 130.77
2025-02-25 14:25:49,954 - Epoch 13, Training Loss: 125.77, Validation Loss: 126.88
2025-02-25 14:25:50,160 - Epoch 14, Training Loss: 110.72, Validation Loss: 123.15
2025-02-25 14:25:50,361 - Epoch 15, Training Loss: 111.71, Validation Loss: 119.93
2025-02-25 14:25:50,561 - Epoch 16, Training Loss: 120.66, Validation Loss: 116.61
2025-02-25 14:25:50,765 - Epoch 17, Training Loss: 88.27, Validation Loss: 113.66
2025-02-25 14:25:50,964 - Epoch 18, Training Loss: 94.02, Validation Loss: 111.40
2025-02-25 14:25:51,168 - Epoch 19, Training Loss: 99.40, Validation Loss: 109.27
2025-02-25 14:25:51,375 - Epoch 20, Training Loss: 98.80, Validation Loss: 106.96
2025-02-25 14:25:51,580 - Epoch 21, Training Loss: 114.26, Validation Loss: 104.66
2025-02-25 14:25:51,778 - Epoch 22, Training Loss: 84.87, Validation Loss: 102.53
2025-02-25 14:25:51,979 - Epoch 23, Training Loss: 83.53, Validation Loss: 100.63
2025-02-25 14:25:52,181 - Epoch 24, Training Loss: 85.04, Validation Loss: 98.97
2025-02-25 14:25:52,381 - Epoch 25, Training Loss: 89.25, Validation Loss: 97.28
2025-02-25 14:25:52,582 - Epoch 26, Training Loss: 81.77, Validation Loss: 95.77
2025-02-25 14:25:52,784 - Epoch 27, Training Loss: 81.90, Validation Loss: 94.30
2025-02-25 14:25:52,985 - Epoch 28, Training Loss: 80.84, Validation Loss: 92.80
2025-02-25 14:25:53,191 - Epoch 29, Training Loss: 88.78, Validation Loss: 91.33
2025-02-25 14:25:53,399 - Epoch 30, Training Loss: 77.09, Validation Loss: 89.87
2025-02-25 14:25:53,598 - Epoch 31, Training Loss: 86.68, Validation Loss: 89.00
2025-02-25 14:25:53,807 - Epoch 32, Training Loss: 78.74, Validation Loss: 87.91
2025-02-25 14:25:54,007 - Epoch 33, Training Loss: 78.02, Validation Loss: 86.81
2025-02-25 14:25:54,208 - Epoch 34, Training Loss: 75.65, Validation Loss: 85.70
2025-02-25 14:25:54,412 - Epoch 35, Training Loss: 69.35, Validation Loss: 84.84
2025-02-25 14:25:54,616 - Epoch 36, Training Loss: 72.31, Validation Loss: 84.55
2025-02-25 14:25:54,825 - Epoch 37, Training Loss: 91.02, Validation Loss: 83.64
2025-02-25 14:25:55,025 - Epoch 38, Training Loss: 84.52, Validation Loss: 82.06
2025-02-25 14:25:55,229 - Epoch 39, Training Loss: 76.79, Validation Loss: 80.80
2025-02-25 14:25:55,427 - Epoch 40, Training Loss: 74.82, Validation Loss: 79.93
2025-02-25 14:25:55,629 - Epoch 41, Training Loss: 74.80, Validation Loss: 78.99
2025-02-25 14:25:55,828 - Epoch 42, Training Loss: 77.61, Validation Loss: 77.84
2025-02-25 14:25:56,034 - Epoch 43, Training Loss: 72.48, Validation Loss: 77.39
2025-02-25 14:25:56,236 - Epoch 44, Training Loss: 68.50, Validation Loss: 77.45
2025-02-25 14:25:56,415 - Epoch 45, Training Loss: 85.18, Validation Loss: 77.07
2025-02-25 14:25:56,612 - Epoch 46, Training Loss: 80.19, Validation Loss: 75.89
2025-02-25 14:25:56,823 - Epoch 47, Training Loss: 80.09, Validation Loss: 74.73
2025-02-25 14:25:57,031 - Epoch 48, Training Loss: 70.02, Validation Loss: 73.82
2025-02-25 14:25:57,244 - Epoch 49, Training Loss: 72.93, Validation Loss: 73.19
2025-02-25 14:25:57,457 - Epoch 50, Training Loss: 72.74, Validation Loss: 72.83
2025-02-25 14:25:57,664 - Epoch 51, Training Loss: 71.28, Validation Loss: 73.18
2025-02-25 14:25:57,856 - Epoch 52, Training Loss: 64.99, Validation Loss: 73.06
2025-02-25 14:25:58,078 - Epoch 53, Training Loss: 70.56, Validation Loss: 72.98
2025-02-25 14:25:58,270 - Epoch 54, Training Loss: 70.17, Validation Loss: 72.64
2025-02-25 14:25:58,484 - Epoch 55, Training Loss: 76.27, Validation Loss: 72.72
2025-02-25 14:25:58,666 - Epoch 56, Training Loss: 73.53, Validation Loss: 72.97
2025-02-25 14:25:58,852 - Epoch 57, Training Loss: 79.24, Validation Loss: 71.96
2025-02-25 14:25:59,062 - Epoch 58, Training Loss: 66.30, Validation Loss: 71.01
2025-02-25 14:25:59,269 - Epoch 59, Training Loss: 72.65, Validation Loss: 70.14
2025-02-25 14:25:59,478 - Epoch 60, Training Loss: 67.82, Validation Loss: 69.72
2025-02-25 14:25:59,685 - Epoch 61, Training Loss: 82.20, Validation Loss: 68.85
2025-02-25 14:25:59,895 - Epoch 62, Training Loss: 83.23, Validation Loss: 67.64
2025-02-25 14:26:00,104 - Epoch 63, Training Loss: 82.64, Validation Loss: 66.87
2025-02-25 14:26:00,310 - Epoch 64, Training Loss: 68.63, Validation Loss: 66.86
2025-02-25 14:26:00,510 - Epoch 65, Training Loss: 74.44, Validation Loss: 66.97
2025-02-25 14:26:00,691 - Epoch 66, Training Loss: 70.59, Validation Loss: 66.59
2025-02-25 14:26:00,909 - Epoch 67, Training Loss: 69.93, Validation Loss: 66.45
2025-02-25 14:26:01,117 - Epoch 68, Training Loss: 70.26, Validation Loss: 67.31
2025-02-25 14:26:01,303 - Epoch 69, Training Loss: 68.70, Validation Loss: 66.93
2025-02-25 14:26:01,489 - Epoch 70, Training Loss: 70.05, Validation Loss: 66.40
2025-02-25 14:26:01,691 - Epoch 71, Training Loss: 70.76, Validation Loss: 65.98
2025-02-25 14:26:01,900 - Epoch 72, Training Loss: 77.79, Validation Loss: 65.47
2025-02-25 14:26:02,111 - Epoch 73, Training Loss: 76.24, Validation Loss: 64.96
2025-02-25 14:26:02,316 - Epoch 74, Training Loss: 72.15, Validation Loss: 67.30
2025-02-25 14:26:02,500 - Epoch 75, Training Loss: 64.45, Validation Loss: 67.33
2025-02-25 14:26:02,677 - Epoch 76, Training Loss: 77.88, Validation Loss: 66.59
2025-02-25 14:26:02,862 - Epoch 77, Training Loss: 72.85, Validation Loss: 66.19
2025-02-25 14:26:03,049 - Epoch 78, Training Loss: 67.96, Validation Loss: 65.82
2025-02-25 14:26:03,233 - Epoch 79, Training Loss: 67.98, Validation Loss: 65.67
2025-02-25 14:26:03,408 - Epoch 80, Training Loss: 75.83, Validation Loss: 67.89
2025-02-25 14:26:03,595 - Epoch 81, Training Loss: 67.58, Validation Loss: 67.89
2025-02-25 14:26:03,772 - Epoch 82, Training Loss: 68.82, Validation Loss: 68.84
2025-02-25 14:26:03,960 - Epoch 83, Training Loss: 74.17, Validation Loss: 67.24
2025-02-25 14:26:04,145 - Epoch 84, Training Loss: 70.24, Validation Loss: 66.17
2025-02-25 14:26:04,334 - Epoch 85, Training Loss: 69.31, Validation Loss: 65.42
2025-02-25 14:26:04,512 - Epoch 86, Training Loss: 75.04, Validation Loss: 65.06
2025-02-25 14:26:04,696 - Epoch 87, Training Loss: 69.39, Validation Loss: 65.10
2025-02-25 14:26:04,885 - Epoch 88, Training Loss: 68.43, Validation Loss: 65.12
2025-02-25 14:26:05,072 - Epoch 89, Training Loss: 63.07, Validation Loss: 65.13
2025-02-25 14:26:05,259 - Epoch 90, Training Loss: 67.69, Validation Loss: 65.07
2025-02-25 14:26:05,443 - Epoch 91, Training Loss: 64.92, Validation Loss: 65.26
2025-02-25 14:26:05,621 - Epoch 92, Training Loss: 72.54, Validation Loss: 64.76
2025-02-25 14:26:05,834 - Epoch 93, Training Loss: 68.30, Validation Loss: 64.30
2025-02-25 14:26:06,033 - Epoch 94, Training Loss: 69.13, Validation Loss: 64.12
2025-02-25 14:26:06,235 - Epoch 95, Training Loss: 66.26, Validation Loss: 64.48
2025-02-25 14:26:06,416 - Epoch 96, Training Loss: 66.17, Validation Loss: 64.74
2025-02-25 14:26:06,598 - Epoch 97, Training Loss: 62.16, Validation Loss: 65.00
2025-02-25 14:26:06,782 - Epoch 98, Training Loss: 70.72, Validation Loss: 65.12
2025-02-25 14:26:06,963 - Epoch 99, Training Loss: 78.17, Validation Loss: 65.66
2025-02-25 14:26:07,159 - Epoch 100, Training Loss: 70.43, Validation Loss: 65.72
2025-02-25 14:26:07,339 - Epoch 101, Training Loss: 71.77, Validation Loss: 65.97
2025-02-25 14:26:07,517 - Epoch 102, Training Loss: 73.52, Validation Loss: 66.51
2025-02-25 14:26:07,698 - Epoch 103, Training Loss: 62.56, Validation Loss: 66.74
2025-02-25 14:26:07,884 - Epoch 104, Training Loss: 72.90, Validation Loss: 66.46
2025-02-25 14:26:08,070 - Epoch 105, Training Loss: 74.47, Validation Loss: 65.78
2025-02-25 14:26:08,250 - Epoch 106, Training Loss: 65.18, Validation Loss: 65.10
2025-02-25 14:26:08,429 - Epoch 107, Training Loss: 68.82, Validation Loss: 64.60
2025-02-25 14:26:08,610 - Epoch 108, Training Loss: 69.15, Validation Loss: 64.52
2025-02-25 14:26:08,791 - Epoch 109, Training Loss: 64.30, Validation Loss: 64.76
2025-02-25 14:26:08,972 - Epoch 110, Training Loss: 69.86, Validation Loss: 64.44
2025-02-25 14:26:09,154 - Epoch 111, Training Loss: 72.31, Validation Loss: 63.84
2025-02-25 14:26:09,355 - Epoch 112, Training Loss: 69.97, Validation Loss: 63.36
2025-02-25 14:26:09,556 - Epoch 113, Training Loss: 75.81, Validation Loss: 63.40
2025-02-25 14:26:09,737 - Epoch 114, Training Loss: 64.06, Validation Loss: 63.61
2025-02-25 14:26:09,919 - Epoch 115, Training Loss: 72.39, Validation Loss: 63.51
2025-02-25 14:26:10,097 - Epoch 116, Training Loss: 72.01, Validation Loss: 63.59
2025-02-25 14:26:10,278 - Epoch 117, Training Loss: 76.64, Validation Loss: 64.27
2025-02-25 14:26:10,461 - Epoch 118, Training Loss: 71.04, Validation Loss: 64.40
2025-02-25 14:26:10,639 - Epoch 119, Training Loss: 69.28, Validation Loss: 64.56
2025-02-25 14:26:10,818 - Epoch 120, Training Loss: 65.59, Validation Loss: 64.38
2025-02-25 14:26:10,999 - Epoch 121, Training Loss: 77.55, Validation Loss: 64.23
2025-02-25 14:26:11,190 - Epoch 122, Training Loss: 72.38, Validation Loss: 63.58
2025-02-25 14:26:11,385 - Epoch 123, Training Loss: 70.65, Validation Loss: 63.03
2025-02-25 14:26:11,602 - Epoch 124, Training Loss: 74.82, Validation Loss: 63.36
2025-02-25 14:26:11,838 - Epoch 125, Training Loss: 77.15, Validation Loss: 63.59
2025-02-25 14:26:12,071 - Epoch 126, Training Loss: 73.43, Validation Loss: 63.37
2025-02-25 14:26:12,314 - Epoch 127, Training Loss: 65.04, Validation Loss: 63.48
2025-02-25 14:26:13,345 - Epoch 128, Training Loss: 78.49, Validation Loss: 63.12
2025-02-25 14:26:13,584 - Epoch 129, Training Loss: 70.03, Validation Loss: 63.22
2025-02-25 14:26:13,786 - Epoch 130, Training Loss: 69.23, Validation Loss: 63.71
2025-02-25 14:26:13,980 - Epoch 131, Training Loss: 68.39, Validation Loss: 63.62
2025-02-25 14:26:14,159 - Epoch 132, Training Loss: 73.93, Validation Loss: 63.25
2025-02-25 14:26:14,343 - Epoch 133, Training Loss: 63.93, Validation Loss: 63.07
2025-02-25 14:26:14,525 - Epoch 134, Training Loss: 74.57, Validation Loss: 63.06
2025-02-25 14:26:14,710 - Epoch 135, Training Loss: 75.95, Validation Loss: 62.96
2025-02-25 14:26:14,910 - Epoch 136, Training Loss: 70.58, Validation Loss: 62.59
2025-02-25 14:26:15,109 - Epoch 137, Training Loss: 68.74, Validation Loss: 62.76
2025-02-25 14:26:15,311 - Epoch 138, Training Loss: 68.68, Validation Loss: 62.69
2025-02-25 14:26:15,489 - Epoch 139, Training Loss: 69.36, Validation Loss: 63.29
2025-02-25 14:26:15,677 - Epoch 140, Training Loss: 75.88, Validation Loss: 63.56
2025-02-25 14:26:15,858 - Epoch 141, Training Loss: 76.53, Validation Loss: 63.26
2025-02-25 14:26:16,043 - Epoch 142, Training Loss: 69.19, Validation Loss: 62.68
2025-02-25 14:26:16,222 - Epoch 143, Training Loss: 76.32, Validation Loss: 62.72
2025-02-25 14:26:16,412 - Epoch 144, Training Loss: 70.78, Validation Loss: 62.52
2025-02-25 14:26:16,608 - Epoch 145, Training Loss: 77.35, Validation Loss: 61.97
2025-02-25 14:26:16,810 - Epoch 146, Training Loss: 66.76, Validation Loss: 61.57
2025-02-25 14:26:17,013 - Epoch 147, Training Loss: 75.20, Validation Loss: 61.21
2025-02-25 14:26:17,213 - Epoch 148, Training Loss: 74.86, Validation Loss: 61.17
2025-02-25 14:26:17,416 - Epoch 149, Training Loss: 65.25, Validation Loss: 61.14
2025-02-25 14:26:17,623 - Epoch 150, Training Loss: 67.73, Validation Loss: 61.15
2025-02-25 14:26:17,809 - Epoch 151, Training Loss: 72.47, Validation Loss: 61.33
2025-02-25 14:26:17,990 - Epoch 152, Training Loss: 69.22, Validation Loss: 61.23
2025-02-25 14:26:18,187 - Epoch 153, Training Loss: 68.50, Validation Loss: 61.28
2025-02-25 14:26:18,371 - Epoch 154, Training Loss: 77.15, Validation Loss: 61.73
2025-02-25 14:26:18,560 - Epoch 155, Training Loss: 74.48, Validation Loss: 62.02
2025-02-25 14:26:18,753 - Epoch 156, Training Loss: 70.41, Validation Loss: 61.99
2025-02-25 14:26:18,947 - Epoch 157, Training Loss: 76.97, Validation Loss: 62.36
2025-02-25 14:26:19,136 - Epoch 158, Training Loss: 68.93, Validation Loss: 63.23
2025-02-25 14:26:19,332 - Epoch 159, Training Loss: 73.55, Validation Loss: 63.55
2025-02-25 14:26:19,515 - Epoch 160, Training Loss: 73.67, Validation Loss: 63.21
2025-02-25 14:26:19,755 - Epoch 161, Training Loss: 67.33, Validation Loss: 62.98
2025-02-25 14:26:19,941 - Epoch 162, Training Loss: 74.82, Validation Loss: 62.97
2025-02-25 14:26:20,131 - Epoch 163, Training Loss: 62.68, Validation Loss: 62.86
2025-02-25 14:26:20,316 - Epoch 164, Training Loss: 72.09, Validation Loss: 63.05
2025-02-25 14:26:20,505 - Epoch 165, Training Loss: 74.57, Validation Loss: 63.43
2025-02-25 14:26:20,687 - Epoch 166, Training Loss: 66.89, Validation Loss: 63.70
2025-02-25 14:26:20,879 - Epoch 167, Training Loss: 75.52, Validation Loss: 63.85
2025-02-25 14:26:21,061 - Epoch 168, Training Loss: 79.24, Validation Loss: 63.61
2025-02-25 14:26:21,249 - Epoch 169, Training Loss: 77.26, Validation Loss: 63.24
2025-02-25 14:26:21,249 - Early stopping at epoch 169 due to no improvement in validation loss.
2025-02-25 14:26:21,469 - learning rate: 0.01
2025-02-25 14:26:21,469 - Test RMSE: 6.976304769515991, Test MAE: 1.0869417488574982
2025-02-25 14:38:31,804 - -----------------------Starting training-------------------------
2025-02-25 14:38:31,804 - learning rate: 0.1
2025-02-25 14:38:32,000 - Epoch 1, Training Loss: 162.23, Validation Loss: 190.54
2025-02-25 14:38:32,218 - Epoch 2, Training Loss: 141.61, Validation Loss: 142.09
2025-02-25 14:38:32,430 - Epoch 3, Training Loss: 113.58, Validation Loss: 108.84
2025-02-25 14:38:32,634 - Epoch 4, Training Loss: 93.14, Validation Loss: 93.41
2025-02-25 14:38:32,849 - Epoch 5, Training Loss: 95.39, Validation Loss: 86.48
2025-02-25 14:38:33,069 - Epoch 6, Training Loss: 77.67, Validation Loss: 78.55
2025-02-25 14:38:33,277 - Epoch 7, Training Loss: 75.82, Validation Loss: 73.88
2025-02-25 14:38:33,492 - Epoch 8, Training Loss: 71.49, Validation Loss: 70.24
2025-02-25 14:38:33,709 - Epoch 9, Training Loss: 78.59, Validation Loss: 68.15
2025-02-25 14:38:33,920 - Epoch 10, Training Loss: 75.36, Validation Loss: 66.46
2025-02-25 14:38:34,128 - Epoch 11, Training Loss: 63.34, Validation Loss: 64.56
2025-02-25 14:38:34,342 - Epoch 12, Training Loss: 69.18, Validation Loss: 63.78
2025-02-25 14:38:34,551 - Epoch 13, Training Loss: 78.87, Validation Loss: 63.08
2025-02-25 14:38:34,769 - Epoch 14, Training Loss: 76.15, Validation Loss: 62.16
2025-02-25 14:38:34,981 - Epoch 15, Training Loss: 74.86, Validation Loss: 62.46
2025-02-25 14:38:35,174 - Epoch 16, Training Loss: 81.12, Validation Loss: 60.51
2025-02-25 14:38:35,392 - Epoch 17, Training Loss: 71.64, Validation Loss: 61.74
2025-02-25 14:38:35,582 - Epoch 18, Training Loss: 72.11, Validation Loss: 63.90
2025-02-25 14:38:35,777 - Epoch 19, Training Loss: 71.19, Validation Loss: 64.21
2025-02-25 14:38:35,968 - Epoch 20, Training Loss: 74.23, Validation Loss: 63.10
2025-02-25 14:38:36,158 - Epoch 21, Training Loss: 83.84, Validation Loss: 62.30
2025-02-25 14:38:36,344 - Epoch 22, Training Loss: 68.01, Validation Loss: 62.05
2025-02-25 14:38:36,540 - Epoch 23, Training Loss: 67.19, Validation Loss: 62.93
2025-02-25 14:38:36,736 - Epoch 24, Training Loss: 66.91, Validation Loss: 64.12
2025-02-25 14:38:36,928 - Epoch 25, Training Loss: 74.84, Validation Loss: 63.88
2025-02-25 14:38:37,123 - Epoch 26, Training Loss: 67.43, Validation Loss: 64.13
2025-02-25 14:38:37,311 - Epoch 27, Training Loss: 66.94, Validation Loss: 64.22
2025-02-25 14:38:37,504 - Epoch 28, Training Loss: 67.53, Validation Loss: 63.92
2025-02-25 14:38:37,695 - Epoch 29, Training Loss: 73.94, Validation Loss: 63.16
2025-02-25 14:38:37,892 - Epoch 30, Training Loss: 72.78, Validation Loss: 62.70
2025-02-25 14:38:38,083 - Epoch 31, Training Loss: 74.56, Validation Loss: 64.85
2025-02-25 14:38:38,278 - Epoch 32, Training Loss: 71.43, Validation Loss: 66.55
2025-02-25 14:38:38,461 - Epoch 33, Training Loss: 69.56, Validation Loss: 65.42
2025-02-25 14:38:38,653 - Epoch 34, Training Loss: 67.02, Validation Loss: 64.36
2025-02-25 14:38:38,845 - Epoch 35, Training Loss: 69.00, Validation Loss: 64.92
2025-02-25 14:38:39,035 - Epoch 36, Training Loss: 66.74, Validation Loss: 67.18
2025-02-25 14:38:39,035 - Early stopping at epoch 36 due to no improvement in validation loss.
2025-02-25 14:38:39,261 - learning rate: 0.1
2025-02-25 14:38:39,262 - Test RMSE: 7.522082328796387, Test MAE: 1.172703117132187
2025-02-25 14:38:52,928 - -----------------------Starting training-------------------------
2025-02-25 14:38:52,929 - learning rate: 0.05
2025-02-25 14:38:53,143 - Epoch 1, Training Loss: 156.74, Validation Loss: 193.24
2025-02-25 14:38:53,378 - Epoch 2, Training Loss: 152.09, Validation Loss: 164.89
2025-02-25 14:38:53,640 - Epoch 3, Training Loss: 131.34, Validation Loss: 144.32
2025-02-25 14:38:53,878 - Epoch 4, Training Loss: 111.62, Validation Loss: 128.72
2025-02-25 14:38:54,100 - Epoch 5, Training Loss: 121.97, Validation Loss: 117.37
2025-02-25 14:38:54,314 - Epoch 6, Training Loss: 90.26, Validation Loss: 107.69
2025-02-25 14:38:54,523 - Epoch 7, Training Loss: 89.22, Validation Loss: 100.66
2025-02-25 14:38:54,743 - Epoch 8, Training Loss: 85.68, Validation Loss: 95.02
2025-02-25 14:38:54,951 - Epoch 9, Training Loss: 91.44, Validation Loss: 90.37
2025-02-25 14:38:55,159 - Epoch 10, Training Loss: 89.47, Validation Loss: 86.35
2025-02-25 14:38:55,381 - Epoch 11, Training Loss: 71.38, Validation Loss: 82.68
2025-02-25 14:38:55,590 - Epoch 12, Training Loss: 76.67, Validation Loss: 79.99
2025-02-25 14:38:55,802 - Epoch 13, Training Loss: 87.14, Validation Loss: 77.68
2025-02-25 14:38:56,023 - Epoch 14, Training Loss: 79.60, Validation Loss: 75.46
2025-02-25 14:38:56,246 - Epoch 15, Training Loss: 79.58, Validation Loss: 74.20
2025-02-25 14:38:56,471 - Epoch 16, Training Loss: 85.02, Validation Loss: 72.05
2025-02-25 14:38:56,686 - Epoch 17, Training Loss: 70.25, Validation Loss: 70.97
2025-02-25 14:38:56,896 - Epoch 18, Training Loss: 73.78, Validation Loss: 71.23
2025-02-25 14:38:57,101 - Epoch 19, Training Loss: 72.62, Validation Loss: 70.60
2025-02-25 14:38:57,314 - Epoch 20, Training Loss: 75.22, Validation Loss: 69.50
2025-02-25 14:38:57,530 - Epoch 21, Training Loss: 85.20, Validation Loss: 68.48
2025-02-25 14:38:57,747 - Epoch 22, Training Loss: 67.97, Validation Loss: 67.73
2025-02-25 14:38:57,962 - Epoch 23, Training Loss: 66.94, Validation Loss: 68.38
2025-02-25 14:38:58,159 - Epoch 24, Training Loss: 67.41, Validation Loss: 68.27
2025-02-25 14:38:58,349 - Epoch 25, Training Loss: 74.58, Validation Loss: 67.80
2025-02-25 14:38:58,540 - Epoch 26, Training Loss: 67.26, Validation Loss: 67.54
2025-02-25 14:38:58,751 - Epoch 27, Training Loss: 67.06, Validation Loss: 67.22
2025-02-25 14:38:58,966 - Epoch 28, Training Loss: 67.49, Validation Loss: 66.66
2025-02-25 14:38:59,171 - Epoch 29, Training Loss: 73.81, Validation Loss: 66.06
2025-02-25 14:38:59,384 - Epoch 30, Training Loss: 71.52, Validation Loss: 65.50
2025-02-25 14:38:59,595 - Epoch 31, Training Loss: 74.10, Validation Loss: 66.15
2025-02-25 14:38:59,784 - Epoch 32, Training Loss: 70.88, Validation Loss: 66.00
2025-02-25 14:38:59,969 - Epoch 33, Training Loss: 68.77, Validation Loss: 65.78
2025-02-25 14:39:00,162 - Epoch 34, Training Loss: 67.50, Validation Loss: 65.43
2025-02-25 14:39:00,374 - Epoch 35, Training Loss: 66.26, Validation Loss: 65.76
2025-02-25 14:39:00,560 - Epoch 36, Training Loss: 66.44, Validation Loss: 66.82
2025-02-25 14:39:00,752 - Epoch 37, Training Loss: 79.58, Validation Loss: 66.62
2025-02-25 14:39:00,957 - Epoch 38, Training Loss: 76.85, Validation Loss: 64.93
2025-02-25 14:39:01,175 - Epoch 39, Training Loss: 71.43, Validation Loss: 64.30
2025-02-25 14:39:01,386 - Epoch 40, Training Loss: 70.06, Validation Loss: 64.40
2025-02-25 14:39:01,573 - Epoch 41, Training Loss: 66.33, Validation Loss: 64.13
2025-02-25 14:39:01,785 - Epoch 42, Training Loss: 73.18, Validation Loss: 63.49
2025-02-25 14:39:01,996 - Epoch 43, Training Loss: 71.49, Validation Loss: 64.46
2025-02-25 14:39:02,184 - Epoch 44, Training Loss: 65.52, Validation Loss: 66.07
2025-02-25 14:39:02,366 - Epoch 45, Training Loss: 79.36, Validation Loss: 66.14
2025-02-25 14:39:02,562 - Epoch 46, Training Loss: 74.01, Validation Loss: 64.21
2025-02-25 14:39:02,746 - Epoch 47, Training Loss: 75.77, Validation Loss: 62.83
2025-02-25 14:39:02,970 - Epoch 48, Training Loss: 66.04, Validation Loss: 62.43
2025-02-25 14:39:03,186 - Epoch 49, Training Loss: 67.98, Validation Loss: 62.52
2025-02-25 14:39:03,374 - Epoch 50, Training Loss: 75.57, Validation Loss: 62.99
2025-02-25 14:39:03,564 - Epoch 51, Training Loss: 68.38, Validation Loss: 64.85
2025-02-25 14:39:03,752 - Epoch 52, Training Loss: 65.02, Validation Loss: 65.15
2025-02-25 14:39:03,951 - Epoch 53, Training Loss: 68.37, Validation Loss: 65.56
2025-02-25 14:39:04,141 - Epoch 54, Training Loss: 69.31, Validation Loss: 65.38
2025-02-25 14:39:04,327 - Epoch 55, Training Loss: 76.32, Validation Loss: 65.64
2025-02-25 14:39:04,519 - Epoch 56, Training Loss: 71.22, Validation Loss: 66.12
2025-02-25 14:39:04,719 - Epoch 57, Training Loss: 76.21, Validation Loss: 64.80
2025-02-25 14:39:04,915 - Epoch 58, Training Loss: 65.24, Validation Loss: 63.33
2025-02-25 14:39:05,107 - Epoch 59, Training Loss: 71.18, Validation Loss: 63.15
2025-02-25 14:39:05,290 - Epoch 60, Training Loss: 66.48, Validation Loss: 62.92
2025-02-25 14:39:05,487 - Epoch 61, Training Loss: 79.07, Validation Loss: 62.62
2025-02-25 14:39:05,672 - Epoch 62, Training Loss: 81.39, Validation Loss: 61.42
2025-02-25 14:39:05,887 - Epoch 63, Training Loss: 79.51, Validation Loss: 60.72
2025-02-25 14:39:06,099 - Epoch 64, Training Loss: 70.91, Validation Loss: 60.63
2025-02-25 14:39:06,310 - Epoch 65, Training Loss: 73.26, Validation Loss: 61.87
2025-02-25 14:39:06,500 - Epoch 66, Training Loss: 70.30, Validation Loss: 61.89
2025-02-25 14:39:06,688 - Epoch 67, Training Loss: 69.82, Validation Loss: 62.48
2025-02-25 14:39:06,879 - Epoch 68, Training Loss: 69.60, Validation Loss: 62.69
2025-02-25 14:39:07,068 - Epoch 69, Training Loss: 68.16, Validation Loss: 62.63
2025-02-25 14:39:07,269 - Epoch 70, Training Loss: 69.29, Validation Loss: 62.19
2025-02-25 14:39:07,460 - Epoch 71, Training Loss: 70.36, Validation Loss: 62.02
2025-02-25 14:39:07,647 - Epoch 72, Training Loss: 76.97, Validation Loss: 61.69
2025-02-25 14:39:07,837 - Epoch 73, Training Loss: 76.31, Validation Loss: 61.17
2025-02-25 14:39:08,023 - Epoch 74, Training Loss: 73.56, Validation Loss: 61.22
2025-02-25 14:39:08,208 - Epoch 75, Training Loss: 63.63, Validation Loss: 62.08
2025-02-25 14:39:08,404 - Epoch 76, Training Loss: 78.55, Validation Loss: 62.34
2025-02-25 14:39:08,593 - Epoch 77, Training Loss: 72.64, Validation Loss: 63.08
2025-02-25 14:39:08,781 - Epoch 78, Training Loss: 68.24, Validation Loss: 62.89
2025-02-25 14:39:08,968 - Epoch 79, Training Loss: 68.36, Validation Loss: 63.01
2025-02-25 14:39:09,159 - Epoch 80, Training Loss: 76.43, Validation Loss: 63.60
2025-02-25 14:39:09,344 - Epoch 81, Training Loss: 68.46, Validation Loss: 65.00
2025-02-25 14:39:09,541 - Epoch 82, Training Loss: 69.04, Validation Loss: 66.15
2025-02-25 14:39:09,724 - Epoch 83, Training Loss: 73.64, Validation Loss: 65.64
2025-02-25 14:39:09,918 - Epoch 84, Training Loss: 69.96, Validation Loss: 63.78
2025-02-25 14:39:09,918 - Early stopping at epoch 84 due to no improvement in validation loss.
2025-02-25 14:39:10,134 - learning rate: 0.05
2025-02-25 14:39:10,134 - Test RMSE: 7.016652584075928, Test MAE: 1.1418729424476624
2025-02-25 14:39:19,352 - -----------------------Starting training-------------------------
2025-02-25 14:39:19,352 - learning rate: 0.02
2025-02-25 14:39:19,558 - Epoch 1, Training Loss: 153.32, Validation Loss: 201.67
2025-02-25 14:39:19,774 - Epoch 2, Training Loss: 162.10, Validation Loss: 186.03
2025-02-25 14:39:19,980 - Epoch 3, Training Loss: 148.49, Validation Loss: 172.72
2025-02-25 14:39:20,199 - Epoch 4, Training Loss: 130.14, Validation Loss: 161.39
2025-02-25 14:39:20,401 - Epoch 5, Training Loss: 149.71, Validation Loss: 152.09
2025-02-25 14:39:20,620 - Epoch 6, Training Loss: 109.37, Validation Loss: 143.68
2025-02-25 14:39:20,949 - Epoch 7, Training Loss: 111.55, Validation Loss: 136.82
2025-02-25 14:39:21,613 - Epoch 8, Training Loss: 109.70, Validation Loss: 130.86
2025-02-25 14:39:21,829 - Epoch 9, Training Loss: 115.08, Validation Loss: 125.49
2025-02-25 14:39:22,057 - Epoch 10, Training Loss: 116.34, Validation Loss: 120.52
2025-02-25 14:39:22,261 - Epoch 11, Training Loss: 91.60, Validation Loss: 115.91
2025-02-25 14:39:22,477 - Epoch 12, Training Loss: 97.09, Validation Loss: 111.97
2025-02-25 14:39:22,690 - Epoch 13, Training Loss: 111.25, Validation Loss: 108.42
2025-02-25 14:39:22,898 - Epoch 14, Training Loss: 98.39, Validation Loss: 105.03
2025-02-25 14:39:23,116 - Epoch 15, Training Loss: 98.52, Validation Loss: 102.22
2025-02-25 14:39:23,324 - Epoch 16, Training Loss: 106.31, Validation Loss: 99.19
2025-02-25 14:39:23,537 - Epoch 17, Training Loss: 79.47, Validation Loss: 96.66
2025-02-25 14:39:23,757 - Epoch 18, Training Loss: 84.68, Validation Loss: 95.01
2025-02-25 14:39:24,450 - Epoch 19, Training Loss: 87.47, Validation Loss: 93.39
2025-02-25 14:39:24,661 - Epoch 20, Training Loss: 87.93, Validation Loss: 91.49
2025-02-25 14:39:25,553 - Epoch 21, Training Loss: 101.37, Validation Loss: 89.62
2025-02-25 14:39:25,777 - Epoch 22, Training Loss: 76.46, Validation Loss: 87.89
2025-02-25 14:39:26,029 - Epoch 23, Training Loss: 75.23, Validation Loss: 86.45
2025-02-25 14:39:26,367 - Epoch 24, Training Loss: 76.47, Validation Loss: 85.36
2025-02-25 14:39:26,616 - Epoch 25, Training Loss: 81.60, Validation Loss: 84.18
2025-02-25 14:39:26,856 - Epoch 26, Training Loss: 74.26, Validation Loss: 83.19
2025-02-25 14:39:27,073 - Epoch 27, Training Loss: 74.33, Validation Loss: 82.22
2025-02-25 14:39:27,289 - Epoch 28, Training Loss: 73.92, Validation Loss: 81.16
2025-02-25 14:39:27,510 - Epoch 29, Training Loss: 80.87, Validation Loss: 80.11
2025-02-25 14:39:27,723 - Epoch 30, Training Loss: 73.30, Validation Loss: 79.10
2025-02-25 14:39:27,941 - Epoch 31, Training Loss: 79.76, Validation Loss: 78.69
2025-02-25 14:39:28,143 - Epoch 32, Training Loss: 73.88, Validation Loss: 77.99
2025-02-25 14:39:28,365 - Epoch 33, Training Loss: 72.73, Validation Loss: 77.25
2025-02-25 14:39:28,580 - Epoch 34, Training Loss: 70.85, Validation Loss: 76.49
2025-02-25 14:39:28,788 - Epoch 35, Training Loss: 66.81, Validation Loss: 76.03
2025-02-25 14:39:28,997 - Epoch 36, Training Loss: 68.75, Validation Loss: 76.04
2025-02-25 14:39:29,197 - Epoch 37, Training Loss: 84.89, Validation Loss: 75.60
2025-02-25 14:39:29,408 - Epoch 38, Training Loss: 80.17, Validation Loss: 74.24
2025-02-25 14:39:29,618 - Epoch 39, Training Loss: 73.22, Validation Loss: 73.26
2025-02-25 14:39:29,829 - Epoch 40, Training Loss: 72.13, Validation Loss: 73.31
2025-02-25 14:39:30,015 - Epoch 41, Training Loss: 70.73, Validation Loss: 72.78
2025-02-25 14:39:30,221 - Epoch 42, Training Loss: 74.56, Validation Loss: 71.47
2025-02-25 14:39:30,431 - Epoch 43, Training Loss: 71.09, Validation Loss: 71.36
2025-02-25 14:39:30,647 - Epoch 44, Training Loss: 66.23, Validation Loss: 71.66
2025-02-25 14:39:30,844 - Epoch 45, Training Loss: 81.32, Validation Loss: 71.41
2025-02-25 14:39:31,030 - Epoch 46, Training Loss: 76.47, Validation Loss: 70.14
2025-02-25 14:39:31,251 - Epoch 47, Training Loss: 77.23, Validation Loss: 68.93
2025-02-25 14:39:31,469 - Epoch 48, Training Loss: 67.10, Validation Loss: 68.14
2025-02-25 14:39:31,683 - Epoch 49, Training Loss: 69.84, Validation Loss: 67.69
2025-02-25 14:39:31,892 - Epoch 50, Training Loss: 73.33, Validation Loss: 67.52
2025-02-25 14:39:32,100 - Epoch 51, Training Loss: 69.13, Validation Loss: 68.20
2025-02-25 14:39:32,294 - Epoch 52, Training Loss: 64.36, Validation Loss: 68.36
2025-02-25 14:39:32,481 - Epoch 53, Training Loss: 68.74, Validation Loss: 68.49
2025-02-25 14:39:32,675 - Epoch 54, Training Loss: 69.13, Validation Loss: 68.34
2025-02-25 14:39:32,862 - Epoch 55, Training Loss: 75.85, Validation Loss: 68.41
2025-02-25 14:39:33,057 - Epoch 56, Training Loss: 71.78, Validation Loss: 68.86
2025-02-25 14:39:33,244 - Epoch 57, Training Loss: 76.89, Validation Loss: 67.93
2025-02-25 14:39:33,433 - Epoch 58, Training Loss: 65.33, Validation Loss: 66.72
2025-02-25 14:39:33,643 - Epoch 59, Training Loss: 71.40, Validation Loss: 66.21
2025-02-25 14:39:33,856 - Epoch 60, Training Loss: 66.65, Validation Loss: 65.72
2025-02-25 14:39:34,079 - Epoch 61, Training Loss: 80.04, Validation Loss: 65.32
2025-02-25 14:39:34,295 - Epoch 62, Training Loss: 81.93, Validation Loss: 64.31
2025-02-25 14:39:34,516 - Epoch 63, Training Loss: 80.71, Validation Loss: 63.58
2025-02-25 14:39:34,725 - Epoch 64, Training Loss: 69.02, Validation Loss: 63.35
2025-02-25 14:39:34,950 - Epoch 65, Training Loss: 73.26, Validation Loss: 63.89
2025-02-25 14:39:35,152 - Epoch 66, Training Loss: 69.98, Validation Loss: 63.82
2025-02-25 14:39:35,348 - Epoch 67, Training Loss: 69.42, Validation Loss: 63.88
2025-02-25 14:39:35,534 - Epoch 68, Training Loss: 69.47, Validation Loss: 63.85
2025-02-25 14:39:35,727 - Epoch 69, Training Loss: 68.04, Validation Loss: 63.72
2025-02-25 14:39:35,921 - Epoch 70, Training Loss: 69.45, Validation Loss: 63.81
2025-02-25 14:39:36,119 - Epoch 71, Training Loss: 70.17, Validation Loss: 63.40
2025-02-25 14:39:36,306 - Epoch 72, Training Loss: 76.83, Validation Loss: 62.92
2025-02-25 14:39:36,520 - Epoch 73, Training Loss: 76.05, Validation Loss: 62.41
2025-02-25 14:39:36,744 - Epoch 74, Training Loss: 72.83, Validation Loss: 62.89
2025-02-25 14:39:36,938 - Epoch 75, Training Loss: 63.28, Validation Loss: 63.47
2025-02-25 14:39:37,149 - Epoch 76, Training Loss: 78.01, Validation Loss: 63.48
2025-02-25 14:39:37,353 - Epoch 77, Training Loss: 72.60, Validation Loss: 64.33
2025-02-25 14:39:37,552 - Epoch 78, Training Loss: 67.94, Validation Loss: 64.45
2025-02-25 14:39:37,749 - Epoch 79, Training Loss: 67.88, Validation Loss: 65.01
2025-02-25 14:39:37,945 - Epoch 80, Training Loss: 75.64, Validation Loss: 68.13
2025-02-25 14:39:38,139 - Epoch 81, Training Loss: 67.61, Validation Loss: 68.10
2025-02-25 14:39:38,330 - Epoch 82, Training Loss: 68.94, Validation Loss: 68.36
2025-02-25 14:39:38,516 - Epoch 83, Training Loss: 74.66, Validation Loss: 67.53
2025-02-25 14:39:38,710 - Epoch 84, Training Loss: 70.14, Validation Loss: 64.70
2025-02-25 14:39:38,894 - Epoch 85, Training Loss: 69.21, Validation Loss: 63.61
2025-02-25 14:39:39,086 - Epoch 86, Training Loss: 75.33, Validation Loss: 63.30
2025-02-25 14:39:39,271 - Epoch 87, Training Loss: 69.50, Validation Loss: 63.89
2025-02-25 14:39:39,470 - Epoch 88, Training Loss: 68.44, Validation Loss: 64.33
2025-02-25 14:39:39,657 - Epoch 89, Training Loss: 63.01, Validation Loss: 64.40
2025-02-25 14:39:39,850 - Epoch 90, Training Loss: 67.99, Validation Loss: 63.75
2025-02-25 14:39:40,033 - Epoch 91, Training Loss: 65.85, Validation Loss: 66.99
2025-02-25 14:39:40,221 - Epoch 92, Training Loss: 72.99, Validation Loss: 65.28
2025-02-25 14:39:40,405 - Epoch 93, Training Loss: 68.45, Validation Loss: 64.24
2025-02-25 14:39:40,405 - Early stopping at epoch 93 due to no improvement in validation loss.
2025-02-25 14:39:40,637 - learning rate: 0.02
2025-02-25 14:39:40,637 - Test RMSE: 6.987890720367432, Test MAE: 1.1916662156581879
2025-02-25 14:39:47,468 - -----------------------Starting training-------------------------
2025-02-25 14:39:47,468 - learning rate: 0.005
2025-02-25 14:39:47,670 - Epoch 1, Training Loss: 157.00, Validation Loss: 217.28
2025-02-25 14:39:47,894 - Epoch 2, Training Loss: 175.12, Validation Loss: 207.11
2025-02-25 14:39:48,116 - Epoch 3, Training Loss: 165.30, Validation Loss: 197.55
2025-02-25 14:39:48,324 - Epoch 4, Training Loss: 147.76, Validation Loss: 189.67
2025-02-25 14:39:48,547 - Epoch 5, Training Loss: 174.66, Validation Loss: 182.67
2025-02-25 14:39:48,753 - Epoch 6, Training Loss: 128.35, Validation Loss: 176.16
2025-02-25 14:39:48,969 - Epoch 7, Training Loss: 133.80, Validation Loss: 170.42
2025-02-25 14:39:49,177 - Epoch 8, Training Loss: 133.63, Validation Loss: 165.15
2025-02-25 14:39:49,385 - Epoch 9, Training Loss: 138.67, Validation Loss: 160.29
2025-02-25 14:39:49,597 - Epoch 10, Training Loss: 143.65, Validation Loss: 155.77
2025-02-25 14:39:49,805 - Epoch 11, Training Loss: 114.27, Validation Loss: 151.53
2025-02-25 14:39:50,016 - Epoch 12, Training Loss: 121.09, Validation Loss: 147.70
2025-02-25 14:39:50,225 - Epoch 13, Training Loss: 138.99, Validation Loss: 144.16
2025-02-25 14:39:50,438 - Epoch 14, Training Loss: 122.35, Validation Loss: 140.76
2025-02-25 14:39:50,651 - Epoch 15, Training Loss: 124.94, Validation Loss: 137.71
2025-02-25 14:39:50,866 - Epoch 16, Training Loss: 135.01, Validation Loss: 134.59
2025-02-25 14:39:51,073 - Epoch 17, Training Loss: 97.87, Validation Loss: 131.74
2025-02-25 14:39:51,281 - Epoch 18, Training Loss: 104.63, Validation Loss: 129.38
2025-02-25 14:39:51,490 - Epoch 19, Training Loss: 112.85, Validation Loss: 127.15
2025-02-25 14:39:51,697 - Epoch 20, Training Loss: 111.49, Validation Loss: 124.84
2025-02-25 14:39:51,907 - Epoch 21, Training Loss: 129.20, Validation Loss: 122.57
2025-02-25 14:39:52,118 - Epoch 22, Training Loss: 95.75, Validation Loss: 120.40
2025-02-25 14:39:52,329 - Epoch 23, Training Loss: 94.61, Validation Loss: 118.42
2025-02-25 14:39:52,544 - Epoch 24, Training Loss: 96.66, Validation Loss: 116.66
2025-02-25 14:39:52,752 - Epoch 25, Training Loss: 100.22, Validation Loss: 114.90
2025-02-25 14:39:52,963 - Epoch 26, Training Loss: 92.90, Validation Loss: 113.27
2025-02-25 14:39:53,169 - Epoch 27, Training Loss: 93.43, Validation Loss: 111.67
2025-02-25 14:39:53,378 - Epoch 28, Training Loss: 91.98, Validation Loss: 110.07
2025-02-25 14:39:53,587 - Epoch 29, Training Loss: 101.76, Validation Loss: 108.50
2025-02-25 14:39:53,797 - Epoch 30, Training Loss: 84.43, Validation Loss: 106.98
2025-02-25 14:39:54,007 - Epoch 31, Training Loss: 98.91, Validation Loss: 105.80
2025-02-25 14:39:54,226 - Epoch 32, Training Loss: 88.50, Validation Loss: 104.57
2025-02-25 14:39:54,435 - Epoch 33, Training Loss: 88.51, Validation Loss: 103.36
2025-02-25 14:39:54,644 - Epoch 34, Training Loss: 85.53, Validation Loss: 102.13
2025-02-25 14:39:54,857 - Epoch 35, Training Loss: 75.89, Validation Loss: 101.05
2025-02-25 14:39:55,065 - Epoch 36, Training Loss: 80.70, Validation Loss: 100.28
2025-02-25 14:39:55,276 - Epoch 37, Training Loss: 103.88, Validation Loss: 99.35
2025-02-25 14:39:55,484 - Epoch 38, Training Loss: 94.78, Validation Loss: 97.94
2025-02-25 14:39:55,698 - Epoch 39, Training Loss: 85.90, Validation Loss: 96.65
2025-02-25 14:39:55,912 - Epoch 40, Training Loss: 83.73, Validation Loss: 95.54
2025-02-25 14:39:56,122 - Epoch 41, Training Loss: 85.95, Validation Loss: 94.52
2025-02-25 14:39:56,337 - Epoch 42, Training Loss: 86.55, Validation Loss: 93.37
2025-02-25 14:39:56,556 - Epoch 43, Training Loss: 77.64, Validation Loss: 92.52
2025-02-25 14:39:56,776 - Epoch 44, Training Loss: 75.82, Validation Loss: 92.02
2025-02-25 14:39:56,985 - Epoch 45, Training Loss: 96.90, Validation Loss: 91.39
2025-02-25 14:39:57,194 - Epoch 46, Training Loss: 90.57, Validation Loss: 90.25
2025-02-25 14:39:57,415 - Epoch 47, Training Loss: 88.66, Validation Loss: 89.10
2025-02-25 14:39:57,621 - Epoch 48, Training Loss: 78.97, Validation Loss: 88.08
2025-02-25 14:39:57,838 - Epoch 49, Training Loss: 81.65, Validation Loss: 87.20
2025-02-25 14:39:58,053 - Epoch 50, Training Loss: 74.49, Validation Loss: 86.48
2025-02-25 14:39:58,268 - Epoch 51, Training Loss: 78.66, Validation Loss: 86.21
2025-02-25 14:39:58,479 - Epoch 52, Training Loss: 69.75, Validation Loss: 85.78
2025-02-25 14:39:58,686 - Epoch 53, Training Loss: 77.22, Validation Loss: 85.36
2025-02-25 14:39:58,901 - Epoch 54, Training Loss: 75.23, Validation Loss: 84.86
2025-02-25 14:39:59,107 - Epoch 55, Training Loss: 80.09, Validation Loss: 84.47
2025-02-25 14:39:59,317 - Epoch 56, Training Loss: 80.45, Validation Loss: 84.21
2025-02-25 14:39:59,538 - Epoch 57, Training Loss: 88.41, Validation Loss: 83.58
2025-02-25 14:39:59,742 - Epoch 58, Training Loss: 71.30, Validation Loss: 82.75
2025-02-25 14:39:59,955 - Epoch 59, Training Loss: 79.02, Validation Loss: 82.09
2025-02-25 14:40:00,171 - Epoch 60, Training Loss: 74.46, Validation Loss: 81.43
2025-02-25 14:40:00,388 - Epoch 61, Training Loss: 91.07, Validation Loss: 80.76
2025-02-25 14:40:00,599 - Epoch 62, Training Loss: 90.50, Validation Loss: 79.88
2025-02-25 14:40:00,812 - Epoch 63, Training Loss: 92.83, Validation Loss: 79.04
2025-02-25 14:40:01,044 - Epoch 64, Training Loss: 70.34, Validation Loss: 78.32
2025-02-25 14:40:01,246 - Epoch 65, Training Loss: 81.70, Validation Loss: 77.97
2025-02-25 14:40:01,460 - Epoch 66, Training Loss: 75.94, Validation Loss: 77.51
2025-02-25 14:40:01,670 - Epoch 67, Training Loss: 74.47, Validation Loss: 77.19
2025-02-25 14:40:01,879 - Epoch 68, Training Loss: 74.82, Validation Loss: 76.81
2025-02-25 14:40:02,092 - Epoch 69, Training Loss: 73.40, Validation Loss: 76.41
2025-02-25 14:40:02,301 - Epoch 70, Training Loss: 74.79, Validation Loss: 75.94
2025-02-25 14:40:02,520 - Epoch 71, Training Loss: 75.52, Validation Loss: 75.53
2025-02-25 14:40:02,735 - Epoch 72, Training Loss: 83.67, Validation Loss: 75.11
2025-02-25 14:40:02,949 - Epoch 73, Training Loss: 80.28, Validation Loss: 74.65
2025-02-25 14:40:03,172 - Epoch 74, Training Loss: 74.47, Validation Loss: 74.26
2025-02-25 14:40:03,378 - Epoch 75, Training Loss: 68.05, Validation Loss: 74.09
2025-02-25 14:40:03,590 - Epoch 76, Training Loss: 80.35, Validation Loss: 73.87
2025-02-25 14:40:03,798 - Epoch 77, Training Loss: 76.09, Validation Loss: 73.78
2025-02-25 14:40:04,012 - Epoch 78, Training Loss: 70.55, Validation Loss: 73.54
2025-02-25 14:40:04,219 - Epoch 79, Training Loss: 70.16, Validation Loss: 73.36
2025-02-25 14:40:04,430 - Epoch 80, Training Loss: 78.00, Validation Loss: 73.27
2025-02-25 14:40:04,634 - Epoch 81, Training Loss: 68.90, Validation Loss: 73.36
2025-02-25 14:40:04,824 - Epoch 82, Training Loss: 71.27, Validation Loss: 73.49
2025-02-25 14:40:05,019 - Epoch 83, Training Loss: 77.29, Validation Loss: 73.33
2025-02-25 14:40:05,203 - Epoch 84, Training Loss: 73.25, Validation Loss: 72.79
2025-02-25 14:40:05,413 - Epoch 85, Training Loss: 71.95, Validation Loss: 72.29
2025-02-25 14:40:05,626 - Epoch 86, Training Loss: 77.15, Validation Loss: 71.95
2025-02-25 14:40:05,838 - Epoch 87, Training Loss: 71.06, Validation Loss: 71.82
2025-02-25 14:40:06,046 - Epoch 88, Training Loss: 69.99, Validation Loss: 71.70
2025-02-25 14:40:06,260 - Epoch 89, Training Loss: 65.29, Validation Loss: 71.59
2025-02-25 14:40:06,468 - Epoch 90, Training Loss: 68.81, Validation Loss: 71.46
2025-02-25 14:40:06,681 - Epoch 91, Training Loss: 68.16, Validation Loss: 71.43
2025-02-25 14:40:06,887 - Epoch 92, Training Loss: 75.17, Validation Loss: 71.06
2025-02-25 14:40:07,097 - Epoch 93, Training Loss: 70.71, Validation Loss: 70.70
2025-02-25 14:40:07,312 - Epoch 94, Training Loss: 69.79, Validation Loss: 70.47
2025-02-25 14:40:07,521 - Epoch 95, Training Loss: 67.95, Validation Loss: 70.51
2025-02-25 14:40:07,710 - Epoch 96, Training Loss: 67.04, Validation Loss: 70.54
2025-02-25 14:40:07,901 - Epoch 97, Training Loss: 63.94, Validation Loss: 70.59
2025-02-25 14:40:08,089 - Epoch 98, Training Loss: 71.04, Validation Loss: 70.71
2025-02-25 14:40:08,279 - Epoch 99, Training Loss: 79.87, Validation Loss: 71.70
2025-02-25 14:40:08,476 - Epoch 100, Training Loss: 71.14, Validation Loss: 71.62
2025-02-25 14:40:08,668 - Epoch 101, Training Loss: 71.55, Validation Loss: 72.59
2025-02-25 14:40:08,860 - Epoch 102, Training Loss: 74.56, Validation Loss: 72.78
2025-02-25 14:40:09,049 - Epoch 103, Training Loss: 64.33, Validation Loss: 73.82
2025-02-25 14:40:09,244 - Epoch 104, Training Loss: 75.43, Validation Loss: 73.05
2025-02-25 14:40:09,442 - Epoch 105, Training Loss: 76.94, Validation Loss: 72.51
2025-02-25 14:40:09,633 - Epoch 106, Training Loss: 67.76, Validation Loss: 71.92
2025-02-25 14:40:09,824 - Epoch 107, Training Loss: 69.99, Validation Loss: 71.91
2025-02-25 14:40:10,012 - Epoch 108, Training Loss: 69.32, Validation Loss: 71.96
2025-02-25 14:40:10,197 - Epoch 109, Training Loss: 66.56, Validation Loss: 70.96
2025-02-25 14:40:10,384 - Epoch 110, Training Loss: 72.70, Validation Loss: 70.53
2025-02-25 14:40:10,571 - Epoch 111, Training Loss: 74.17, Validation Loss: 69.92
2025-02-25 14:40:10,795 - Epoch 112, Training Loss: 70.43, Validation Loss: 69.39
2025-02-25 14:40:11,005 - Epoch 113, Training Loss: 75.99, Validation Loss: 69.15
2025-02-25 14:40:11,215 - Epoch 114, Training Loss: 66.33, Validation Loss: 69.40
2025-02-25 14:40:11,405 - Epoch 115, Training Loss: 74.09, Validation Loss: 68.81
2025-02-25 14:40:11,611 - Epoch 116, Training Loss: 70.65, Validation Loss: 68.70
2025-02-25 14:40:11,820 - Epoch 117, Training Loss: 77.78, Validation Loss: 68.93
2025-02-25 14:40:12,013 - Epoch 118, Training Loss: 71.38, Validation Loss: 68.90
2025-02-25 14:40:12,201 - Epoch 119, Training Loss: 70.31, Validation Loss: 68.89
2025-02-25 14:40:12,386 - Epoch 120, Training Loss: 66.33, Validation Loss: 68.70
2025-02-25 14:40:12,592 - Epoch 121, Training Loss: 78.73, Validation Loss: 68.52
2025-02-25 14:40:12,802 - Epoch 122, Training Loss: 74.25, Validation Loss: 68.07
2025-02-25 14:40:13,008 - Epoch 123, Training Loss: 69.92, Validation Loss: 67.61
2025-02-25 14:40:13,216 - Epoch 124, Training Loss: 75.21, Validation Loss: 67.64
2025-02-25 14:40:13,414 - Epoch 125, Training Loss: 78.25, Validation Loss: 67.66
2025-02-25 14:40:13,601 - Epoch 126, Training Loss: 73.62, Validation Loss: 67.45
2025-02-25 14:40:13,810 - Epoch 127, Training Loss: 66.40, Validation Loss: 67.40
2025-02-25 14:40:14,021 - Epoch 128, Training Loss: 78.63, Validation Loss: 67.08
2025-02-25 14:40:14,234 - Epoch 129, Training Loss: 69.55, Validation Loss: 67.01
2025-02-25 14:40:14,440 - Epoch 130, Training Loss: 70.06, Validation Loss: 67.18
2025-02-25 14:40:14,642 - Epoch 131, Training Loss: 69.44, Validation Loss: 67.06
2025-02-25 14:40:14,825 - Epoch 132, Training Loss: 74.15, Validation Loss: 66.79
2025-02-25 14:40:15,035 - Epoch 133, Training Loss: 64.86, Validation Loss: 66.58
2025-02-25 14:40:15,242 - Epoch 134, Training Loss: 75.06, Validation Loss: 66.47
2025-02-25 14:40:15,455 - Epoch 135, Training Loss: 77.45, Validation Loss: 66.31
2025-02-25 14:40:15,664 - Epoch 136, Training Loss: 70.28, Validation Loss: 66.00
2025-02-25 14:40:15,887 - Epoch 137, Training Loss: 69.65, Validation Loss: 65.98
2025-02-25 14:40:16,094 - Epoch 138, Training Loss: 68.13, Validation Loss: 65.86
2025-02-25 14:40:16,301 - Epoch 139, Training Loss: 69.45, Validation Loss: 66.11
2025-02-25 14:40:16,490 - Epoch 140, Training Loss: 76.21, Validation Loss: 66.20
2025-02-25 14:40:16,679 - Epoch 141, Training Loss: 77.79, Validation Loss: 65.98
2025-02-25 14:40:16,866 - Epoch 142, Training Loss: 68.64, Validation Loss: 65.60
2025-02-25 14:40:17,073 - Epoch 143, Training Loss: 76.79, Validation Loss: 65.52
2025-02-25 14:40:17,277 - Epoch 144, Training Loss: 71.83, Validation Loss: 65.33
2025-02-25 14:40:17,483 - Epoch 145, Training Loss: 78.06, Validation Loss: 64.91
2025-02-25 14:40:17,693 - Epoch 146, Training Loss: 67.60, Validation Loss: 64.24
2025-02-25 14:40:17,902 - Epoch 147, Training Loss: 75.64, Validation Loss: 63.91
2025-02-25 14:40:18,110 - Epoch 148, Training Loss: 75.25, Validation Loss: 63.78
2025-02-25 14:40:18,324 - Epoch 149, Training Loss: 65.85, Validation Loss: 63.69
2025-02-25 14:40:18,540 - Epoch 150, Training Loss: 67.77, Validation Loss: 63.62
2025-02-25 14:40:18,752 - Epoch 151, Training Loss: 73.27, Validation Loss: 63.66
2025-02-25 14:40:18,938 - Epoch 152, Training Loss: 69.49, Validation Loss: 63.55
2025-02-25 14:40:19,149 - Epoch 153, Training Loss: 68.34, Validation Loss: 63.53
2025-02-25 14:40:19,356 - Epoch 154, Training Loss: 77.17, Validation Loss: 64.17
2025-02-25 14:40:19,553 - Epoch 155, Training Loss: 74.93, Validation Loss: 64.33
2025-02-25 14:40:19,746 - Epoch 156, Training Loss: 70.24, Validation Loss: 64.24
2025-02-25 14:40:19,939 - Epoch 157, Training Loss: 76.47, Validation Loss: 64.38
2025-02-25 14:40:20,135 - Epoch 158, Training Loss: 68.95, Validation Loss: 64.81
2025-02-25 14:40:20,325 - Epoch 159, Training Loss: 73.80, Validation Loss: 65.01
2025-02-25 14:40:20,523 - Epoch 160, Training Loss: 74.03, Validation Loss: 64.86
2025-02-25 14:40:20,705 - Epoch 161, Training Loss: 67.29, Validation Loss: 64.85
2025-02-25 14:40:20,899 - Epoch 162, Training Loss: 75.13, Validation Loss: 64.64
2025-02-25 14:40:21,083 - Epoch 163, Training Loss: 62.95, Validation Loss: 64.54
2025-02-25 14:40:21,273 - Epoch 164, Training Loss: 71.94, Validation Loss: 64.63
2025-02-25 14:40:21,460 - Epoch 165, Training Loss: 74.69, Validation Loss: 64.92
2025-02-25 14:40:21,649 - Epoch 166, Training Loss: 66.94, Validation Loss: 64.96
2025-02-25 14:40:21,841 - Epoch 167, Training Loss: 75.75, Validation Loss: 65.14
2025-02-25 14:40:22,033 - Epoch 168, Training Loss: 79.42, Validation Loss: 64.56
2025-02-25 14:40:22,220 - Epoch 169, Training Loss: 77.33, Validation Loss: 64.33
2025-02-25 14:40:22,409 - Epoch 170, Training Loss: 75.31, Validation Loss: 64.03
2025-02-25 14:40:22,593 - Epoch 171, Training Loss: 69.46, Validation Loss: 63.62
2025-02-25 14:40:22,785 - Epoch 172, Training Loss: 68.33, Validation Loss: 63.38
2025-02-25 14:40:22,987 - Epoch 173, Training Loss: 76.88, Validation Loss: 63.32
2025-02-25 14:40:23,198 - Epoch 174, Training Loss: 68.17, Validation Loss: 63.25
2025-02-25 14:40:23,405 - Epoch 175, Training Loss: 68.96, Validation Loss: 63.09
2025-02-25 14:40:23,617 - Epoch 176, Training Loss: 73.22, Validation Loss: 63.18
2025-02-25 14:40:23,803 - Epoch 177, Training Loss: 71.36, Validation Loss: 63.28
2025-02-25 14:40:23,987 - Epoch 178, Training Loss: 69.11, Validation Loss: 63.70
2025-02-25 14:40:24,172 - Epoch 179, Training Loss: 69.40, Validation Loss: 64.17
2025-02-25 14:40:24,360 - Epoch 180, Training Loss: 70.59, Validation Loss: 64.70
2025-02-25 14:40:24,548 - Epoch 181, Training Loss: 67.36, Validation Loss: 65.19
2025-02-25 14:40:24,740 - Epoch 182, Training Loss: 63.31, Validation Loss: 65.73
2025-02-25 14:40:24,928 - Epoch 183, Training Loss: 67.55, Validation Loss: 66.26
2025-02-25 14:40:25,116 - Epoch 184, Training Loss: 70.04, Validation Loss: 66.10
2025-02-25 14:40:25,308 - Epoch 185, Training Loss: 69.67, Validation Loss: 66.88
2025-02-25 14:40:25,498 - Epoch 186, Training Loss: 80.31, Validation Loss: 66.15
2025-02-25 14:40:25,687 - Epoch 187, Training Loss: 79.11, Validation Loss: 65.64
2025-02-25 14:40:25,885 - Epoch 188, Training Loss: 68.96, Validation Loss: 65.35
2025-02-25 14:40:26,079 - Epoch 189, Training Loss: 70.62, Validation Loss: 65.03
2025-02-25 14:40:26,290 - Epoch 190, Training Loss: 67.05, Validation Loss: 66.86
2025-02-25 14:40:26,511 - Epoch 191, Training Loss: 66.20, Validation Loss: 64.49
2025-02-25 14:40:26,708 - Epoch 192, Training Loss: 76.56, Validation Loss: 65.37
2025-02-25 14:40:26,901 - Epoch 193, Training Loss: 73.14, Validation Loss: 64.02
2025-02-25 14:40:27,096 - Epoch 194, Training Loss: 71.87, Validation Loss: 62.96
2025-02-25 14:40:27,305 - Epoch 195, Training Loss: 65.14, Validation Loss: 69.62
2025-02-25 14:40:27,493 - Epoch 196, Training Loss: 77.24, Validation Loss: 62.91
2025-02-25 14:40:27,697 - Epoch 197, Training Loss: 65.95, Validation Loss: 64.94
2025-02-25 14:40:27,894 - Epoch 198, Training Loss: 69.94, Validation Loss: 64.80
2025-02-25 14:40:28,081 - Epoch 199, Training Loss: 71.71, Validation Loss: 62.89
2025-02-25 14:40:28,288 - Epoch 200, Training Loss: 72.27, Validation Loss: 61.69
2025-02-25 14:40:28,502 - Epoch 201, Training Loss: 69.45, Validation Loss: 64.18
2025-02-25 14:40:28,713 - Epoch 202, Training Loss: 70.47, Validation Loss: 57.89
2025-02-25 14:40:28,929 - Epoch 203, Training Loss: 56.87, Validation Loss: 55.49
2025-02-25 14:40:29,134 - Epoch 204, Training Loss: 75.78, Validation Loss: 57.72
2025-02-25 14:40:29,341 - Epoch 205, Training Loss: 66.02, Validation Loss: 60.34
2025-02-25 14:40:29,526 - Epoch 206, Training Loss: 63.05, Validation Loss: 60.34
2025-02-25 14:40:29,721 - Epoch 207, Training Loss: 76.09, Validation Loss: 60.39
2025-02-25 14:40:29,905 - Epoch 208, Training Loss: 71.89, Validation Loss: 60.93
2025-02-25 14:40:30,091 - Epoch 209, Training Loss: 67.85, Validation Loss: 63.43
2025-02-25 14:40:30,276 - Epoch 210, Training Loss: 61.75, Validation Loss: 65.49
2025-02-25 14:40:30,469 - Epoch 211, Training Loss: 60.54, Validation Loss: 64.78
2025-02-25 14:40:30,651 - Epoch 212, Training Loss: 57.70, Validation Loss: 58.71
2025-02-25 14:40:30,842 - Epoch 213, Training Loss: 61.92, Validation Loss: 59.29
2025-02-25 14:40:31,023 - Epoch 214, Training Loss: 71.95, Validation Loss: 59.38
2025-02-25 14:40:31,218 - Epoch 215, Training Loss: 77.42, Validation Loss: 61.36
2025-02-25 14:40:31,405 - Epoch 216, Training Loss: 63.06, Validation Loss: 60.94
2025-02-25 14:40:31,595 - Epoch 217, Training Loss: 77.90, Validation Loss: 60.86
2025-02-25 14:40:31,782 - Epoch 218, Training Loss: 77.79, Validation Loss: 61.15
2025-02-25 14:40:31,974 - Epoch 219, Training Loss: 72.83, Validation Loss: 61.13
2025-02-25 14:40:32,155 - Epoch 220, Training Loss: 68.35, Validation Loss: 61.18
2025-02-25 14:40:32,350 - Epoch 221, Training Loss: 65.66, Validation Loss: 61.90
2025-02-25 14:40:32,538 - Epoch 222, Training Loss: 74.39, Validation Loss: 61.75
2025-02-25 14:40:32,726 - Epoch 223, Training Loss: 68.69, Validation Loss: 61.75
2025-02-25 14:40:32,726 - Early stopping at epoch 223 due to no improvement in validation loss.
2025-02-25 14:40:32,981 - learning rate: 0.005
2025-02-25 14:40:32,981 - Test RMSE: 6.9350340366363525, Test MAE: 1.102683275938034
2025-02-25 14:40:59,610 - -----------------------Starting training-------------------------
2025-02-25 14:40:59,611 - learning rate: 0.002
2025-02-25 14:40:59,819 - Epoch 1, Training Loss: 157.33, Validation Loss: 220.35
2025-02-25 14:41:00,059 - Epoch 2, Training Loss: 179.52, Validation Loss: 217.45
2025-02-25 14:41:00,278 - Epoch 3, Training Loss: 174.62, Validation Loss: 211.92
2025-02-25 14:41:00,497 - Epoch 4, Training Loss: 158.51, Validation Loss: 206.29
2025-02-25 14:41:00,716 - Epoch 5, Training Loss: 189.87, Validation Loss: 201.60
2025-02-25 14:41:00,964 - Epoch 6, Training Loss: 141.28, Validation Loss: 197.57
2025-02-25 14:41:01,181 - Epoch 7, Training Loss: 149.68, Validation Loss: 193.95
2025-02-25 14:41:01,392 - Epoch 8, Training Loss: 151.64, Validation Loss: 190.55
2025-02-25 14:41:01,608 - Epoch 9, Training Loss: 157.34, Validation Loss: 187.33
2025-02-25 14:41:01,819 - Epoch 10, Training Loss: 165.72, Validation Loss: 184.25
2025-02-25 14:41:02,039 - Epoch 11, Training Loss: 133.99, Validation Loss: 181.31
2025-02-25 14:41:02,250 - Epoch 12, Training Loss: 142.54, Validation Loss: 178.56
2025-02-25 14:41:02,465 - Epoch 13, Training Loss: 163.72, Validation Loss: 175.96
2025-02-25 14:41:02,672 - Epoch 14, Training Loss: 144.50, Validation Loss: 173.45
2025-02-25 14:41:02,882 - Epoch 15, Training Loss: 150.55, Validation Loss: 171.12
2025-02-25 14:41:03,090 - Epoch 16, Training Loss: 162.18, Validation Loss: 168.79
2025-02-25 14:41:03,301 - Epoch 17, Training Loss: 117.35, Validation Loss: 166.59
2025-02-25 14:41:03,523 - Epoch 18, Training Loss: 126.40, Validation Loss: 164.64
2025-02-25 14:41:03,738 - Epoch 19, Training Loss: 139.79, Validation Loss: 162.79
2025-02-25 14:41:03,957 - Epoch 20, Training Loss: 137.22, Validation Loss: 160.93
2025-02-25 14:41:04,175 - Epoch 21, Training Loss: 158.85, Validation Loss: 159.10
2025-02-25 14:41:04,431 - Epoch 22, Training Loss: 119.06, Validation Loss: 157.33
2025-02-25 14:41:04,653 - Epoch 23, Training Loss: 118.56, Validation Loss: 155.65
2025-02-25 14:41:04,857 - Epoch 24, Training Loss: 122.31, Validation Loss: 154.08
2025-02-25 14:41:05,069 - Epoch 25, Training Loss: 124.67, Validation Loss: 152.53
2025-02-25 14:41:05,277 - Epoch 26, Training Loss: 117.76, Validation Loss: 151.05
2025-02-25 14:41:05,487 - Epoch 27, Training Loss: 119.68, Validation Loss: 149.60
2025-02-25 14:41:05,701 - Epoch 28, Training Loss: 118.25, Validation Loss: 148.17
2025-02-25 14:41:05,910 - Epoch 29, Training Loss: 131.35, Validation Loss: 146.75
2025-02-25 14:41:06,124 - Epoch 30, Training Loss: 104.03, Validation Loss: 145.36
2025-02-25 14:41:06,333 - Epoch 31, Training Loss: 127.23, Validation Loss: 144.12
2025-02-25 14:41:06,546 - Epoch 32, Training Loss: 113.32, Validation Loss: 142.88
2025-02-25 14:41:06,755 - Epoch 33, Training Loss: 114.93, Validation Loss: 141.67
2025-02-25 14:41:06,962 - Epoch 34, Training Loss: 110.59, Validation Loss: 140.46
2025-02-25 14:41:07,174 - Epoch 35, Training Loss: 95.04, Validation Loss: 139.31
2025-02-25 14:41:07,380 - Epoch 36, Training Loss: 104.04, Validation Loss: 138.30
2025-02-25 14:41:07,604 - Epoch 37, Training Loss: 136.44, Validation Loss: 137.26
2025-02-25 14:41:07,810 - Epoch 38, Training Loss: 122.47, Validation Loss: 136.02
2025-02-25 14:41:08,029 - Epoch 39, Training Loss: 111.36, Validation Loss: 134.83
2025-02-25 14:41:08,239 - Epoch 40, Training Loss: 108.59, Validation Loss: 133.70
2025-02-25 14:41:08,449 - Epoch 41, Training Loss: 115.34, Validation Loss: 132.62
2025-02-25 14:41:08,661 - Epoch 42, Training Loss: 112.03, Validation Loss: 131.49
2025-02-25 14:41:08,875 - Epoch 43, Training Loss: 96.16, Validation Loss: 130.49
2025-02-25 14:41:09,088 - Epoch 44, Training Loss: 98.87, Validation Loss: 129.64
2025-02-25 14:41:09,324 - Epoch 45, Training Loss: 129.45, Validation Loss: 128.78
2025-02-25 14:41:09,534 - Epoch 46, Training Loss: 119.85, Validation Loss: 127.71
2025-02-25 14:41:09,741 - Epoch 47, Training Loss: 114.74, Validation Loss: 126.61
2025-02-25 14:41:09,951 - Epoch 48, Training Loss: 105.15, Validation Loss: 125.56
2025-02-25 14:41:10,165 - Epoch 49, Training Loss: 108.12, Validation Loss: 124.57
2025-02-25 14:41:10,370 - Epoch 50, Training Loss: 87.75, Validation Loss: 123.64
2025-02-25 14:41:10,584 - Epoch 51, Training Loss: 102.79, Validation Loss: 122.92
2025-02-25 14:41:10,795 - Epoch 52, Training Loss: 90.01, Validation Loss: 122.18
2025-02-25 14:41:11,002 - Epoch 53, Training Loss: 100.51, Validation Loss: 121.47
2025-02-25 14:41:11,214 - Epoch 54, Training Loss: 95.39, Validation Loss: 120.75
2025-02-25 14:41:11,422 - Epoch 55, Training Loss: 98.06, Validation Loss: 120.06
2025-02-25 14:41:11,647 - Epoch 56, Training Loss: 104.91, Validation Loss: 119.44
2025-02-25 14:41:11,859 - Epoch 57, Training Loss: 117.88, Validation Loss: 118.68
2025-02-25 14:41:12,066 - Epoch 58, Training Loss: 91.45, Validation Loss: 117.83
2025-02-25 14:41:12,276 - Epoch 59, Training Loss: 102.17, Validation Loss: 117.05
2025-02-25 14:41:12,484 - Epoch 60, Training Loss: 98.23, Validation Loss: 116.25
2025-02-25 14:41:12,694 - Epoch 61, Training Loss: 121.71, Validation Loss: 115.45
2025-02-25 14:41:12,897 - Epoch 62, Training Loss: 116.98, Validation Loss: 114.55
2025-02-25 14:41:13,108 - Epoch 63, Training Loss: 125.33, Validation Loss: 113.66
2025-02-25 14:41:13,315 - Epoch 64, Training Loss: 85.07, Validation Loss: 112.80
2025-02-25 14:41:13,533 - Epoch 65, Training Loss: 109.21, Validation Loss: 112.11
2025-02-25 14:41:13,742 - Epoch 66, Training Loss: 98.48, Validation Loss: 111.38
2025-02-25 14:41:13,950 - Epoch 67, Training Loss: 94.38, Validation Loss: 110.72
2025-02-25 14:41:14,162 - Epoch 68, Training Loss: 96.16, Validation Loss: 110.08
2025-02-25 14:41:14,372 - Epoch 69, Training Loss: 94.91, Validation Loss: 109.44
2025-02-25 14:41:14,586 - Epoch 70, Training Loss: 96.56, Validation Loss: 108.76
2025-02-25 14:41:14,790 - Epoch 71, Training Loss: 98.08, Validation Loss: 108.13
2025-02-25 14:41:15,011 - Epoch 72, Training Loss: 110.62, Validation Loss: 107.48
2025-02-25 14:41:15,222 - Epoch 73, Training Loss: 101.65, Validation Loss: 106.81
2025-02-25 14:41:15,426 - Epoch 74, Training Loss: 90.81, Validation Loss: 106.18
2025-02-25 14:41:15,635 - Epoch 75, Training Loss: 88.07, Validation Loss: 105.64
2025-02-25 14:41:15,845 - Epoch 76, Training Loss: 97.49, Validation Loss: 105.12
2025-02-25 14:41:16,056 - Epoch 77, Training Loss: 95.15, Validation Loss: 104.66
2025-02-25 14:41:16,268 - Epoch 78, Training Loss: 87.59, Validation Loss: 104.15
2025-02-25 14:41:16,479 - Epoch 79, Training Loss: 86.29, Validation Loss: 103.67
2025-02-25 14:41:16,692 - Epoch 80, Training Loss: 93.62, Validation Loss: 103.23
2025-02-25 14:41:16,902 - Epoch 81, Training Loss: 79.75, Validation Loss: 102.88
2025-02-25 14:41:17,111 - Epoch 82, Training Loss: 87.18, Validation Loss: 102.57
2025-02-25 14:41:17,318 - Epoch 83, Training Loss: 99.27, Validation Loss: 102.17
2025-02-25 14:41:17,533 - Epoch 84, Training Loss: 92.26, Validation Loss: 101.60
2025-02-25 14:41:17,737 - Epoch 85, Training Loss: 89.67, Validation Loss: 101.03
2025-02-25 14:41:17,949 - Epoch 86, Training Loss: 95.50, Validation Loss: 100.51
2025-02-25 14:41:18,160 - Epoch 87, Training Loss: 85.82, Validation Loss: 100.06
2025-02-25 14:41:18,371 - Epoch 88, Training Loss: 84.41, Validation Loss: 99.64
2025-02-25 14:41:18,580 - Epoch 89, Training Loss: 80.35, Validation Loss: 99.24
2025-02-25 14:41:18,789 - Epoch 90, Training Loss: 79.87, Validation Loss: 98.84
2025-02-25 14:41:18,999 - Epoch 91, Training Loss: 86.56, Validation Loss: 98.50
2025-02-25 14:41:19,216 - Epoch 92, Training Loss: 93.30, Validation Loss: 98.04
2025-02-25 14:41:19,432 - Epoch 93, Training Loss: 87.23, Validation Loss: 97.56
2025-02-25 14:41:19,648 - Epoch 94, Training Loss: 80.41, Validation Loss: 97.13
2025-02-25 14:41:19,853 - Epoch 95, Training Loss: 80.94, Validation Loss: 96.80
2025-02-25 14:41:20,063 - Epoch 96, Training Loss: 76.99, Validation Loss: 96.49
2025-02-25 14:41:20,273 - Epoch 97, Training Loss: 77.62, Validation Loss: 96.20
2025-02-25 14:41:20,481 - Epoch 98, Training Loss: 78.83, Validation Loss: 95.90
2025-02-25 14:41:20,691 - Epoch 99, Training Loss: 92.90, Validation Loss: 95.70
2025-02-25 14:41:20,899 - Epoch 100, Training Loss: 81.34, Validation Loss: 95.43
2025-02-25 14:41:21,109 - Epoch 101, Training Loss: 79.26, Validation Loss: 95.19
2025-02-25 14:41:21,317 - Epoch 102, Training Loss: 85.52, Validation Loss: 95.03
2025-02-25 14:41:21,526 - Epoch 103, Training Loss: 75.08, Validation Loss: 94.83
2025-02-25 14:41:21,736 - Epoch 104, Training Loss: 88.99, Validation Loss: 94.56
2025-02-25 14:41:21,947 - Epoch 105, Training Loss: 90.88, Validation Loss: 94.19
2025-02-25 14:41:22,152 - Epoch 106, Training Loss: 80.99, Validation Loss: 93.76
2025-02-25 14:41:22,365 - Epoch 107, Training Loss: 80.76, Validation Loss: 93.35
2025-02-25 14:41:22,579 - Epoch 108, Training Loss: 77.38, Validation Loss: 93.00
2025-02-25 14:41:22,788 - Epoch 109, Training Loss: 80.22, Validation Loss: 92.72
2025-02-25 14:41:23,000 - Epoch 110, Training Loss: 88.39, Validation Loss: 92.34
2025-02-25 14:41:23,207 - Epoch 111, Training Loss: 87.26, Validation Loss: 91.87
2025-02-25 14:41:23,424 - Epoch 112, Training Loss: 79.34, Validation Loss: 91.41
2025-02-25 14:41:23,634 - Epoch 113, Training Loss: 84.51, Validation Loss: 91.05
2025-02-25 14:41:23,843 - Epoch 114, Training Loss: 78.90, Validation Loss: 90.73
2025-02-25 14:41:24,054 - Epoch 115, Training Loss: 86.91, Validation Loss: 90.40
2025-02-25 14:41:24,262 - Epoch 116, Training Loss: 73.78, Validation Loss: 90.10
2025-02-25 14:41:24,474 - Epoch 117, Training Loss: 90.04, Validation Loss: 89.95
2025-02-25 14:41:24,683 - Epoch 118, Training Loss: 80.14, Validation Loss: 89.71
2025-02-25 14:41:24,901 - Epoch 119, Training Loss: 80.62, Validation Loss: 89.48
2025-02-25 14:41:25,111 - Epoch 120, Training Loss: 75.62, Validation Loss: 89.19
2025-02-25 14:41:25,322 - Epoch 121, Training Loss: 90.96, Validation Loss: 88.91
2025-02-25 14:41:25,539 - Epoch 122, Training Loss: 89.11, Validation Loss: 88.51
2025-02-25 14:41:25,748 - Epoch 123, Training Loss: 74.26, Validation Loss: 88.09
2025-02-25 14:41:25,959 - Epoch 124, Training Loss: 84.06, Validation Loss: 87.84
2025-02-25 14:41:26,168 - Epoch 125, Training Loss: 90.18, Validation Loss: 87.61
2025-02-25 14:41:26,379 - Epoch 126, Training Loss: 81.27, Validation Loss: 87.31
2025-02-25 14:41:26,590 - Epoch 127, Training Loss: 78.97, Validation Loss: 87.08
2025-02-25 14:41:26,803 - Epoch 128, Training Loss: 87.04, Validation Loss: 86.74
2025-02-25 14:41:27,013 - Epoch 129, Training Loss: 74.50, Validation Loss: 86.49
2025-02-25 14:41:27,223 - Epoch 130, Training Loss: 79.83, Validation Loss: 86.32
2025-02-25 14:41:27,436 - Epoch 131, Training Loss: 81.50, Validation Loss: 86.07
2025-02-25 14:41:27,654 - Epoch 132, Training Loss: 81.33, Validation Loss: 85.75
2025-02-25 14:41:27,874 - Epoch 133, Training Loss: 73.31, Validation Loss: 85.47
2025-02-25 14:41:28,087 - Epoch 134, Training Loss: 83.94, Validation Loss: 85.22
2025-02-25 14:41:28,297 - Epoch 135, Training Loss: 90.86, Validation Loss: 84.94
2025-02-25 14:41:28,506 - Epoch 136, Training Loss: 75.59, Validation Loss: 84.61
2025-02-25 14:41:28,718 - Epoch 137, Training Loss: 79.87, Validation Loss: 84.38
2025-02-25 14:41:28,936 - Epoch 138, Training Loss: 72.08, Validation Loss: 84.12
2025-02-25 14:41:29,151 - Epoch 139, Training Loss: 76.37, Validation Loss: 84.01
2025-02-25 14:41:29,358 - Epoch 140, Training Loss: 85.48, Validation Loss: 83.87
2025-02-25 14:41:29,573 - Epoch 141, Training Loss: 90.33, Validation Loss: 83.61
2025-02-25 14:41:29,784 - Epoch 142, Training Loss: 72.22, Validation Loss: 83.27
2025-02-25 14:41:29,992 - Epoch 143, Training Loss: 85.95, Validation Loss: 83.04
2025-02-25 14:41:30,201 - Epoch 144, Training Loss: 83.19, Validation Loss: 82.76
2025-02-25 14:41:30,409 - Epoch 145, Training Loss: 88.19, Validation Loss: 82.39
2025-02-25 14:41:30,621 - Epoch 146, Training Loss: 77.93, Validation Loss: 82.03
2025-02-25 14:41:30,833 - Epoch 147, Training Loss: 84.53, Validation Loss: 81.66
2025-02-25 14:41:31,086 - Epoch 148, Training Loss: 83.51, Validation Loss: 81.36
2025-02-25 14:41:31,367 - Epoch 149, Training Loss: 74.59, Validation Loss: 81.09
2025-02-25 14:41:31,586 - Epoch 150, Training Loss: 73.89, Validation Loss: 80.84
2025-02-25 14:41:31,807 - Epoch 151, Training Loss: 83.92, Validation Loss: 80.64
2025-02-25 14:41:32,039 - Epoch 152, Training Loss: 76.19, Validation Loss: 80.40
2025-02-25 14:41:32,253 - Epoch 153, Training Loss: 72.23, Validation Loss: 80.19
2025-02-25 14:41:32,469 - Epoch 154, Training Loss: 83.01, Validation Loss: 80.08
2025-02-25 14:41:32,689 - Epoch 155, Training Loss: 83.15, Validation Loss: 79.96
2025-02-25 14:41:32,916 - Epoch 156, Training Loss: 74.72, Validation Loss: 79.78
2025-02-25 14:41:33,144 - Epoch 157, Training Loss: 79.13, Validation Loss: 79.69
2025-02-25 14:41:33,369 - Epoch 158, Training Loss: 73.27, Validation Loss: 79.71
2025-02-25 14:41:33,568 - Epoch 159, Training Loss: 81.25, Validation Loss: 79.66
2025-02-25 14:41:33,785 - Epoch 160, Training Loss: 81.57, Validation Loss: 79.50
2025-02-25 14:41:34,005 - Epoch 161, Training Loss: 70.93, Validation Loss: 79.32
2025-02-25 14:41:34,230 - Epoch 162, Training Loss: 82.64, Validation Loss: 79.18
2025-02-25 14:41:34,451 - Epoch 163, Training Loss: 67.90, Validation Loss: 79.01
2025-02-25 14:41:34,669 - Epoch 164, Training Loss: 74.46, Validation Loss: 78.91
2025-02-25 14:41:34,877 - Epoch 165, Training Loss: 80.67, Validation Loss: 78.85
2025-02-25 14:41:35,090 - Epoch 166, Training Loss: 70.09, Validation Loss: 78.79
2025-02-25 14:41:35,301 - Epoch 167, Training Loss: 82.60, Validation Loss: 78.71
2025-02-25 14:41:35,515 - Epoch 168, Training Loss: 87.23, Validation Loss: 78.56
2025-02-25 14:41:35,727 - Epoch 169, Training Loss: 84.39, Validation Loss: 78.35
2025-02-25 14:41:35,944 - Epoch 170, Training Loss: 83.63, Validation Loss: 78.08
2025-02-25 14:41:36,152 - Epoch 171, Training Loss: 74.70, Validation Loss: 77.75
2025-02-25 14:41:36,364 - Epoch 172, Training Loss: 72.88, Validation Loss: 77.49
2025-02-25 14:41:36,575 - Epoch 173, Training Loss: 83.07, Validation Loss: 77.29
2025-02-25 14:41:36,783 - Epoch 174, Training Loss: 75.83, Validation Loss: 77.09
2025-02-25 14:41:36,993 - Epoch 175, Training Loss: 72.21, Validation Loss: 76.86
2025-02-25 14:41:37,207 - Epoch 176, Training Loss: 78.28, Validation Loss: 76.73
2025-02-25 14:41:37,419 - Epoch 177, Training Loss: 71.89, Validation Loss: 76.60
2025-02-25 14:41:37,628 - Epoch 178, Training Loss: 71.56, Validation Loss: 76.59
2025-02-25 14:41:37,845 - Epoch 179, Training Loss: 71.50, Validation Loss: 76.59
2025-02-25 14:41:38,043 - Epoch 180, Training Loss: 72.77, Validation Loss: 76.60
2025-02-25 14:41:38,236 - Epoch 181, Training Loss: 68.47, Validation Loss: 76.69
2025-02-25 14:41:38,434 - Epoch 182, Training Loss: 66.53, Validation Loss: 76.79
2025-02-25 14:41:38,630 - Epoch 183, Training Loss: 70.26, Validation Loss: 76.80
2025-02-25 14:41:38,867 - Epoch 184, Training Loss: 73.93, Validation Loss: 76.74
2025-02-25 14:41:39,086 - Epoch 185, Training Loss: 72.19, Validation Loss: 76.61
2025-02-25 14:41:39,278 - Epoch 186, Training Loss: 84.76, Validation Loss: 76.51
2025-02-25 14:41:39,504 - Epoch 187, Training Loss: 83.99, Validation Loss: 76.45
2025-02-25 14:41:39,747 - Epoch 188, Training Loss: 73.56, Validation Loss: 76.73
2025-02-25 14:41:39,940 - Epoch 189, Training Loss: 75.94, Validation Loss: 75.91
2025-02-25 14:41:40,160 - Epoch 190, Training Loss: 70.32, Validation Loss: 76.14
2025-02-25 14:41:41,438 - Epoch 191, Training Loss: 68.26, Validation Loss: 76.47
2025-02-25 14:41:41,659 - Epoch 192, Training Loss: 82.10, Validation Loss: 75.24
2025-02-25 14:41:41,932 - Epoch 193, Training Loss: 78.61, Validation Loss: 74.81
2025-02-25 14:41:42,179 - Epoch 194, Training Loss: 77.79, Validation Loss: 74.43
2025-02-25 14:41:42,418 - Epoch 195, Training Loss: 71.08, Validation Loss: 74.14
2025-02-25 14:41:42,641 - Epoch 196, Training Loss: 82.12, Validation Loss: 73.98
2025-02-25 14:41:42,883 - Epoch 197, Training Loss: 70.04, Validation Loss: 73.91
2025-02-25 14:41:43,153 - Epoch 198, Training Loss: 76.99, Validation Loss: 74.17
2025-02-25 14:41:43,365 - Epoch 199, Training Loss: 80.32, Validation Loss: 75.42
2025-02-25 14:41:43,570 - Epoch 200, Training Loss: 80.31, Validation Loss: 74.03
2025-02-25 14:41:44,036 - Epoch 201, Training Loss: 74.25, Validation Loss: 74.54
2025-02-25 14:41:44,750 - Epoch 202, Training Loss: 77.15, Validation Loss: 73.35
2025-02-25 14:41:44,985 - Epoch 203, Training Loss: 64.77, Validation Loss: 72.16
2025-02-25 14:41:45,212 - Epoch 204, Training Loss: 86.18, Validation Loss: 71.34
2025-02-25 14:41:45,444 - Epoch 205, Training Loss: 68.22, Validation Loss: 71.75
2025-02-25 14:41:45,705 - Epoch 206, Training Loss: 65.08, Validation Loss: 70.33
2025-02-25 14:41:45,942 - Epoch 207, Training Loss: 79.33, Validation Loss: 70.08
2025-02-25 14:41:46,180 - Epoch 208, Training Loss: 66.88, Validation Loss: 70.41
2025-02-25 14:41:46,373 - Epoch 209, Training Loss: 65.64, Validation Loss: 68.83
2025-02-25 14:41:46,593 - Epoch 210, Training Loss: 61.24, Validation Loss: 71.10
2025-02-25 14:41:46,781 - Epoch 211, Training Loss: 59.99, Validation Loss: 68.04
2025-02-25 14:41:47,006 - Epoch 212, Training Loss: 57.77, Validation Loss: 68.96
2025-02-25 14:41:47,204 - Epoch 213, Training Loss: 66.89, Validation Loss: 66.96
2025-02-25 14:41:47,415 - Epoch 214, Training Loss: 80.59, Validation Loss: 66.51
2025-02-25 14:41:47,628 - Epoch 215, Training Loss: 73.23, Validation Loss: 68.37
2025-02-25 14:41:47,824 - Epoch 216, Training Loss: 62.36, Validation Loss: 65.36
2025-02-25 14:41:48,040 - Epoch 217, Training Loss: 63.26, Validation Loss: 65.57
2025-02-25 14:41:48,231 - Epoch 218, Training Loss: 68.89, Validation Loss: 64.74
2025-02-25 14:41:48,451 - Epoch 219, Training Loss: 67.75, Validation Loss: 63.87
2025-02-25 14:41:48,661 - Epoch 220, Training Loss: 56.40, Validation Loss: 63.87
2025-02-25 14:41:48,855 - Epoch 221, Training Loss: 58.37, Validation Loss: 62.77
2025-02-25 14:41:49,066 - Epoch 222, Training Loss: 67.71, Validation Loss: 63.95
2025-02-25 14:41:49,267 - Epoch 223, Training Loss: 58.27, Validation Loss: 62.28
2025-02-25 14:41:49,483 - Epoch 224, Training Loss: 58.12, Validation Loss: 61.70
2025-02-25 14:41:49,692 - Epoch 225, Training Loss: 53.96, Validation Loss: 62.32
2025-02-25 14:41:49,885 - Epoch 226, Training Loss: 55.45, Validation Loss: 61.09
2025-02-25 14:41:50,102 - Epoch 227, Training Loss: 64.06, Validation Loss: 60.97
2025-02-25 14:41:50,311 - Epoch 228, Training Loss: 59.39, Validation Loss: 60.75
2025-02-25 14:41:50,522 - Epoch 229, Training Loss: 52.96, Validation Loss: 61.70
2025-02-25 14:41:50,709 - Epoch 230, Training Loss: 54.81, Validation Loss: 60.68
2025-02-25 14:41:50,921 - Epoch 231, Training Loss: 56.61, Validation Loss: 59.74
2025-02-25 14:41:51,141 - Epoch 232, Training Loss: 59.59, Validation Loss: 59.25
2025-02-25 14:41:51,354 - Epoch 233, Training Loss: 57.72, Validation Loss: 59.40
2025-02-25 14:41:51,546 - Epoch 234, Training Loss: 58.76, Validation Loss: 58.58
2025-02-25 14:41:51,754 - Epoch 235, Training Loss: 57.21, Validation Loss: 58.19
2025-02-25 14:41:51,973 - Epoch 236, Training Loss: 54.82, Validation Loss: 57.87
2025-02-25 14:41:52,182 - Epoch 237, Training Loss: 63.67, Validation Loss: 59.29
2025-02-25 14:41:52,375 - Epoch 238, Training Loss: 67.82, Validation Loss: 57.63
2025-02-25 14:41:52,592 - Epoch 239, Training Loss: 64.87, Validation Loss: 57.78
2025-02-25 14:41:52,782 - Epoch 240, Training Loss: 63.65, Validation Loss: 58.25
2025-02-25 14:41:52,992 - Epoch 241, Training Loss: 88.06, Validation Loss: 59.11
2025-02-25 14:41:53,180 - Epoch 242, Training Loss: 70.51, Validation Loss: 65.71
2025-02-25 14:41:53,374 - Epoch 243, Training Loss: 68.32, Validation Loss: 65.74
2025-02-25 14:41:53,567 - Epoch 244, Training Loss: 67.27, Validation Loss: 65.73
2025-02-25 14:41:53,760 - Epoch 245, Training Loss: 72.94, Validation Loss: 65.77
2025-02-25 14:41:53,949 - Epoch 246, Training Loss: 80.52, Validation Loss: 65.87
2025-02-25 14:41:54,138 - Epoch 247, Training Loss: 67.85, Validation Loss: 66.01
2025-02-25 14:41:54,321 - Epoch 248, Training Loss: 73.26, Validation Loss: 66.14
2025-02-25 14:41:54,509 - Epoch 249, Training Loss: 77.17, Validation Loss: 66.37
2025-02-25 14:41:54,695 - Epoch 250, Training Loss: 78.16, Validation Loss: 66.59
2025-02-25 14:41:54,889 - Epoch 251, Training Loss: 71.58, Validation Loss: 66.75
2025-02-25 14:41:55,072 - Epoch 252, Training Loss: 71.74, Validation Loss: 66.95
2025-02-25 14:41:55,264 - Epoch 253, Training Loss: 74.28, Validation Loss: 67.01
2025-02-25 14:41:55,450 - Epoch 254, Training Loss: 68.60, Validation Loss: 67.01
2025-02-25 14:41:55,643 - Epoch 255, Training Loss: 66.07, Validation Loss: 67.01
2025-02-25 14:41:55,826 - Epoch 256, Training Loss: 76.46, Validation Loss: 66.98
2025-02-25 14:41:56,018 - Epoch 257, Training Loss: 75.13, Validation Loss: 66.98
2025-02-25 14:41:56,203 - Epoch 258, Training Loss: 76.59, Validation Loss: 67.01
2025-02-25 14:41:56,203 - Early stopping at epoch 258 due to no improvement in validation loss.
2025-02-25 14:41:56,440 - learning rate: 0.002
2025-02-25 14:41:56,440 - Test RMSE: 7.241636276245117, Test MAE: 1.0311947464942932
2025-02-25 14:42:24,981 - -----------------------Starting training-------------------------
2025-02-25 14:42:24,981 - learning rate: 0.005
2025-02-25 14:42:25,181 - Epoch 1, Training Loss: 157.00, Validation Loss: 217.28
2025-02-25 14:42:25,412 - Epoch 2, Training Loss: 175.12, Validation Loss: 207.11
2025-02-25 14:42:25,628 - Epoch 3, Training Loss: 165.30, Validation Loss: 197.55
2025-02-25 14:42:25,865 - Epoch 4, Training Loss: 147.76, Validation Loss: 189.67
2025-02-25 14:42:26,076 - Epoch 5, Training Loss: 174.66, Validation Loss: 182.67
2025-02-25 14:42:26,290 - Epoch 6, Training Loss: 128.35, Validation Loss: 176.16
2025-02-25 14:42:26,520 - Epoch 7, Training Loss: 133.80, Validation Loss: 170.42
2025-02-25 14:42:26,744 - Epoch 8, Training Loss: 133.63, Validation Loss: 165.15
2025-02-25 14:42:26,964 - Epoch 9, Training Loss: 138.67, Validation Loss: 160.29
2025-02-25 14:42:27,184 - Epoch 10, Training Loss: 143.65, Validation Loss: 155.77
2025-02-25 14:42:27,412 - Epoch 11, Training Loss: 114.27, Validation Loss: 151.53
2025-02-25 14:42:27,630 - Epoch 12, Training Loss: 121.09, Validation Loss: 147.70
2025-02-25 14:42:27,860 - Epoch 13, Training Loss: 138.99, Validation Loss: 144.16
2025-02-25 14:42:28,077 - Epoch 14, Training Loss: 122.35, Validation Loss: 140.76
2025-02-25 14:42:28,294 - Epoch 15, Training Loss: 124.94, Validation Loss: 137.71
2025-02-25 14:42:28,510 - Epoch 16, Training Loss: 135.01, Validation Loss: 134.59
2025-02-25 14:42:28,725 - Epoch 17, Training Loss: 97.87, Validation Loss: 131.74
2025-02-25 14:42:28,947 - Epoch 18, Training Loss: 104.63, Validation Loss: 129.38
2025-02-25 14:42:29,177 - Epoch 19, Training Loss: 112.85, Validation Loss: 127.15
2025-02-25 14:42:29,406 - Epoch 20, Training Loss: 111.49, Validation Loss: 124.84
2025-02-25 14:42:29,624 - Epoch 21, Training Loss: 129.20, Validation Loss: 122.57
2025-02-25 14:42:29,844 - Epoch 22, Training Loss: 95.75, Validation Loss: 120.40
2025-02-25 14:42:30,055 - Epoch 23, Training Loss: 94.61, Validation Loss: 118.42
2025-02-25 14:42:30,278 - Epoch 24, Training Loss: 96.66, Validation Loss: 116.66
2025-02-25 14:42:30,495 - Epoch 25, Training Loss: 100.22, Validation Loss: 114.90
2025-02-25 14:42:30,828 - Epoch 26, Training Loss: 92.90, Validation Loss: 113.27
2025-02-25 14:42:31,051 - Epoch 27, Training Loss: 93.43, Validation Loss: 111.67
2025-02-25 14:42:31,268 - Epoch 28, Training Loss: 91.98, Validation Loss: 110.07
2025-02-25 14:42:31,489 - Epoch 29, Training Loss: 101.76, Validation Loss: 108.50
2025-02-25 14:42:31,712 - Epoch 30, Training Loss: 84.43, Validation Loss: 106.98
2025-02-25 14:42:31,930 - Epoch 31, Training Loss: 98.91, Validation Loss: 105.80
2025-02-25 14:42:32,156 - Epoch 32, Training Loss: 88.50, Validation Loss: 104.57
2025-02-25 14:42:32,376 - Epoch 33, Training Loss: 88.51, Validation Loss: 103.36
2025-02-25 14:42:32,594 - Epoch 34, Training Loss: 85.53, Validation Loss: 102.13
2025-02-25 14:42:32,817 - Epoch 35, Training Loss: 75.89, Validation Loss: 101.05
2025-02-25 14:42:33,028 - Epoch 36, Training Loss: 80.70, Validation Loss: 100.28
2025-02-25 14:42:33,244 - Epoch 37, Training Loss: 103.88, Validation Loss: 99.35
2025-02-25 14:42:33,454 - Epoch 38, Training Loss: 94.78, Validation Loss: 97.94
2025-02-25 14:42:33,660 - Epoch 39, Training Loss: 85.90, Validation Loss: 96.65
2025-02-25 14:42:33,875 - Epoch 40, Training Loss: 83.73, Validation Loss: 95.54
2025-02-25 14:42:34,078 - Epoch 41, Training Loss: 85.95, Validation Loss: 94.52
2025-02-25 14:42:34,309 - Epoch 42, Training Loss: 86.55, Validation Loss: 93.37
2025-02-25 14:42:34,525 - Epoch 43, Training Loss: 77.64, Validation Loss: 92.52
2025-02-25 14:42:34,763 - Epoch 44, Training Loss: 75.82, Validation Loss: 92.02
2025-02-25 14:42:35,010 - Epoch 45, Training Loss: 96.90, Validation Loss: 91.39
2025-02-25 14:42:35,254 - Epoch 46, Training Loss: 90.57, Validation Loss: 90.25
2025-02-25 14:42:35,469 - Epoch 47, Training Loss: 88.66, Validation Loss: 89.10
2025-02-25 14:42:35,680 - Epoch 48, Training Loss: 78.97, Validation Loss: 88.08
2025-02-25 14:42:35,894 - Epoch 49, Training Loss: 81.65, Validation Loss: 87.20
2025-02-25 14:42:36,112 - Epoch 50, Training Loss: 74.49, Validation Loss: 86.48
2025-02-25 14:42:36,331 - Epoch 51, Training Loss: 78.66, Validation Loss: 86.21
2025-02-25 14:42:36,545 - Epoch 52, Training Loss: 69.75, Validation Loss: 85.78
2025-02-25 14:42:36,765 - Epoch 53, Training Loss: 77.22, Validation Loss: 85.36
2025-02-25 14:42:36,996 - Epoch 54, Training Loss: 75.23, Validation Loss: 84.86
2025-02-25 14:42:37,234 - Epoch 55, Training Loss: 80.09, Validation Loss: 84.47
2025-02-25 14:42:37,442 - Epoch 56, Training Loss: 80.45, Validation Loss: 84.21
2025-02-25 14:42:37,647 - Epoch 57, Training Loss: 88.41, Validation Loss: 83.58
2025-02-25 14:42:37,863 - Epoch 58, Training Loss: 71.30, Validation Loss: 82.75
2025-02-25 14:42:38,078 - Epoch 59, Training Loss: 79.02, Validation Loss: 82.09
2025-02-25 14:42:38,296 - Epoch 60, Training Loss: 74.46, Validation Loss: 81.43
2025-02-25 14:42:38,503 - Epoch 61, Training Loss: 91.07, Validation Loss: 80.76
2025-02-25 14:42:38,717 - Epoch 62, Training Loss: 90.50, Validation Loss: 79.88
2025-02-25 14:42:38,933 - Epoch 63, Training Loss: 92.83, Validation Loss: 79.04
2025-02-25 14:42:39,259 - Epoch 64, Training Loss: 70.34, Validation Loss: 78.32
2025-02-25 14:42:39,477 - Epoch 65, Training Loss: 81.70, Validation Loss: 77.97
2025-02-25 14:42:39,686 - Epoch 66, Training Loss: 75.94, Validation Loss: 77.51
2025-02-25 14:42:39,895 - Epoch 67, Training Loss: 74.47, Validation Loss: 77.19
2025-02-25 14:42:40,195 - Epoch 68, Training Loss: 74.82, Validation Loss: 76.81
2025-02-25 14:42:40,411 - Epoch 69, Training Loss: 73.40, Validation Loss: 76.41
2025-02-25 14:42:40,623 - Epoch 70, Training Loss: 74.79, Validation Loss: 75.94
2025-02-25 14:42:40,846 - Epoch 71, Training Loss: 75.52, Validation Loss: 75.53
2025-02-25 14:42:41,065 - Epoch 72, Training Loss: 83.67, Validation Loss: 75.11
2025-02-25 14:42:41,287 - Epoch 73, Training Loss: 80.28, Validation Loss: 74.65
2025-02-25 14:42:41,506 - Epoch 74, Training Loss: 74.47, Validation Loss: 74.26
2025-02-25 14:42:41,817 - Epoch 75, Training Loss: 68.05, Validation Loss: 74.09
2025-02-25 14:42:42,046 - Epoch 76, Training Loss: 80.35, Validation Loss: 73.87
2025-02-25 14:42:42,264 - Epoch 77, Training Loss: 76.09, Validation Loss: 73.78
2025-02-25 14:42:42,484 - Epoch 78, Training Loss: 70.55, Validation Loss: 73.54
2025-02-25 14:42:42,701 - Epoch 79, Training Loss: 70.16, Validation Loss: 73.36
2025-02-25 14:42:42,910 - Epoch 80, Training Loss: 78.00, Validation Loss: 73.27
2025-02-25 14:42:43,120 - Epoch 81, Training Loss: 68.90, Validation Loss: 73.36
2025-02-25 14:42:43,305 - Epoch 82, Training Loss: 71.27, Validation Loss: 73.49
2025-02-25 14:42:43,501 - Epoch 83, Training Loss: 77.29, Validation Loss: 73.33
2025-02-25 14:42:43,699 - Epoch 84, Training Loss: 73.25, Validation Loss: 72.79
2025-02-25 14:42:43,915 - Epoch 85, Training Loss: 71.95, Validation Loss: 72.29
2025-02-25 14:42:44,132 - Epoch 86, Training Loss: 77.15, Validation Loss: 71.95
2025-02-25 14:42:44,338 - Epoch 87, Training Loss: 71.06, Validation Loss: 71.82
2025-02-25 14:42:44,561 - Epoch 88, Training Loss: 69.99, Validation Loss: 71.70
2025-02-25 14:42:44,785 - Epoch 89, Training Loss: 65.29, Validation Loss: 71.59
2025-02-25 14:42:45,001 - Epoch 90, Training Loss: 68.81, Validation Loss: 71.46
2025-02-25 14:42:45,224 - Epoch 91, Training Loss: 68.16, Validation Loss: 71.43
2025-02-25 14:42:45,437 - Epoch 92, Training Loss: 75.17, Validation Loss: 71.06
2025-02-25 14:42:45,656 - Epoch 93, Training Loss: 70.71, Validation Loss: 70.70
2025-02-25 14:42:45,876 - Epoch 94, Training Loss: 69.79, Validation Loss: 70.47
2025-02-25 14:42:46,078 - Epoch 95, Training Loss: 67.95, Validation Loss: 70.51
2025-02-25 14:42:46,269 - Epoch 96, Training Loss: 67.04, Validation Loss: 70.54
2025-02-25 14:42:46,466 - Epoch 97, Training Loss: 63.94, Validation Loss: 70.59
2025-02-25 14:42:46,666 - Epoch 98, Training Loss: 71.04, Validation Loss: 70.71
2025-02-25 14:42:46,864 - Epoch 99, Training Loss: 79.87, Validation Loss: 71.70
2025-02-25 14:42:47,060 - Epoch 100, Training Loss: 71.14, Validation Loss: 71.62
2025-02-25 14:42:47,251 - Epoch 101, Training Loss: 71.55, Validation Loss: 72.59
2025-02-25 14:42:47,441 - Epoch 102, Training Loss: 74.56, Validation Loss: 72.78
2025-02-25 14:42:47,627 - Epoch 103, Training Loss: 64.33, Validation Loss: 73.82
2025-02-25 14:42:47,820 - Epoch 104, Training Loss: 75.43, Validation Loss: 73.05
2025-02-25 14:42:48,017 - Epoch 105, Training Loss: 76.94, Validation Loss: 72.51
2025-02-25 14:42:48,213 - Epoch 106, Training Loss: 67.76, Validation Loss: 71.92
2025-02-25 14:42:48,403 - Epoch 107, Training Loss: 69.99, Validation Loss: 71.91
2025-02-25 14:42:48,601 - Epoch 108, Training Loss: 69.32, Validation Loss: 71.96
2025-02-25 14:42:48,787 - Epoch 109, Training Loss: 66.56, Validation Loss: 70.96
2025-02-25 14:42:48,981 - Epoch 110, Training Loss: 72.70, Validation Loss: 70.53
2025-02-25 14:42:49,183 - Epoch 111, Training Loss: 74.17, Validation Loss: 69.92
2025-02-25 14:42:49,405 - Epoch 112, Training Loss: 70.43, Validation Loss: 69.39
2025-02-25 14:42:49,622 - Epoch 113, Training Loss: 75.99, Validation Loss: 69.15
2025-02-25 14:42:49,828 - Epoch 114, Training Loss: 66.33, Validation Loss: 69.40
2025-02-25 14:42:50,040 - Epoch 115, Training Loss: 74.09, Validation Loss: 68.81
2025-02-25 14:42:50,257 - Epoch 116, Training Loss: 70.65, Validation Loss: 68.70
2025-02-25 14:42:50,471 - Epoch 117, Training Loss: 77.78, Validation Loss: 68.93
2025-02-25 14:42:50,660 - Epoch 118, Training Loss: 71.38, Validation Loss: 68.90
2025-02-25 14:42:50,852 - Epoch 119, Training Loss: 70.31, Validation Loss: 68.89
2025-02-25 14:42:51,050 - Epoch 120, Training Loss: 66.33, Validation Loss: 68.70
2025-02-25 14:42:51,266 - Epoch 121, Training Loss: 78.73, Validation Loss: 68.52
2025-02-25 14:42:51,478 - Epoch 122, Training Loss: 74.25, Validation Loss: 68.07
2025-02-25 14:42:51,715 - Epoch 123, Training Loss: 69.92, Validation Loss: 67.61
2025-02-25 14:42:51,934 - Epoch 124, Training Loss: 75.21, Validation Loss: 67.64
2025-02-25 14:42:52,126 - Epoch 125, Training Loss: 78.25, Validation Loss: 67.66
2025-02-25 14:42:52,328 - Epoch 126, Training Loss: 73.62, Validation Loss: 67.45
2025-02-25 14:42:52,554 - Epoch 127, Training Loss: 66.40, Validation Loss: 67.40
2025-02-25 14:42:52,768 - Epoch 128, Training Loss: 78.63, Validation Loss: 67.08
2025-02-25 14:42:52,973 - Epoch 129, Training Loss: 69.55, Validation Loss: 67.01
2025-02-25 14:42:53,180 - Epoch 130, Training Loss: 70.06, Validation Loss: 67.18
2025-02-25 14:42:53,387 - Epoch 131, Training Loss: 69.44, Validation Loss: 67.06
2025-02-25 14:42:53,583 - Epoch 132, Training Loss: 74.15, Validation Loss: 66.79
2025-02-25 14:42:53,807 - Epoch 133, Training Loss: 64.86, Validation Loss: 66.58
2025-02-25 14:42:54,022 - Epoch 134, Training Loss: 75.06, Validation Loss: 66.47
2025-02-25 14:42:54,252 - Epoch 135, Training Loss: 77.45, Validation Loss: 66.31
2025-02-25 14:42:54,473 - Epoch 136, Training Loss: 70.28, Validation Loss: 66.00
2025-02-25 14:42:54,688 - Epoch 137, Training Loss: 69.65, Validation Loss: 65.98
2025-02-25 14:42:54,904 - Epoch 138, Training Loss: 68.13, Validation Loss: 65.86
2025-02-25 14:42:55,110 - Epoch 139, Training Loss: 69.45, Validation Loss: 66.11
2025-02-25 14:42:55,301 - Epoch 140, Training Loss: 76.21, Validation Loss: 66.20
2025-02-25 14:42:55,494 - Epoch 141, Training Loss: 77.79, Validation Loss: 65.98
2025-02-25 14:42:55,682 - Epoch 142, Training Loss: 68.64, Validation Loss: 65.60
2025-02-25 14:42:55,893 - Epoch 143, Training Loss: 76.79, Validation Loss: 65.52
2025-02-25 14:42:56,098 - Epoch 144, Training Loss: 71.83, Validation Loss: 65.33
2025-02-25 14:42:56,309 - Epoch 145, Training Loss: 78.06, Validation Loss: 64.91
2025-02-25 14:42:56,516 - Epoch 146, Training Loss: 67.60, Validation Loss: 64.24
2025-02-25 14:42:56,732 - Epoch 147, Training Loss: 75.64, Validation Loss: 63.91
2025-02-25 14:42:56,945 - Epoch 148, Training Loss: 75.25, Validation Loss: 63.78
2025-02-25 14:42:57,170 - Epoch 149, Training Loss: 65.85, Validation Loss: 63.69
2025-02-25 14:42:57,387 - Epoch 150, Training Loss: 67.77, Validation Loss: 63.62
2025-02-25 14:42:57,598 - Epoch 151, Training Loss: 73.27, Validation Loss: 63.66
2025-02-25 14:42:57,799 - Epoch 152, Training Loss: 69.49, Validation Loss: 63.55
2025-02-25 14:42:58,010 - Epoch 153, Training Loss: 68.34, Validation Loss: 63.53
2025-02-25 14:42:58,230 - Epoch 154, Training Loss: 77.17, Validation Loss: 64.17
2025-02-25 14:42:58,422 - Epoch 155, Training Loss: 74.93, Validation Loss: 64.33
2025-02-25 14:42:58,611 - Epoch 156, Training Loss: 70.24, Validation Loss: 64.24
2025-02-25 14:42:58,798 - Epoch 157, Training Loss: 76.47, Validation Loss: 64.38
2025-02-25 14:42:58,984 - Epoch 158, Training Loss: 68.95, Validation Loss: 64.81
2025-02-25 14:42:59,172 - Epoch 159, Training Loss: 73.80, Validation Loss: 65.01
2025-02-25 14:42:59,361 - Epoch 160, Training Loss: 74.03, Validation Loss: 64.86
2025-02-25 14:42:59,557 - Epoch 161, Training Loss: 67.29, Validation Loss: 64.85
2025-02-25 14:42:59,745 - Epoch 162, Training Loss: 75.13, Validation Loss: 64.64
2025-02-25 14:42:59,937 - Epoch 163, Training Loss: 62.95, Validation Loss: 64.54
2025-02-25 14:43:00,131 - Epoch 164, Training Loss: 71.94, Validation Loss: 64.63
2025-02-25 14:43:00,328 - Epoch 165, Training Loss: 74.69, Validation Loss: 64.92
2025-02-25 14:43:00,521 - Epoch 166, Training Loss: 66.94, Validation Loss: 64.96
2025-02-25 14:43:00,729 - Epoch 167, Training Loss: 75.75, Validation Loss: 65.14
2025-02-25 14:43:00,950 - Epoch 168, Training Loss: 79.42, Validation Loss: 64.56
2025-02-25 14:43:01,146 - Epoch 169, Training Loss: 77.33, Validation Loss: 64.33
2025-02-25 14:43:01,347 - Epoch 170, Training Loss: 75.31, Validation Loss: 64.03
2025-02-25 14:43:01,533 - Epoch 171, Training Loss: 69.46, Validation Loss: 63.62
2025-02-25 14:43:01,728 - Epoch 172, Training Loss: 68.33, Validation Loss: 63.38
2025-02-25 14:43:01,931 - Epoch 173, Training Loss: 76.88, Validation Loss: 63.32
2025-02-25 14:43:02,142 - Epoch 174, Training Loss: 68.17, Validation Loss: 63.25
2025-02-25 14:43:02,352 - Epoch 175, Training Loss: 68.96, Validation Loss: 63.09
2025-02-25 14:43:02,571 - Epoch 176, Training Loss: 73.22, Validation Loss: 63.18
2025-02-25 14:43:02,766 - Epoch 177, Training Loss: 71.36, Validation Loss: 63.28
2025-02-25 14:43:02,960 - Epoch 178, Training Loss: 69.11, Validation Loss: 63.70
2025-02-25 14:43:03,155 - Epoch 179, Training Loss: 69.40, Validation Loss: 64.17
2025-02-25 14:43:03,346 - Epoch 180, Training Loss: 70.59, Validation Loss: 64.70
2025-02-25 14:43:03,537 - Epoch 181, Training Loss: 67.36, Validation Loss: 65.19
2025-02-25 14:43:03,732 - Epoch 182, Training Loss: 63.31, Validation Loss: 65.73
2025-02-25 14:43:03,939 - Epoch 183, Training Loss: 67.55, Validation Loss: 66.26
2025-02-25 14:43:04,133 - Epoch 184, Training Loss: 70.04, Validation Loss: 66.10
2025-02-25 14:43:04,330 - Epoch 185, Training Loss: 69.67, Validation Loss: 66.88
2025-02-25 14:43:04,520 - Epoch 186, Training Loss: 80.31, Validation Loss: 66.15
2025-02-25 14:43:04,717 - Epoch 187, Training Loss: 79.11, Validation Loss: 65.64
2025-02-25 14:43:04,919 - Epoch 188, Training Loss: 68.96, Validation Loss: 65.35
2025-02-25 14:43:05,111 - Epoch 189, Training Loss: 70.62, Validation Loss: 65.03
2025-02-25 14:43:05,302 - Epoch 190, Training Loss: 67.05, Validation Loss: 66.86
2025-02-25 14:43:05,491 - Epoch 191, Training Loss: 66.20, Validation Loss: 64.49
2025-02-25 14:43:05,679 - Epoch 192, Training Loss: 76.56, Validation Loss: 65.37
2025-02-25 14:43:05,873 - Epoch 193, Training Loss: 73.14, Validation Loss: 64.02
2025-02-25 14:43:06,070 - Epoch 194, Training Loss: 71.87, Validation Loss: 62.96
2025-02-25 14:43:06,278 - Epoch 195, Training Loss: 65.14, Validation Loss: 69.62
2025-02-25 14:43:06,464 - Epoch 196, Training Loss: 77.24, Validation Loss: 62.91
2025-02-25 14:43:06,668 - Epoch 197, Training Loss: 65.95, Validation Loss: 64.94
2025-02-25 14:43:06,860 - Epoch 198, Training Loss: 69.94, Validation Loss: 64.80
2025-02-25 14:43:07,050 - Epoch 199, Training Loss: 71.71, Validation Loss: 62.89
2025-02-25 14:43:07,269 - Epoch 200, Training Loss: 72.27, Validation Loss: 61.69
2025-02-25 14:43:07,477 - Epoch 201, Training Loss: 69.45, Validation Loss: 64.18
2025-02-25 14:43:07,669 - Epoch 202, Training Loss: 70.47, Validation Loss: 57.89
2025-02-25 14:43:07,900 - Epoch 203, Training Loss: 56.87, Validation Loss: 55.49
2025-02-25 14:43:08,201 - Epoch 204, Training Loss: 75.78, Validation Loss: 57.72
2025-02-25 14:43:08,416 - Epoch 205, Training Loss: 66.02, Validation Loss: 60.34
2025-02-25 14:43:08,609 - Epoch 206, Training Loss: 63.05, Validation Loss: 60.34
2025-02-25 14:43:08,811 - Epoch 207, Training Loss: 76.09, Validation Loss: 60.39
2025-02-25 14:43:09,036 - Epoch 208, Training Loss: 71.89, Validation Loss: 60.93
2025-02-25 14:43:09,248 - Epoch 209, Training Loss: 67.85, Validation Loss: 63.43
2025-02-25 14:43:09,452 - Epoch 210, Training Loss: 61.75, Validation Loss: 65.49
2025-02-25 14:43:09,670 - Epoch 211, Training Loss: 60.54, Validation Loss: 64.78
2025-02-25 14:43:09,890 - Epoch 212, Training Loss: 57.70, Validation Loss: 58.71
2025-02-25 14:43:10,124 - Epoch 213, Training Loss: 61.92, Validation Loss: 59.29
2025-02-25 14:43:10,362 - Epoch 214, Training Loss: 71.95, Validation Loss: 59.38
2025-02-25 14:43:10,581 - Epoch 215, Training Loss: 77.42, Validation Loss: 61.36
2025-02-25 14:43:10,791 - Epoch 216, Training Loss: 63.06, Validation Loss: 60.94
2025-02-25 14:43:11,008 - Epoch 217, Training Loss: 77.90, Validation Loss: 60.86
2025-02-25 14:43:11,279 - Epoch 218, Training Loss: 77.79, Validation Loss: 61.15
2025-02-25 14:43:11,493 - Epoch 219, Training Loss: 72.83, Validation Loss: 61.13
2025-02-25 14:43:11,711 - Epoch 220, Training Loss: 68.35, Validation Loss: 61.18
2025-02-25 14:43:11,912 - Epoch 221, Training Loss: 65.66, Validation Loss: 61.90
2025-02-25 14:43:12,101 - Epoch 222, Training Loss: 74.39, Validation Loss: 61.75
2025-02-25 14:43:12,285 - Epoch 223, Training Loss: 68.69, Validation Loss: 61.75
2025-02-25 14:43:12,285 - Early stopping at epoch 223 due to no improvement in validation loss.
2025-02-25 14:43:12,514 - learning rate: 0.005
2025-02-25 14:43:12,514 - Test RMSE: 6.9350340366363525, Test MAE: 1.102683275938034
